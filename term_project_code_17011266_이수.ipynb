{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSU8nJqsHChhRqsY6I5PVr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/TNTTNTTTN/Titanic_Survive_Prediction/blob/main/term_project_code_17011266_%EC%9D%B4%EC%88%98.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 385,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cB_zyD5x-ao2",
        "outputId": "d0ba9ad6-c463-4f65-9759-e69e6983950a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 417\n",
            "Data columns (total 11 columns):\n",
            " #   Column       Non-Null Count  Dtype  \n",
            "---  ------       --------------  -----  \n",
            " 0   PassengerId  1309 non-null   int64  \n",
            " 1   Pclass       1309 non-null   int64  \n",
            " 2   Name         1309 non-null   object \n",
            " 3   Sex          1309 non-null   object \n",
            " 4   Age          1046 non-null   float64\n",
            " 5   SibSp        1309 non-null   int64  \n",
            " 6   Parch        1309 non-null   int64  \n",
            " 7   Ticket       1309 non-null   object \n",
            " 8   Fare         1308 non-null   float64\n",
            " 9   Cabin        295 non-null    object \n",
            " 10  Embarked     1307 non-null   object \n",
            "dtypes: float64(2), int64(4), object(5)\n",
            "memory usage: 122.7+ KB\n"
          ]
        }
      ],
      "source": [
        "#-*- coding: utf-8 -*-\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.layers import Dense, Dropout\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler, LabelEncoder\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "seed = 3\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)\n",
        "\n",
        "df1 = pd.read_csv(\"/content/train.csv\")\n",
        "df2 = pd.read_csv(\"/content/test.csv\")\n",
        "df1.drop(labels='Survived', axis=1, inplace=True)\n",
        "df = pd.concat([df1, df2[:]], axis=0)\n",
        "stscaler = StandardScaler()\n",
        "mmscaler = MinMaxScaler()\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_title(Name):\n",
        "  if 'Mrs' in Name or 'Mme' in Name :\n",
        "    Title='Mrs'\n",
        "  elif 'Mr' in Name or 'Sir' in Name :\n",
        "    Title='Mr'\n",
        "  elif 'Miss' in Name or 'Ms' in Name or 'Mlle' in Name:\n",
        "    Title='Miss'\n",
        "  elif 'Master' in Name:\n",
        "    Title='Master'\n",
        "  else:\n",
        "    Title='Else'\n",
        "  return Title"
      ],
      "metadata": {
        "id": "UW5mHZHE4fEj"
      },
      "execution_count": 386,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_age(Age):\n",
        "  if Age<=10 : tag =\"0\"\n",
        "  elif Age <=20 : tag=\"1\"\n",
        "  elif Age <= 30 : tag=\"2\"\n",
        "  elif Age <= 40 : tag=\"3\"\n",
        "  elif Age <= 50 : tag=\"4\"\n",
        "  elif Age <= 60 : tag =\"5\"\n",
        "  else : tag = \"6\"\n",
        "  return tag"
      ],
      "metadata": {
        "id": "U3GGrlfzr0kf"
      },
      "execution_count": 387,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classify_fare(Fare):\n",
        "  if Fare <= 75 : tag=\"0\"\n",
        "  elif Fare <= 150 : tag=\"\"\n",
        "  elif Fare <= 225 : tag=\"2\"\n",
        "  elif Fare <= 300 : tag=\"3\"\n",
        "  elif Fare <= 375 : tag=\"4\"\n",
        "  elif Fare <= 450 : tag=\"5\"\n",
        "  else : tag = \"6\"\n",
        "  return tag"
      ],
      "metadata": {
        "id": "_5kZXhuHwUQ0"
      },
      "execution_count": 388,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Title'] = df['Name'].apply(lambda x : get_title(x))\n",
        "df['Pclass'] = df['Pclass'].astype('string')\n",
        "title_dic = {0:\"Mrs\", 1:\"Mr\", 2:\"Miss\", 3:\"Master\", 4:\"Else\"}\n",
        "#df['Title'] = df['Title'].map(title_dic).astype(int).fillna(0)"
      ],
      "metadata": {
        "id": "rH-Oxktgsbza"
      },
      "execution_count": 389,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Title']==3]"
      ],
      "metadata": {
        "id": "MsBAYx7zUwI8",
        "outputId": "977624e1-10aa-40a9-daa8-bc08e6a28b47",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Title]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2a29a210-ec19-4d7d-b350-22e3dbc26715\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2a29a210-ec19-4d7d-b350-22e3dbc26715')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2a29a210-ec19-4d7d-b350-22e3dbc26715 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2a29a210-ec19-4d7d-b350-22e3dbc26715');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 390
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#df['Sex'] = df['Sex'].map({'male':0, 'female':1}).astype(int)\n",
        "df.loc[(df['Sex']=='male') & (df['Age'].isnull()) & (df['Title']==title_dic[3]),'Age'] = 10\n",
        "df.loc[(df['Sex']=='male') & (df['Age'].isnull()),'Age'] = df[df['Sex']=='male']['Age'].mean()\n",
        "df.loc[(df['Sex']=='female') & (df['Age'].isnull()),'Age'] = df[df['Sex']=='female']['Age'].mean()\n",
        "df['Age'] = df['Age'].apply(lambda x : classify_age(x))"
      ],
      "metadata": {
        "id": "qtCZiz6XCjZa"
      },
      "execution_count": 391,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.loc[df['Fare'].isnull(),'Fare'] = df['Fare'].mean()"
      ],
      "metadata": {
        "id": "tWKvwuJZnWQM"
      },
      "execution_count": 392,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cabin_dic={'A':0, 'B':1, 'C':2, 'D':3, 'E':4, 'F':5, 'G':6}\n",
        "df['NCabin'] = df['Cabin'].fillna(\"N\")\n",
        "df['NCabin'] = df['NCabin'].str.extract('([A-Z])', expand=False)"
      ],
      "metadata": {
        "id": "bPXUQnRCXPff"
      },
      "execution_count": 393,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.groupby(\"NCabin\")['Fare'].mean().sort_values()"
      ],
      "metadata": {
        "id": "iAPph672ppUW",
        "outputId": "4195e8b5-aa3d-41ee-a3d6-11f76288fe59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 394,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NCabin\n",
              "G     14.205000\n",
              "F     18.079367\n",
              "N     19.146674\n",
              "T     35.500000\n",
              "A     41.244314\n",
              "D     53.007339\n",
              "E     54.564634\n",
              "C    107.926598\n",
              "B    122.383078\n",
              "Name: Fare, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 394
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def cabin_estimator(i):\n",
        "    if i<16:\n",
        "        a = \"G\"\n",
        "    elif i<30:\n",
        "        a = \"F\"\n",
        "    elif i<44:\n",
        "        a = \"A\"\n",
        "    elif i<50:\n",
        "        a = \"E\"\n",
        "    elif i<60:\n",
        "        a = \"D\"\n",
        "    elif i<110:\n",
        "        a = 'C'\n",
        "    else:\n",
        "        a = \"B\"\n",
        "    return a\n",
        "df['Cabin'] = df.Fare.apply(lambda x: cabin_estimator(x))"
      ],
      "metadata": {
        "id": "DCRkyIX-rcLx"
      },
      "execution_count": 395,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Family'] = df['SibSp']+df['Parch']\n",
        "df.loc[df['Family'] > 3,'Family'] = 4\n",
        "df['Family'] = df['Family'].astype('string')"
      ],
      "metadata": {
        "id": "0m1cylAVJoGQ"
      },
      "execution_count": 396,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embark_dic = {0:\"C\", 1:\"S\", 2:\"Q\"}\n",
        "df['Embarked'].fillna(df['Embarked'].dropna().mode()[0], inplace=True)\n",
        "for i in range(3):\n",
        "  df.loc[(df['Pclass']==i+1) & (df['Fare'].isnull()),'Fare'] = df[df['Pclass']==i+1]['Fare'].dropna().median()\n",
        "#df['Fare'].fillna(df['Fare'].dropna().median(), inplace=True)\n",
        "#df['Fare'] = df['Fare'].apply(lambda x : classify_fare(x))"
      ],
      "metadata": {
        "id": "kYXA_GzRNPtO"
      },
      "execution_count": 397,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[df['Fare'].isnull()]"
      ],
      "metadata": {
        "id": "3H3OBhI8qlXV",
        "outputId": "ffe82c8a-2670-4634-d567-8a2785f59d14",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "execution_count": 398,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Empty DataFrame\n",
              "Columns: [PassengerId, Pclass, Name, Sex, Age, SibSp, Parch, Ticket, Fare, Cabin, Embarked, Title, NCabin, Family]\n",
              "Index: []"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5750ef93-bf9e-477a-8256-9d8eb6a610fd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Pclass</th>\n",
              "      <th>Name</th>\n",
              "      <th>Sex</th>\n",
              "      <th>Age</th>\n",
              "      <th>SibSp</th>\n",
              "      <th>Parch</th>\n",
              "      <th>Ticket</th>\n",
              "      <th>Fare</th>\n",
              "      <th>Cabin</th>\n",
              "      <th>Embarked</th>\n",
              "      <th>Title</th>\n",
              "      <th>NCabin</th>\n",
              "      <th>Family</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5750ef93-bf9e-477a-8256-9d8eb6a610fd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5750ef93-bf9e-477a-8256-9d8eb6a610fd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5750ef93-bf9e-477a-8256-9d8eb6a610fd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 398
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['Sex'].value_counts()"
      ],
      "metadata": {
        "id": "cmGaxM5rVUqt",
        "outputId": "ec5586c2-ee69-4ec5-b5b9-324fbe522cae",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 399,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "male      843\n",
              "female    466\n",
              "Name: Sex, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 399
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "stscaler.fit(df[['Fare']])\n",
        "scaled = stscaler.transform(df[['Fare']])\n",
        "mmscaler.fit(scaled)\n",
        "output = mmscaler.transform(scaled)\n",
        "output = pd.DataFrame(output, columns=['Fare'])\n",
        "#df['Age'] = output['Age']\n",
        "df['Fare'] = output['Fare']\n",
        "#df['Ncabin'] = df['Ncabin'].astype(int)"
      ],
      "metadata": {
        "id": "Ioau9cMNYHpc"
      },
      "execution_count": 400,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(15,15))\n",
        "plt.subplot(4,2,1)\n",
        "sns.barplot(x='Sex', y='Survived', hue='Pclass', data=df)\n",
        "plt.subplot(4,2,2)\n",
        "sns.barplot(x='Age', y='Survived', hue='Sex', data=df)\n",
        "plt.subplot(4,2,3)\n",
        "sns.scatterplot(x='Age', y='Title', hue='Survived', data=df)\n",
        "plt.subplot(4,2,4)\n",
        "sns.barplot(x='Family', y='Survived', data=df)\n",
        "plt.subplot(4,2,5)\n",
        "sns.scatterplot(x='Embarked', y='Fare',hue='Survived', data=df)\n",
        "plt.subplot(4,2,6)\n",
        "sns.scatterplot(x='Age', y='Fare',hue='Survived', data=df)"
      ],
      "metadata": {
        "id": "qWq7JS54_Yah",
        "outputId": "8463e521-7801-4201-f178-225c7f1b1dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 701
        }
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-108-aa88d3d24143>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Pclass'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Sex'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatterplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Age'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Title'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Survived'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mbarplot\u001b[0;34m(data, x, y, hue, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge, ci, ax, **kwargs)\u001b[0m\n\u001b[1;32m   2753\u001b[0m         \u001b[0mestimator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"size\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2755\u001b[0;31m     plotter = _BarPlotter(x, y, hue, data, order, hue_order,\n\u001b[0m\u001b[1;32m   2756\u001b[0m                           \u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2757\u001b[0m                           \u001b[0morient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, hue, data, order, hue_order, estimator, errorbar, n_boot, units, seed, orient, color, palette, saturation, width, errcolor, errwidth, capsize, dodge)\u001b[0m\n\u001b[1;32m   1531\u001b[0m                                  order, hue_order, units)\n\u001b[1;32m   1532\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestablish_colors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaturation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1533\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimate_statistic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorbar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_boot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1534\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1535\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdodge\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdodge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/categorical.py\u001b[0m in \u001b[0;36mestimate_statistic\u001b[0;34m(self, estimator, errorbar, n_boot, seed)\u001b[0m\n\u001b[1;32m   1482\u001b[0m                         \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"units\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_units\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhue_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1483\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1484\u001b[0;31m                     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1485\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1486\u001b[0m                     \u001b[0mstatistic\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/_statistics.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, data, var)\u001b[0m\n\u001b[1;32m    511\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_method\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"ci\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m             \u001b[0munits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"units\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 513\u001b[0;31m             \u001b[0mboots\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboot_kws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    514\u001b[0m             \u001b[0merr_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_percentile_interval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboots\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror_level\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/seaborn/algorithms.py\u001b[0m in \u001b[0;36mbootstrap\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0mresampler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mintegers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintp\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# intp is indexing dtype\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresampler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 98\u001b[0;31m         \u001b[0mboot_dist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     99\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboot_dist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/overrides.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mmean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m   3472\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3474\u001b[0;31m     return _methods._mean(a, axis=axis, dtype=dtype,\n\u001b[0m\u001b[1;32m   3475\u001b[0m                           out=out, **kwargs)\n\u001b[1;32m   3476\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_mean\u001b[0;34m(a, axis, dtype, out, keepdims, where)\u001b[0m\n\u001b[1;32m    165\u001b[0m     \u001b[0mis_float16_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 167\u001b[0;31m     \u001b[0mrcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_count_reduce_items\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhere\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mwhere\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mumr_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrcount\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Mean of empty slice.\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeWarning\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/numpy/core/_methods.py\u001b[0m in \u001b[0;36m_count_reduce_items\u001b[0;34m(arr, axis, keepdims, where)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0;31m# no boolean mask given, calculate items according to axis\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1500x1500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['PassengerId','Name', 'Ticket', 'SibSp','Parch'],axis=1,inplace=True)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "-gxTDT9y9HZa",
        "outputId": "78064d5b-0579-48d4-cfbc-38c5bcf6f3a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 401,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 417\n",
            "Data columns (total 9 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Pclass    1309 non-null   string \n",
            " 1   Sex       1309 non-null   object \n",
            " 2   Age       1309 non-null   object \n",
            " 3   Fare      1309 non-null   float64\n",
            " 4   Cabin     1309 non-null   object \n",
            " 5   Embarked  1309 non-null   object \n",
            " 6   Title     1309 non-null   object \n",
            " 7   NCabin    1309 non-null   object \n",
            " 8   Family    1309 non-null   string \n",
            "dtypes: float64(1), object(6), string(2)\n",
            "memory usage: 102.3+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.drop(['NCabin','Embarked', 'Sex'],axis=1,inplace=True)"
      ],
      "metadata": {
        "id": "RX_hxMnNdnjJ"
      },
      "execution_count": 402,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#data = ['Pclass','Sex','Embarked','Title','Ncabin','Family']\n",
        "data= ['Pclass','Sex','Family','Age']\n",
        "for column in data:\n",
        "  le = LabelEncoder()\n",
        "  le = le.fit(df[column])\n",
        "  df[column] = le.transform(df[column])\n",
        "me = MinMaxScaler()\n",
        "me = me.fit(df[data])\n",
        "df[data] = me.transform(df[data])"
      ],
      "metadata": {
        "id": "UWPe25zmjvKY"
      },
      "execution_count": 236,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "FYavK7MTJTjM",
        "outputId": "d8f7f461-bd87-4013-8db1-b2f301fa6bd4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 372,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 891 entries, 0 to 890\n",
            "Data columns (total 7 columns):\n",
            " #   Column    Non-Null Count  Dtype  \n",
            "---  ------    --------------  -----  \n",
            " 0   Survived  891 non-null    int64  \n",
            " 1   Pclass    891 non-null    string \n",
            " 2   Age       891 non-null    object \n",
            " 3   Fare      891 non-null    float64\n",
            " 4   Cabin     891 non-null    object \n",
            " 5   Title     891 non-null    object \n",
            " 6   Family    891 non-null    string \n",
            "dtypes: float64(1), int64(1), object(3), string(2)\n",
            "memory usage: 48.9+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Survive = df.iloc[:,0]\n",
        "#df = pd.get_dummies(df.iloc[:,1:])\n",
        "df = pd.get_dummies(df,drop_first=True)\n",
        "#df = pd.concat([Survive, df],axis=1)\n",
        "df.info()"
      ],
      "metadata": {
        "id": "toWyAxMBQaSP",
        "outputId": "a79a088e-c779-433e-88d3-a7aaefa91b69",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 403,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 1309 entries, 0 to 417\n",
            "Data columns (total 23 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   Fare          1309 non-null   float64\n",
            " 1   Pclass_2      1309 non-null   uint8  \n",
            " 2   Pclass_3      1309 non-null   uint8  \n",
            " 3   Age_1         1309 non-null   uint8  \n",
            " 4   Age_2         1309 non-null   uint8  \n",
            " 5   Age_3         1309 non-null   uint8  \n",
            " 6   Age_4         1309 non-null   uint8  \n",
            " 7   Age_5         1309 non-null   uint8  \n",
            " 8   Age_6         1309 non-null   uint8  \n",
            " 9   Cabin_B       1309 non-null   uint8  \n",
            " 10  Cabin_C       1309 non-null   uint8  \n",
            " 11  Cabin_D       1309 non-null   uint8  \n",
            " 12  Cabin_E       1309 non-null   uint8  \n",
            " 13  Cabin_F       1309 non-null   uint8  \n",
            " 14  Cabin_G       1309 non-null   uint8  \n",
            " 15  Title_Master  1309 non-null   uint8  \n",
            " 16  Title_Miss    1309 non-null   uint8  \n",
            " 17  Title_Mr      1309 non-null   uint8  \n",
            " 18  Title_Mrs     1309 non-null   uint8  \n",
            " 19  Family_1      1309 non-null   uint8  \n",
            " 20  Family_2      1309 non-null   uint8  \n",
            " 21  Family_3      1309 non-null   uint8  \n",
            " 22  Family_4      1309 non-null   uint8  \n",
            "dtypes: float64(1), uint8(22)\n",
            "memory usage: 48.6 KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "NHZrK0xdny8Q",
        "outputId": "7c0fbb7b-31a2-4808-d7b7-f3de1aa5428c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 363,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Survived  Pclass_2  Pclass_3  Fare_0  Fare_2  Fare_3  Fare_6  Title_Master  \\\n",
              "0         0         0         1       1       0       0       0             0   \n",
              "1         1         0         0       1       0       0       0             0   \n",
              "2         1         0         1       1       0       0       0             0   \n",
              "3         1         0         0       1       0       0       0             0   \n",
              "4         0         0         1       1       0       0       0             0   \n",
              "\n",
              "   Title_Miss  Title_Mr  Title_Mrs  Family_1  Family_2  Family_3  Family_4  \n",
              "0           0         1          0         1         0         0         0  \n",
              "1           0         0          1         1         0         0         0  \n",
              "2           1         0          0         0         0         0         0  \n",
              "3           0         0          1         1         0         0         0  \n",
              "4           0         1          0         0         0         0         0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d17411bc-245b-42c1-8bad-4767c1b2341c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Survived</th>\n",
              "      <th>Pclass_2</th>\n",
              "      <th>Pclass_3</th>\n",
              "      <th>Fare_0</th>\n",
              "      <th>Fare_2</th>\n",
              "      <th>Fare_3</th>\n",
              "      <th>Fare_6</th>\n",
              "      <th>Title_Master</th>\n",
              "      <th>Title_Miss</th>\n",
              "      <th>Title_Mr</th>\n",
              "      <th>Title_Mrs</th>\n",
              "      <th>Family_1</th>\n",
              "      <th>Family_2</th>\n",
              "      <th>Family_3</th>\n",
              "      <th>Family_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d17411bc-245b-42c1-8bad-4767c1b2341c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d17411bc-245b-42c1-8bad-4767c1b2341c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d17411bc-245b-42c1-8bad-4767c1b2341c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 363
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = df.values\n",
        "X = dataset[:,1:]\n",
        "Y = dataset[:,0]\n",
        "n_fold = 5\n",
        "#X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=3)\n",
        "skf = StratifiedKFold(n_splits=n_fold, shuffle=True, random_state=5)\n",
        "accuracy =[]"
      ],
      "metadata": {
        "id": "A7cSl01Slhbe"
      },
      "execution_count": 404,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "\n",
        "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=50)\n",
        "#history = model.fit(X_train, Y_train, validation_split=0.2, epochs=1000, batch_size=5, verbose=1, \n",
        "#          callbacks=[early_stopping_callback])\n",
        "#model.fit(X, Y, validation_split=0.2, epochs=1000, batch_size=5, verbose=1, \n",
        "#         callbacks=[early_stopping_callback])\n",
        "for train, test in skf.split(X, Y):\n",
        "    model = Sequential()\n",
        "    model.add(Dense(1, input_dim=23, kernel_regularizer=regularizers.l2(0.001), activation='sigmoid'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    #model.add(Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    #model.add(Dense(10, kernel_regularizer=regularizers.l2(0.001), activation='softmax'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    #model.add(Dense(4, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "    #model.add(Dropout(0.25))\n",
        "    #model.add(Dense(1, activation='sigmoid'))\n",
        "    model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "    model.fit(X[train], Y[train], validation_split=0.2, epochs=1000, batch_size=16, callbacks=[early_stopping_callback])\n",
        "    k_accuracy = \"%.4f\" % (model.evaluate(X[test], Y[test])[1])\n",
        "    accuracy.append(float(k_accuracy))\n",
        "print(\"\\n %.f fold mean accuracy:\" % n_fold, sum(accuracy)/n_fold)"
      ],
      "metadata": {
        "id": "g6bwLrKGmZPb",
        "outputId": "a3b9d1df-fdae-42fe-82d5-ce7935ca4aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 381,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8260 - val_loss: 0.3987 - val_accuracy: 0.8462\n",
            "Epoch 225/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8260 - val_loss: 0.3988 - val_accuracy: 0.8462\n",
            "Epoch 226/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4296 - accuracy: 0.8260 - val_loss: 0.3988 - val_accuracy: 0.8462\n",
            "Epoch 227/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8260 - val_loss: 0.3985 - val_accuracy: 0.8462\n",
            "Epoch 228/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4296 - accuracy: 0.8260 - val_loss: 0.3985 - val_accuracy: 0.8462\n",
            "Epoch 229/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8260 - val_loss: 0.3984 - val_accuracy: 0.8462\n",
            "Epoch 230/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4297 - accuracy: 0.8260 - val_loss: 0.3983 - val_accuracy: 0.8462\n",
            "Epoch 231/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8260 - val_loss: 0.3983 - val_accuracy: 0.8462\n",
            "Epoch 232/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8260 - val_loss: 0.3981 - val_accuracy: 0.8462\n",
            "Epoch 233/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4295 - accuracy: 0.8260 - val_loss: 0.3982 - val_accuracy: 0.8462\n",
            "Epoch 234/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8260 - val_loss: 0.3981 - val_accuracy: 0.8462\n",
            "Epoch 235/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8260 - val_loss: 0.3983 - val_accuracy: 0.8462\n",
            "Epoch 236/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8260 - val_loss: 0.3981 - val_accuracy: 0.8462\n",
            "Epoch 237/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8260 - val_loss: 0.3981 - val_accuracy: 0.8462\n",
            "Epoch 238/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8260 - val_loss: 0.3979 - val_accuracy: 0.8462\n",
            "Epoch 239/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8260 - val_loss: 0.3982 - val_accuracy: 0.8462\n",
            "Epoch 240/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8260 - val_loss: 0.3980 - val_accuracy: 0.8462\n",
            "Epoch 241/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8260 - val_loss: 0.3979 - val_accuracy: 0.8462\n",
            "Epoch 242/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8260 - val_loss: 0.3978 - val_accuracy: 0.8462\n",
            "Epoch 243/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8260 - val_loss: 0.3980 - val_accuracy: 0.8462\n",
            "Epoch 244/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8260 - val_loss: 0.3976 - val_accuracy: 0.8462\n",
            "Epoch 245/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8260 - val_loss: 0.3976 - val_accuracy: 0.8462\n",
            "Epoch 246/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8260 - val_loss: 0.3976 - val_accuracy: 0.8462\n",
            "Epoch 247/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8260 - val_loss: 0.3976 - val_accuracy: 0.8462\n",
            "Epoch 248/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8260 - val_loss: 0.3977 - val_accuracy: 0.8462\n",
            "Epoch 249/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8260 - val_loss: 0.3974 - val_accuracy: 0.8462\n",
            "Epoch 250/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8260 - val_loss: 0.3975 - val_accuracy: 0.8462\n",
            "Epoch 251/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8260 - val_loss: 0.3974 - val_accuracy: 0.8462\n",
            "Epoch 252/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8260 - val_loss: 0.3976 - val_accuracy: 0.8462\n",
            "Epoch 253/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8260 - val_loss: 0.3975 - val_accuracy: 0.8462\n",
            "Epoch 254/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8260 - val_loss: 0.3971 - val_accuracy: 0.8462\n",
            "Epoch 255/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8260 - val_loss: 0.3973 - val_accuracy: 0.8462\n",
            "Epoch 256/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8260 - val_loss: 0.3973 - val_accuracy: 0.8462\n",
            "Epoch 257/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8260 - val_loss: 0.3971 - val_accuracy: 0.8462\n",
            "Epoch 258/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8278 - val_loss: 0.3973 - val_accuracy: 0.8601\n",
            "Epoch 259/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3970 - val_accuracy: 0.8462\n",
            "Epoch 260/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8260 - val_loss: 0.3968 - val_accuracy: 0.8462\n",
            "Epoch 261/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3969 - val_accuracy: 0.8462\n",
            "Epoch 262/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8260 - val_loss: 0.3968 - val_accuracy: 0.8462\n",
            "Epoch 263/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3968 - val_accuracy: 0.8462\n",
            "Epoch 264/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3967 - val_accuracy: 0.8462\n",
            "Epoch 265/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3967 - val_accuracy: 0.8462\n",
            "Epoch 266/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3967 - val_accuracy: 0.8462\n",
            "Epoch 267/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8260 - val_loss: 0.3967 - val_accuracy: 0.8601\n",
            "Epoch 268/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3966 - val_accuracy: 0.8462\n",
            "Epoch 269/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3966 - val_accuracy: 0.8531\n",
            "Epoch 270/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3966 - val_accuracy: 0.8601\n",
            "Epoch 271/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3964 - val_accuracy: 0.8601\n",
            "Epoch 272/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8260 - val_loss: 0.3963 - val_accuracy: 0.8462\n",
            "Epoch 273/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3965 - val_accuracy: 0.8531\n",
            "Epoch 274/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8260 - val_loss: 0.3964 - val_accuracy: 0.8531\n",
            "Epoch 275/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8260 - val_loss: 0.3964 - val_accuracy: 0.8531\n",
            "Epoch 276/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8260 - val_loss: 0.3963 - val_accuracy: 0.8531\n",
            "Epoch 277/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8260 - val_loss: 0.3963 - val_accuracy: 0.8531\n",
            "Epoch 278/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3963 - val_accuracy: 0.8531\n",
            "Epoch 279/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3961 - val_accuracy: 0.8531\n",
            "Epoch 280/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3963 - val_accuracy: 0.8531\n",
            "Epoch 281/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3963 - val_accuracy: 0.8531\n",
            "Epoch 282/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3960 - val_accuracy: 0.8462\n",
            "Epoch 283/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8260 - val_loss: 0.3962 - val_accuracy: 0.8462\n",
            "Epoch 284/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3960 - val_accuracy: 0.8462\n",
            "Epoch 285/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8260 - val_loss: 0.3961 - val_accuracy: 0.8531\n",
            "Epoch 286/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3960 - val_accuracy: 0.8531\n",
            "Epoch 287/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3961 - val_accuracy: 0.8531\n",
            "Epoch 288/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3959 - val_accuracy: 0.8531\n",
            "Epoch 289/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3961 - val_accuracy: 0.8531\n",
            "Epoch 290/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3961 - val_accuracy: 0.8531\n",
            "Epoch 291/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8260 - val_loss: 0.3959 - val_accuracy: 0.8531\n",
            "Epoch 292/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8260 - val_loss: 0.3958 - val_accuracy: 0.8531\n",
            "Epoch 293/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3962 - val_accuracy: 0.8531\n",
            "Epoch 294/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3959 - val_accuracy: 0.8531\n",
            "Epoch 295/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3958 - val_accuracy: 0.8531\n",
            "Epoch 296/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3959 - val_accuracy: 0.8531\n",
            "Epoch 297/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3959 - val_accuracy: 0.8531\n",
            "Epoch 298/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3959 - val_accuracy: 0.8531\n",
            "Epoch 299/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8260 - val_loss: 0.3960 - val_accuracy: 0.8531\n",
            "Epoch 300/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3957 - val_accuracy: 0.8531\n",
            "Epoch 301/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3960 - val_accuracy: 0.8531\n",
            "Epoch 302/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3960 - val_accuracy: 0.8531\n",
            "Epoch 303/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3956 - val_accuracy: 0.8531\n",
            "Epoch 304/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3957 - val_accuracy: 0.8531\n",
            "Epoch 305/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3958 - val_accuracy: 0.8531\n",
            "Epoch 306/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3956 - val_accuracy: 0.8531\n",
            "Epoch 307/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3956 - val_accuracy: 0.8531\n",
            "Epoch 308/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3955 - val_accuracy: 0.8531\n",
            "Epoch 309/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8260 - val_loss: 0.3958 - val_accuracy: 0.8531\n",
            "Epoch 310/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3955 - val_accuracy: 0.8531\n",
            "Epoch 311/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3956 - val_accuracy: 0.8531\n",
            "Epoch 312/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3955 - val_accuracy: 0.8531\n",
            "Epoch 313/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3957 - val_accuracy: 0.8531\n",
            "Epoch 314/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3953 - val_accuracy: 0.8531\n",
            "Epoch 315/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3954 - val_accuracy: 0.8531\n",
            "Epoch 316/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3953 - val_accuracy: 0.8531\n",
            "Epoch 317/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3952 - val_accuracy: 0.8531\n",
            "Epoch 318/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8278 - val_loss: 0.3954 - val_accuracy: 0.8531\n",
            "Epoch 319/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3954 - val_accuracy: 0.8531\n",
            "Epoch 320/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3951 - val_accuracy: 0.8531\n",
            "Epoch 321/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3949 - val_accuracy: 0.8531\n",
            "Epoch 322/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3953 - val_accuracy: 0.8531\n",
            "Epoch 323/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3953 - val_accuracy: 0.8531\n",
            "Epoch 324/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3951 - val_accuracy: 0.8531\n",
            "Epoch 325/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3951 - val_accuracy: 0.8531\n",
            "Epoch 326/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3951 - val_accuracy: 0.8531\n",
            "Epoch 327/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3950 - val_accuracy: 0.8531\n",
            "Epoch 328/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3951 - val_accuracy: 0.8531\n",
            "Epoch 329/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3950 - val_accuracy: 0.8531\n",
            "Epoch 330/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3951 - val_accuracy: 0.8531\n",
            "Epoch 331/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3949 - val_accuracy: 0.8531\n",
            "Epoch 332/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3949 - val_accuracy: 0.8531\n",
            "Epoch 333/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3948 - val_accuracy: 0.8531\n",
            "Epoch 334/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3950 - val_accuracy: 0.8531\n",
            "Epoch 335/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3951 - val_accuracy: 0.8531\n",
            "Epoch 336/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3951 - val_accuracy: 0.8531\n",
            "Epoch 337/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8260 - val_loss: 0.3950 - val_accuracy: 0.8531\n",
            "Epoch 338/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 339/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3949 - val_accuracy: 0.8531\n",
            "Epoch 340/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 341/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3948 - val_accuracy: 0.8531\n",
            "Epoch 342/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 343/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 344/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3948 - val_accuracy: 0.8531\n",
            "Epoch 345/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 346/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 347/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 348/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 349/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3949 - val_accuracy: 0.8531\n",
            "Epoch 350/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3950 - val_accuracy: 0.8531\n",
            "Epoch 351/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 352/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3948 - val_accuracy: 0.8531\n",
            "Epoch 353/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 354/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 355/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3948 - val_accuracy: 0.8531\n",
            "Epoch 356/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3949 - val_accuracy: 0.8531\n",
            "Epoch 357/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8260 - val_loss: 0.3945 - val_accuracy: 0.8531\n",
            "Epoch 358/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 359/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3947 - val_accuracy: 0.8531\n",
            "Epoch 360/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3948 - val_accuracy: 0.8531\n",
            "Epoch 361/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 362/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
            "Epoch 363/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 364/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 365/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 366/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
            "Epoch 367/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3945 - val_accuracy: 0.8531\n",
            "Epoch 368/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3945 - val_accuracy: 0.8531\n",
            "Epoch 369/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
            "Epoch 370/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3945 - val_accuracy: 0.8531\n",
            "Epoch 371/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
            "Epoch 372/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3943 - val_accuracy: 0.8531\n",
            "Epoch 373/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
            "Epoch 374/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 375/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3942 - val_accuracy: 0.8531\n",
            "Epoch 376/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3942 - val_accuracy: 0.8531\n",
            "Epoch 377/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3943 - val_accuracy: 0.8531\n",
            "Epoch 378/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3943 - val_accuracy: 0.8531\n",
            "Epoch 379/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
            "Epoch 380/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3943 - val_accuracy: 0.8531\n",
            "Epoch 381/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3946 - val_accuracy: 0.8531\n",
            "Epoch 382/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3943 - val_accuracy: 0.8531\n",
            "Epoch 383/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
            "Epoch 384/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3943 - val_accuracy: 0.8531\n",
            "Epoch 385/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3942 - val_accuracy: 0.8531\n",
            "Epoch 386/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3944 - val_accuracy: 0.8531\n",
            "Epoch 387/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3941 - val_accuracy: 0.8531\n",
            "Epoch 388/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3942 - val_accuracy: 0.8531\n",
            "Epoch 389/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3940 - val_accuracy: 0.8531\n",
            "Epoch 390/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3941 - val_accuracy: 0.8531\n",
            "Epoch 391/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3941 - val_accuracy: 0.8531\n",
            "Epoch 392/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 393/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 394/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 395/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3941 - val_accuracy: 0.8531\n",
            "Epoch 396/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 397/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8260 - val_loss: 0.3941 - val_accuracy: 0.8531\n",
            "Epoch 398/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8278 - val_loss: 0.3940 - val_accuracy: 0.8531\n",
            "Epoch 399/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3940 - val_accuracy: 0.8531\n",
            "Epoch 400/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3937 - val_accuracy: 0.8531\n",
            "Epoch 401/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 402/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8260 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 403/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 404/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3940 - val_accuracy: 0.8531\n",
            "Epoch 405/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 406/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 407/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3941 - val_accuracy: 0.8531\n",
            "Epoch 408/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3941 - val_accuracy: 0.8531\n",
            "Epoch 409/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 410/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3942 - val_accuracy: 0.8531\n",
            "Epoch 411/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 412/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3940 - val_accuracy: 0.8531\n",
            "Epoch 413/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 414/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8260 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 415/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3940 - val_accuracy: 0.8531\n",
            "Epoch 416/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 417/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 418/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3937 - val_accuracy: 0.8531\n",
            "Epoch 419/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3939 - val_accuracy: 0.8531\n",
            "Epoch 420/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3936 - val_accuracy: 0.8531\n",
            "Epoch 421/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3936 - val_accuracy: 0.8531\n",
            "Epoch 422/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 423/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 424/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3936 - val_accuracy: 0.8531\n",
            "Epoch 425/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3936 - val_accuracy: 0.8531\n",
            "Epoch 426/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 427/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 428/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8260 - val_loss: 0.3936 - val_accuracy: 0.8531\n",
            "Epoch 429/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 430/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 431/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8278 - val_loss: 0.3938 - val_accuracy: 0.8531\n",
            "Epoch 432/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 433/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3937 - val_accuracy: 0.8531\n",
            "Epoch 434/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 435/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 436/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 437/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 438/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 439/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8260 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 440/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 441/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 442/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 443/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 444/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 445/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 446/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 447/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 448/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 449/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 450/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 451/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8260 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 452/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 453/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 454/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 455/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 456/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 457/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 458/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 459/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4280 - accuracy: 0.8260 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 460/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 461/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 462/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 463/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3936 - val_accuracy: 0.8531\n",
            "Epoch 464/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 465/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 466/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 467/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8260 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 468/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3935 - val_accuracy: 0.8531\n",
            "Epoch 469/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3934 - val_accuracy: 0.8531\n",
            "Epoch 470/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 471/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 472/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8260 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 473/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8260 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 474/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 475/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 476/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 477/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 478/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8295 - val_loss: 0.3936 - val_accuracy: 0.8531\n",
            "Epoch 479/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 480/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 481/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 482/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 483/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 484/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 485/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 486/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 487/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 488/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8260 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 489/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 490/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 491/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 492/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 493/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 494/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 495/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 496/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 497/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 498/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 499/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 500/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 501/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 502/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 503/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 504/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 505/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 506/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 507/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 508/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3932 - val_accuracy: 0.8531\n",
            "Epoch 509/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 510/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 511/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8278 - val_loss: 0.3933 - val_accuracy: 0.8531\n",
            "Epoch 512/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 513/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 514/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 515/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 516/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 517/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 518/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 519/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 520/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 521/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 522/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 523/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 524/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 525/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 526/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 527/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 528/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 529/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 530/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 531/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 532/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 533/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 534/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 535/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 536/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 537/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 538/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 539/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 540/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8260 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 541/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 542/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 543/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 544/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 545/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 546/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 547/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 548/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 549/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 550/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 551/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 552/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 553/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 554/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 555/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 556/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 557/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 558/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 559/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3930 - val_accuracy: 0.8531\n",
            "Epoch 560/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 561/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 562/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 563/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 564/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3931 - val_accuracy: 0.8531\n",
            "Epoch 565/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 566/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 567/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 568/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 569/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 570/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 571/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 572/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 573/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3929 - val_accuracy: 0.8531\n",
            "Epoch 574/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 575/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 576/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 577/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3924 - val_accuracy: 0.8531\n",
            "Epoch 578/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3924 - val_accuracy: 0.8531\n",
            "Epoch 579/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 580/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 581/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3923 - val_accuracy: 0.8531\n",
            "Epoch 582/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3924 - val_accuracy: 0.8531\n",
            "Epoch 583/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 584/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3922 - val_accuracy: 0.8531\n",
            "Epoch 585/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 586/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 587/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 588/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 589/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 590/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 591/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 592/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 593/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 594/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 595/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 596/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 597/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 598/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 599/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 600/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 601/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 602/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 603/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 604/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 605/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3924 - val_accuracy: 0.8531\n",
            "Epoch 606/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 607/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3924 - val_accuracy: 0.8531\n",
            "Epoch 608/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3922 - val_accuracy: 0.8531\n",
            "Epoch 609/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 610/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 611/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 612/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 613/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 614/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 615/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 616/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 617/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 618/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 619/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 620/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 621/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 622/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 623/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 624/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 625/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 626/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 627/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3928 - val_accuracy: 0.8531\n",
            "Epoch 628/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 629/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 630/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "Epoch 631/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8278 - val_loss: 0.3927 - val_accuracy: 0.8531\n",
            "Epoch 632/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 633/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3925 - val_accuracy: 0.8531\n",
            "Epoch 634/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8278 - val_loss: 0.3926 - val_accuracy: 0.8531\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7933\n",
            "Epoch 1/1000\n",
            "36/36 [==============================] - 1s 9ms/step - loss: 0.7861 - accuracy: 0.3544 - val_loss: 0.7508 - val_accuracy: 0.3706\n",
            "Epoch 2/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.7551 - accuracy: 0.4526 - val_loss: 0.7223 - val_accuracy: 0.5245\n",
            "Epoch 3/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.7285 - accuracy: 0.4877 - val_loss: 0.6969 - val_accuracy: 0.5944\n",
            "Epoch 4/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.7058 - accuracy: 0.5386 - val_loss: 0.6756 - val_accuracy: 0.6014\n",
            "Epoch 5/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6860 - accuracy: 0.5596 - val_loss: 0.6570 - val_accuracy: 0.6014\n",
            "Epoch 6/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.6687 - accuracy: 0.5702 - val_loss: 0.6415 - val_accuracy: 0.5804\n",
            "Epoch 7/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6539 - accuracy: 0.6175 - val_loss: 0.6264 - val_accuracy: 0.6364\n",
            "Epoch 8/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6404 - accuracy: 0.6474 - val_loss: 0.6142 - val_accuracy: 0.6783\n",
            "Epoch 9/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.6287 - accuracy: 0.6807 - val_loss: 0.6032 - val_accuracy: 0.6923\n",
            "Epoch 10/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.6180 - accuracy: 0.6947 - val_loss: 0.5929 - val_accuracy: 0.7063\n",
            "Epoch 11/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.6083 - accuracy: 0.7018 - val_loss: 0.5844 - val_accuracy: 0.7063\n",
            "Epoch 12/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5997 - accuracy: 0.7070 - val_loss: 0.5753 - val_accuracy: 0.7203\n",
            "Epoch 13/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5914 - accuracy: 0.7140 - val_loss: 0.5679 - val_accuracy: 0.7203\n",
            "Epoch 14/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5840 - accuracy: 0.7175 - val_loss: 0.5611 - val_accuracy: 0.7273\n",
            "Epoch 15/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5771 - accuracy: 0.7193 - val_loss: 0.5546 - val_accuracy: 0.7273\n",
            "Epoch 16/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5707 - accuracy: 0.7140 - val_loss: 0.5482 - val_accuracy: 0.7273\n",
            "Epoch 17/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.5644 - accuracy: 0.7175 - val_loss: 0.5427 - val_accuracy: 0.7413\n",
            "Epoch 18/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5587 - accuracy: 0.7211 - val_loss: 0.5377 - val_accuracy: 0.7413\n",
            "Epoch 19/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5533 - accuracy: 0.7316 - val_loss: 0.5327 - val_accuracy: 0.7483\n",
            "Epoch 20/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.5482 - accuracy: 0.7404 - val_loss: 0.5279 - val_accuracy: 0.7483\n",
            "Epoch 21/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5433 - accuracy: 0.7526 - val_loss: 0.5236 - val_accuracy: 0.7552\n",
            "Epoch 22/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5388 - accuracy: 0.7579 - val_loss: 0.5191 - val_accuracy: 0.7552\n",
            "Epoch 23/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5344 - accuracy: 0.7596 - val_loss: 0.5153 - val_accuracy: 0.7622\n",
            "Epoch 24/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.5302 - accuracy: 0.7649 - val_loss: 0.5115 - val_accuracy: 0.7692\n",
            "Epoch 25/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5264 - accuracy: 0.7632 - val_loss: 0.5084 - val_accuracy: 0.7692\n",
            "Epoch 26/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5226 - accuracy: 0.7702 - val_loss: 0.5050 - val_accuracy: 0.7692\n",
            "Epoch 27/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5190 - accuracy: 0.7719 - val_loss: 0.5016 - val_accuracy: 0.7692\n",
            "Epoch 28/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5156 - accuracy: 0.7772 - val_loss: 0.4987 - val_accuracy: 0.7762\n",
            "Epoch 29/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5123 - accuracy: 0.7825 - val_loss: 0.4960 - val_accuracy: 0.7762\n",
            "Epoch 30/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7895 - val_loss: 0.4932 - val_accuracy: 0.7762\n",
            "Epoch 31/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5063 - accuracy: 0.7860 - val_loss: 0.4906 - val_accuracy: 0.7762\n",
            "Epoch 32/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5035 - accuracy: 0.7912 - val_loss: 0.4882 - val_accuracy: 0.7692\n",
            "Epoch 33/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5009 - accuracy: 0.7860 - val_loss: 0.4861 - val_accuracy: 0.7692\n",
            "Epoch 34/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4984 - accuracy: 0.8053 - val_loss: 0.4838 - val_accuracy: 0.7692\n",
            "Epoch 35/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4959 - accuracy: 0.8070 - val_loss: 0.4817 - val_accuracy: 0.7762\n",
            "Epoch 36/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4936 - accuracy: 0.8070 - val_loss: 0.4798 - val_accuracy: 0.7832\n",
            "Epoch 37/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4913 - accuracy: 0.8088 - val_loss: 0.4780 - val_accuracy: 0.7902\n",
            "Epoch 38/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4891 - accuracy: 0.8123 - val_loss: 0.4761 - val_accuracy: 0.7902\n",
            "Epoch 39/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.8140 - val_loss: 0.4742 - val_accuracy: 0.7902\n",
            "Epoch 40/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4852 - accuracy: 0.8140 - val_loss: 0.4727 - val_accuracy: 0.7902\n",
            "Epoch 41/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.8140 - val_loss: 0.4712 - val_accuracy: 0.7902\n",
            "Epoch 42/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4816 - accuracy: 0.8140 - val_loss: 0.4695 - val_accuracy: 0.7902\n",
            "Epoch 43/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4798 - accuracy: 0.8158 - val_loss: 0.4682 - val_accuracy: 0.7902\n",
            "Epoch 44/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4782 - accuracy: 0.8158 - val_loss: 0.4670 - val_accuracy: 0.7972\n",
            "Epoch 45/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.8175 - val_loss: 0.4657 - val_accuracy: 0.7972\n",
            "Epoch 46/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.8175 - val_loss: 0.4644 - val_accuracy: 0.8112\n",
            "Epoch 47/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4737 - accuracy: 0.8211 - val_loss: 0.4634 - val_accuracy: 0.8182\n",
            "Epoch 48/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.8193 - val_loss: 0.4622 - val_accuracy: 0.8182\n",
            "Epoch 49/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4710 - accuracy: 0.8193 - val_loss: 0.4612 - val_accuracy: 0.8182\n",
            "Epoch 50/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4696 - accuracy: 0.8193 - val_loss: 0.4602 - val_accuracy: 0.8252\n",
            "Epoch 51/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.8193 - val_loss: 0.4592 - val_accuracy: 0.8322\n",
            "Epoch 52/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4673 - accuracy: 0.8175 - val_loss: 0.4584 - val_accuracy: 0.8252\n",
            "Epoch 53/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4661 - accuracy: 0.8175 - val_loss: 0.4573 - val_accuracy: 0.8252\n",
            "Epoch 54/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4650 - accuracy: 0.8175 - val_loss: 0.4565 - val_accuracy: 0.8252\n",
            "Epoch 55/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.8175 - val_loss: 0.4558 - val_accuracy: 0.8252\n",
            "Epoch 56/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4631 - accuracy: 0.8175 - val_loss: 0.4550 - val_accuracy: 0.8252\n",
            "Epoch 57/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4619 - accuracy: 0.8175 - val_loss: 0.4542 - val_accuracy: 0.8252\n",
            "Epoch 58/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4610 - accuracy: 0.8175 - val_loss: 0.4533 - val_accuracy: 0.8252\n",
            "Epoch 59/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.8175 - val_loss: 0.4527 - val_accuracy: 0.8252\n",
            "Epoch 60/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4592 - accuracy: 0.8193 - val_loss: 0.4523 - val_accuracy: 0.8252\n",
            "Epoch 61/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8193 - val_loss: 0.4515 - val_accuracy: 0.8252\n",
            "Epoch 62/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4576 - accuracy: 0.8193 - val_loss: 0.4509 - val_accuracy: 0.8252\n",
            "Epoch 63/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4567 - accuracy: 0.8193 - val_loss: 0.4503 - val_accuracy: 0.8252\n",
            "Epoch 64/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.8193 - val_loss: 0.4497 - val_accuracy: 0.8252\n",
            "Epoch 65/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.8193 - val_loss: 0.4492 - val_accuracy: 0.8252\n",
            "Epoch 66/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4546 - accuracy: 0.8193 - val_loss: 0.4487 - val_accuracy: 0.8252\n",
            "Epoch 67/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4540 - accuracy: 0.8193 - val_loss: 0.4481 - val_accuracy: 0.8252\n",
            "Epoch 68/1000\n",
            "36/36 [==============================] - 0s 11ms/step - loss: 0.4534 - accuracy: 0.8193 - val_loss: 0.4479 - val_accuracy: 0.8252\n",
            "Epoch 69/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4527 - accuracy: 0.8193 - val_loss: 0.4473 - val_accuracy: 0.8252\n",
            "Epoch 70/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.8193 - val_loss: 0.4469 - val_accuracy: 0.8252\n",
            "Epoch 71/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4515 - accuracy: 0.8193 - val_loss: 0.4464 - val_accuracy: 0.8252\n",
            "Epoch 72/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.8193 - val_loss: 0.4459 - val_accuracy: 0.8252\n",
            "Epoch 73/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.8193 - val_loss: 0.4455 - val_accuracy: 0.8252\n",
            "Epoch 74/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4498 - accuracy: 0.8211 - val_loss: 0.4453 - val_accuracy: 0.8252\n",
            "Epoch 75/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8211 - val_loss: 0.4449 - val_accuracy: 0.8182\n",
            "Epoch 76/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.8211 - val_loss: 0.4446 - val_accuracy: 0.8182\n",
            "Epoch 77/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.8211 - val_loss: 0.4442 - val_accuracy: 0.8182\n",
            "Epoch 78/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.8211 - val_loss: 0.4439 - val_accuracy: 0.8182\n",
            "Epoch 79/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.8211 - val_loss: 0.4437 - val_accuracy: 0.8182\n",
            "Epoch 80/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.8211 - val_loss: 0.4433 - val_accuracy: 0.8182\n",
            "Epoch 81/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4465 - accuracy: 0.8246 - val_loss: 0.4430 - val_accuracy: 0.8182\n",
            "Epoch 82/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4462 - accuracy: 0.8263 - val_loss: 0.4427 - val_accuracy: 0.8182\n",
            "Epoch 83/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8263 - val_loss: 0.4423 - val_accuracy: 0.8182\n",
            "Epoch 84/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4453 - accuracy: 0.8263 - val_loss: 0.4420 - val_accuracy: 0.8182\n",
            "Epoch 85/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8263 - val_loss: 0.4420 - val_accuracy: 0.8182\n",
            "Epoch 86/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8263 - val_loss: 0.4417 - val_accuracy: 0.8182\n",
            "Epoch 87/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.8263 - val_loss: 0.4415 - val_accuracy: 0.8182\n",
            "Epoch 88/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8263 - val_loss: 0.4413 - val_accuracy: 0.8182\n",
            "Epoch 89/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8263 - val_loss: 0.4410 - val_accuracy: 0.8182\n",
            "Epoch 90/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4433 - accuracy: 0.8263 - val_loss: 0.4407 - val_accuracy: 0.8182\n",
            "Epoch 91/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8263 - val_loss: 0.4405 - val_accuracy: 0.8182\n",
            "Epoch 92/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8263 - val_loss: 0.4403 - val_accuracy: 0.8252\n",
            "Epoch 93/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8281 - val_loss: 0.4403 - val_accuracy: 0.8252\n",
            "Epoch 94/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8281 - val_loss: 0.4400 - val_accuracy: 0.8252\n",
            "Epoch 95/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8281 - val_loss: 0.4399 - val_accuracy: 0.8252\n",
            "Epoch 96/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8281 - val_loss: 0.4396 - val_accuracy: 0.8252\n",
            "Epoch 97/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8281 - val_loss: 0.4394 - val_accuracy: 0.8252\n",
            "Epoch 98/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8281 - val_loss: 0.4393 - val_accuracy: 0.8252\n",
            "Epoch 99/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8281 - val_loss: 0.4392 - val_accuracy: 0.8252\n",
            "Epoch 100/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8281 - val_loss: 0.4390 - val_accuracy: 0.8252\n",
            "Epoch 101/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8298 - val_loss: 0.4388 - val_accuracy: 0.8252\n",
            "Epoch 102/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8298 - val_loss: 0.4388 - val_accuracy: 0.8252\n",
            "Epoch 103/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4397 - accuracy: 0.8298 - val_loss: 0.4385 - val_accuracy: 0.8252\n",
            "Epoch 104/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4394 - accuracy: 0.8298 - val_loss: 0.4384 - val_accuracy: 0.8252\n",
            "Epoch 105/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4393 - accuracy: 0.8298 - val_loss: 0.4382 - val_accuracy: 0.8252\n",
            "Epoch 106/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4391 - accuracy: 0.8281 - val_loss: 0.4381 - val_accuracy: 0.8252\n",
            "Epoch 107/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4388 - accuracy: 0.8281 - val_loss: 0.4378 - val_accuracy: 0.8252\n",
            "Epoch 108/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.8281 - val_loss: 0.4377 - val_accuracy: 0.8252\n",
            "Epoch 109/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8281 - val_loss: 0.4376 - val_accuracy: 0.8252\n",
            "Epoch 110/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4383 - accuracy: 0.8281 - val_loss: 0.4375 - val_accuracy: 0.8252\n",
            "Epoch 111/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4383 - accuracy: 0.8281 - val_loss: 0.4374 - val_accuracy: 0.8252\n",
            "Epoch 112/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4379 - accuracy: 0.8281 - val_loss: 0.4373 - val_accuracy: 0.8252\n",
            "Epoch 113/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4377 - accuracy: 0.8281 - val_loss: 0.4371 - val_accuracy: 0.8252\n",
            "Epoch 114/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4376 - accuracy: 0.8281 - val_loss: 0.4369 - val_accuracy: 0.8252\n",
            "Epoch 115/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8281 - val_loss: 0.4367 - val_accuracy: 0.8252\n",
            "Epoch 116/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4374 - accuracy: 0.8281 - val_loss: 0.4367 - val_accuracy: 0.8252\n",
            "Epoch 117/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4371 - accuracy: 0.8281 - val_loss: 0.4367 - val_accuracy: 0.8252\n",
            "Epoch 118/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8281 - val_loss: 0.4365 - val_accuracy: 0.8252\n",
            "Epoch 119/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4367 - accuracy: 0.8281 - val_loss: 0.4365 - val_accuracy: 0.8252\n",
            "Epoch 120/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4366 - accuracy: 0.8281 - val_loss: 0.4364 - val_accuracy: 0.8252\n",
            "Epoch 121/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4365 - accuracy: 0.8281 - val_loss: 0.4361 - val_accuracy: 0.8252\n",
            "Epoch 122/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4363 - accuracy: 0.8281 - val_loss: 0.4360 - val_accuracy: 0.8252\n",
            "Epoch 123/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4361 - accuracy: 0.8281 - val_loss: 0.4358 - val_accuracy: 0.8252\n",
            "Epoch 124/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8281 - val_loss: 0.4358 - val_accuracy: 0.8252\n",
            "Epoch 125/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4360 - accuracy: 0.8281 - val_loss: 0.4356 - val_accuracy: 0.8252\n",
            "Epoch 126/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4358 - accuracy: 0.8281 - val_loss: 0.4355 - val_accuracy: 0.8252\n",
            "Epoch 127/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8281 - val_loss: 0.4356 - val_accuracy: 0.8252\n",
            "Epoch 128/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4356 - accuracy: 0.8316 - val_loss: 0.4355 - val_accuracy: 0.8322\n",
            "Epoch 129/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4354 - accuracy: 0.8281 - val_loss: 0.4354 - val_accuracy: 0.8252\n",
            "Epoch 130/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4352 - accuracy: 0.8316 - val_loss: 0.4353 - val_accuracy: 0.8322\n",
            "Epoch 131/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4351 - accuracy: 0.8316 - val_loss: 0.4352 - val_accuracy: 0.8322\n",
            "Epoch 132/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4353 - accuracy: 0.8281 - val_loss: 0.4350 - val_accuracy: 0.8322\n",
            "Epoch 133/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4349 - accuracy: 0.8316 - val_loss: 0.4351 - val_accuracy: 0.8322\n",
            "Epoch 134/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4350 - accuracy: 0.8316 - val_loss: 0.4352 - val_accuracy: 0.8322\n",
            "Epoch 135/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8298 - val_loss: 0.4350 - val_accuracy: 0.8322\n",
            "Epoch 136/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4346 - accuracy: 0.8281 - val_loss: 0.4349 - val_accuracy: 0.8252\n",
            "Epoch 137/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4347 - accuracy: 0.8298 - val_loss: 0.4347 - val_accuracy: 0.8322\n",
            "Epoch 138/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4344 - accuracy: 0.8298 - val_loss: 0.4347 - val_accuracy: 0.8252\n",
            "Epoch 139/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4343 - accuracy: 0.8281 - val_loss: 0.4344 - val_accuracy: 0.8252\n",
            "Epoch 140/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4342 - accuracy: 0.8281 - val_loss: 0.4345 - val_accuracy: 0.8252\n",
            "Epoch 141/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4341 - accuracy: 0.8281 - val_loss: 0.4345 - val_accuracy: 0.8252\n",
            "Epoch 142/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.8281 - val_loss: 0.4345 - val_accuracy: 0.8252\n",
            "Epoch 143/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4339 - accuracy: 0.8281 - val_loss: 0.4345 - val_accuracy: 0.8252\n",
            "Epoch 144/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4340 - accuracy: 0.8281 - val_loss: 0.4342 - val_accuracy: 0.8252\n",
            "Epoch 145/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8281 - val_loss: 0.4340 - val_accuracy: 0.8252\n",
            "Epoch 146/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8281 - val_loss: 0.4341 - val_accuracy: 0.8252\n",
            "Epoch 147/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4337 - accuracy: 0.8281 - val_loss: 0.4340 - val_accuracy: 0.8252\n",
            "Epoch 148/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8281 - val_loss: 0.4339 - val_accuracy: 0.8252\n",
            "Epoch 149/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4335 - accuracy: 0.8281 - val_loss: 0.4339 - val_accuracy: 0.8252\n",
            "Epoch 150/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4333 - accuracy: 0.8281 - val_loss: 0.4338 - val_accuracy: 0.8252\n",
            "Epoch 151/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8281 - val_loss: 0.4337 - val_accuracy: 0.8252\n",
            "Epoch 152/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4334 - accuracy: 0.8281 - val_loss: 0.4337 - val_accuracy: 0.8252\n",
            "Epoch 153/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4331 - accuracy: 0.8281 - val_loss: 0.4334 - val_accuracy: 0.8252\n",
            "Epoch 154/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4330 - accuracy: 0.8281 - val_loss: 0.4334 - val_accuracy: 0.8252\n",
            "Epoch 155/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.8281 - val_loss: 0.4335 - val_accuracy: 0.8252\n",
            "Epoch 156/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.8281 - val_loss: 0.4335 - val_accuracy: 0.8252\n",
            "Epoch 157/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4328 - accuracy: 0.8281 - val_loss: 0.4333 - val_accuracy: 0.8252\n",
            "Epoch 158/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.8281 - val_loss: 0.4333 - val_accuracy: 0.8252\n",
            "Epoch 159/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4327 - accuracy: 0.8281 - val_loss: 0.4333 - val_accuracy: 0.8252\n",
            "Epoch 160/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4327 - accuracy: 0.8281 - val_loss: 0.4333 - val_accuracy: 0.8252\n",
            "Epoch 161/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4325 - accuracy: 0.8281 - val_loss: 0.4331 - val_accuracy: 0.8252\n",
            "Epoch 162/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4324 - accuracy: 0.8281 - val_loss: 0.4330 - val_accuracy: 0.8252\n",
            "Epoch 163/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4324 - accuracy: 0.8281 - val_loss: 0.4330 - val_accuracy: 0.8252\n",
            "Epoch 164/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4323 - accuracy: 0.8281 - val_loss: 0.4330 - val_accuracy: 0.8252\n",
            "Epoch 165/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.8281 - val_loss: 0.4329 - val_accuracy: 0.8252\n",
            "Epoch 166/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4323 - accuracy: 0.8281 - val_loss: 0.4330 - val_accuracy: 0.8252\n",
            "Epoch 167/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8281 - val_loss: 0.4327 - val_accuracy: 0.8252\n",
            "Epoch 168/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4321 - accuracy: 0.8281 - val_loss: 0.4328 - val_accuracy: 0.8252\n",
            "Epoch 169/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8281 - val_loss: 0.4326 - val_accuracy: 0.8252\n",
            "Epoch 170/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4320 - accuracy: 0.8281 - val_loss: 0.4326 - val_accuracy: 0.8252\n",
            "Epoch 171/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8281 - val_loss: 0.4326 - val_accuracy: 0.8252\n",
            "Epoch 172/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4321 - accuracy: 0.8281 - val_loss: 0.4324 - val_accuracy: 0.8252\n",
            "Epoch 173/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4319 - accuracy: 0.8281 - val_loss: 0.4325 - val_accuracy: 0.8252\n",
            "Epoch 174/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8281 - val_loss: 0.4325 - val_accuracy: 0.8252\n",
            "Epoch 175/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8281 - val_loss: 0.4323 - val_accuracy: 0.8252\n",
            "Epoch 176/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4318 - accuracy: 0.8281 - val_loss: 0.4325 - val_accuracy: 0.8252\n",
            "Epoch 177/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4316 - accuracy: 0.8281 - val_loss: 0.4323 - val_accuracy: 0.8252\n",
            "Epoch 178/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4317 - accuracy: 0.8281 - val_loss: 0.4322 - val_accuracy: 0.8252\n",
            "Epoch 179/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4316 - accuracy: 0.8281 - val_loss: 0.4321 - val_accuracy: 0.8252\n",
            "Epoch 180/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8281 - val_loss: 0.4322 - val_accuracy: 0.8252\n",
            "Epoch 181/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4315 - accuracy: 0.8281 - val_loss: 0.4319 - val_accuracy: 0.8252\n",
            "Epoch 182/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8281 - val_loss: 0.4320 - val_accuracy: 0.8252\n",
            "Epoch 183/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8281 - val_loss: 0.4318 - val_accuracy: 0.8252\n",
            "Epoch 184/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4313 - accuracy: 0.8281 - val_loss: 0.4318 - val_accuracy: 0.8252\n",
            "Epoch 185/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8281 - val_loss: 0.4319 - val_accuracy: 0.8252\n",
            "Epoch 186/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4312 - accuracy: 0.8281 - val_loss: 0.4317 - val_accuracy: 0.8252\n",
            "Epoch 187/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4312 - accuracy: 0.8281 - val_loss: 0.4318 - val_accuracy: 0.8252\n",
            "Epoch 188/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8281 - val_loss: 0.4317 - val_accuracy: 0.8252\n",
            "Epoch 189/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8281 - val_loss: 0.4315 - val_accuracy: 0.8252\n",
            "Epoch 190/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4310 - accuracy: 0.8281 - val_loss: 0.4316 - val_accuracy: 0.8252\n",
            "Epoch 191/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8281 - val_loss: 0.4316 - val_accuracy: 0.8252\n",
            "Epoch 192/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8281 - val_loss: 0.4315 - val_accuracy: 0.8252\n",
            "Epoch 193/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8281 - val_loss: 0.4317 - val_accuracy: 0.8252\n",
            "Epoch 194/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8281 - val_loss: 0.4315 - val_accuracy: 0.8252\n",
            "Epoch 195/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8281 - val_loss: 0.4315 - val_accuracy: 0.8252\n",
            "Epoch 196/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.8298 - val_loss: 0.4313 - val_accuracy: 0.8252\n",
            "Epoch 197/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8281 - val_loss: 0.4314 - val_accuracy: 0.8252\n",
            "Epoch 198/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4308 - accuracy: 0.8263 - val_loss: 0.4311 - val_accuracy: 0.8252\n",
            "Epoch 199/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4309 - accuracy: 0.8281 - val_loss: 0.4311 - val_accuracy: 0.8252\n",
            "Epoch 200/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8263 - val_loss: 0.4312 - val_accuracy: 0.8252\n",
            "Epoch 201/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8263 - val_loss: 0.4313 - val_accuracy: 0.8182\n",
            "Epoch 202/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8263 - val_loss: 0.4311 - val_accuracy: 0.8182\n",
            "Epoch 203/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8263 - val_loss: 0.4311 - val_accuracy: 0.8182\n",
            "Epoch 204/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4307 - accuracy: 0.8263 - val_loss: 0.4310 - val_accuracy: 0.8182\n",
            "Epoch 205/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4306 - accuracy: 0.8246 - val_loss: 0.4310 - val_accuracy: 0.8182\n",
            "Epoch 206/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8263 - val_loss: 0.4310 - val_accuracy: 0.8182\n",
            "Epoch 207/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8263 - val_loss: 0.4310 - val_accuracy: 0.8182\n",
            "Epoch 208/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8263 - val_loss: 0.4310 - val_accuracy: 0.8182\n",
            "Epoch 209/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8263 - val_loss: 0.4309 - val_accuracy: 0.8182\n",
            "Epoch 210/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8263 - val_loss: 0.4311 - val_accuracy: 0.8182\n",
            "Epoch 211/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8263 - val_loss: 0.4307 - val_accuracy: 0.8182\n",
            "Epoch 212/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8263 - val_loss: 0.4307 - val_accuracy: 0.8182\n",
            "Epoch 213/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8263 - val_loss: 0.4306 - val_accuracy: 0.8182\n",
            "Epoch 214/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8263 - val_loss: 0.4306 - val_accuracy: 0.8182\n",
            "Epoch 215/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8263 - val_loss: 0.4305 - val_accuracy: 0.8182\n",
            "Epoch 216/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4305 - accuracy: 0.8263 - val_loss: 0.4306 - val_accuracy: 0.8182\n",
            "Epoch 217/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8263 - val_loss: 0.4304 - val_accuracy: 0.8182\n",
            "Epoch 218/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8263 - val_loss: 0.4305 - val_accuracy: 0.8182\n",
            "Epoch 219/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8263 - val_loss: 0.4304 - val_accuracy: 0.8182\n",
            "Epoch 220/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8281 - val_loss: 0.4302 - val_accuracy: 0.8182\n",
            "Epoch 221/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4303 - accuracy: 0.8263 - val_loss: 0.4305 - val_accuracy: 0.8182\n",
            "Epoch 222/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4301 - accuracy: 0.8263 - val_loss: 0.4301 - val_accuracy: 0.8182\n",
            "Epoch 223/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8263 - val_loss: 0.4302 - val_accuracy: 0.8182\n",
            "Epoch 224/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8263 - val_loss: 0.4303 - val_accuracy: 0.8182\n",
            "Epoch 225/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4302 - accuracy: 0.8263 - val_loss: 0.4301 - val_accuracy: 0.8182\n",
            "Epoch 226/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4300 - accuracy: 0.8263 - val_loss: 0.4302 - val_accuracy: 0.8182\n",
            "Epoch 227/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.8263 - val_loss: 0.4300 - val_accuracy: 0.8182\n",
            "Epoch 228/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8263 - val_loss: 0.4302 - val_accuracy: 0.8182\n",
            "Epoch 229/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8263 - val_loss: 0.4302 - val_accuracy: 0.8182\n",
            "Epoch 230/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8263 - val_loss: 0.4301 - val_accuracy: 0.8182\n",
            "Epoch 231/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4299 - accuracy: 0.8263 - val_loss: 0.4300 - val_accuracy: 0.8182\n",
            "Epoch 232/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4299 - accuracy: 0.8263 - val_loss: 0.4299 - val_accuracy: 0.8182\n",
            "Epoch 233/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8263 - val_loss: 0.4299 - val_accuracy: 0.8182\n",
            "Epoch 234/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4298 - accuracy: 0.8263 - val_loss: 0.4299 - val_accuracy: 0.8182\n",
            "Epoch 235/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8263 - val_loss: 0.4301 - val_accuracy: 0.8182\n",
            "Epoch 236/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4299 - accuracy: 0.8263 - val_loss: 0.4298 - val_accuracy: 0.8182\n",
            "Epoch 237/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.8263 - val_loss: 0.4298 - val_accuracy: 0.8182\n",
            "Epoch 238/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8263 - val_loss: 0.4297 - val_accuracy: 0.8182\n",
            "Epoch 239/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4298 - accuracy: 0.8263 - val_loss: 0.4297 - val_accuracy: 0.8182\n",
            "Epoch 240/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8263 - val_loss: 0.4296 - val_accuracy: 0.8182\n",
            "Epoch 241/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4297 - accuracy: 0.8263 - val_loss: 0.4296 - val_accuracy: 0.8182\n",
            "Epoch 242/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8263 - val_loss: 0.4297 - val_accuracy: 0.8182\n",
            "Epoch 243/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4297 - accuracy: 0.8263 - val_loss: 0.4296 - val_accuracy: 0.8182\n",
            "Epoch 244/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.8263 - val_loss: 0.4296 - val_accuracy: 0.8182\n",
            "Epoch 245/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4296 - accuracy: 0.8263 - val_loss: 0.4294 - val_accuracy: 0.8182\n",
            "Epoch 246/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4295 - accuracy: 0.8263 - val_loss: 0.4295 - val_accuracy: 0.8182\n",
            "Epoch 247/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4296 - accuracy: 0.8246 - val_loss: 0.4295 - val_accuracy: 0.8182\n",
            "Epoch 248/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8263 - val_loss: 0.4294 - val_accuracy: 0.8182\n",
            "Epoch 249/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4295 - accuracy: 0.8263 - val_loss: 0.4292 - val_accuracy: 0.8182\n",
            "Epoch 250/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.8263 - val_loss: 0.4293 - val_accuracy: 0.8252\n",
            "Epoch 251/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8246 - val_loss: 0.4293 - val_accuracy: 0.8252\n",
            "Epoch 252/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4297 - accuracy: 0.8246 - val_loss: 0.4290 - val_accuracy: 0.8182\n",
            "Epoch 253/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4295 - accuracy: 0.8246 - val_loss: 0.4292 - val_accuracy: 0.8252\n",
            "Epoch 254/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4294 - accuracy: 0.8246 - val_loss: 0.4291 - val_accuracy: 0.8252\n",
            "Epoch 255/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4294 - accuracy: 0.8246 - val_loss: 0.4292 - val_accuracy: 0.8252\n",
            "Epoch 256/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8246 - val_loss: 0.4292 - val_accuracy: 0.8252\n",
            "Epoch 257/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8246 - val_loss: 0.4291 - val_accuracy: 0.8252\n",
            "Epoch 258/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8228 - val_loss: 0.4293 - val_accuracy: 0.8252\n",
            "Epoch 259/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8246 - val_loss: 0.4293 - val_accuracy: 0.8252\n",
            "Epoch 260/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8228 - val_loss: 0.4292 - val_accuracy: 0.8252\n",
            "Epoch 261/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4294 - accuracy: 0.8228 - val_loss: 0.4292 - val_accuracy: 0.8252\n",
            "Epoch 262/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8246 - val_loss: 0.4290 - val_accuracy: 0.8252\n",
            "Epoch 263/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8228 - val_loss: 0.4290 - val_accuracy: 0.8252\n",
            "Epoch 264/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8228 - val_loss: 0.4288 - val_accuracy: 0.8252\n",
            "Epoch 265/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8228 - val_loss: 0.4289 - val_accuracy: 0.8252\n",
            "Epoch 266/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8228 - val_loss: 0.4289 - val_accuracy: 0.8252\n",
            "Epoch 267/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4292 - accuracy: 0.8228 - val_loss: 0.4290 - val_accuracy: 0.8252\n",
            "Epoch 268/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8228 - val_loss: 0.4289 - val_accuracy: 0.8252\n",
            "Epoch 269/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8228 - val_loss: 0.4288 - val_accuracy: 0.8252\n",
            "Epoch 270/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8228 - val_loss: 0.4288 - val_accuracy: 0.8252\n",
            "Epoch 271/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8228 - val_loss: 0.4288 - val_accuracy: 0.8252\n",
            "Epoch 272/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4287 - val_accuracy: 0.8252\n",
            "Epoch 273/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4287 - val_accuracy: 0.8252\n",
            "Epoch 274/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8252\n",
            "Epoch 275/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4287 - val_accuracy: 0.8252\n",
            "Epoch 276/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4287 - val_accuracy: 0.8252\n",
            "Epoch 277/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4287 - val_accuracy: 0.8252\n",
            "Epoch 278/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4288 - val_accuracy: 0.8252\n",
            "Epoch 279/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4293 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8252\n",
            "Epoch 280/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8252\n",
            "Epoch 281/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4285 - val_accuracy: 0.8252\n",
            "Epoch 282/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4287 - val_accuracy: 0.8252\n",
            "Epoch 283/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8252\n",
            "Epoch 284/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8252\n",
            "Epoch 285/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8252\n",
            "Epoch 286/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4285 - val_accuracy: 0.8252\n",
            "Epoch 287/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4285 - val_accuracy: 0.8252\n",
            "Epoch 288/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4285 - val_accuracy: 0.8252\n",
            "Epoch 289/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4284 - val_accuracy: 0.8252\n",
            "Epoch 290/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4287 - val_accuracy: 0.8252\n",
            "Epoch 291/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4285 - val_accuracy: 0.8252\n",
            "Epoch 292/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4290 - accuracy: 0.8228 - val_loss: 0.4284 - val_accuracy: 0.8252\n",
            "Epoch 293/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4284 - val_accuracy: 0.8252\n",
            "Epoch 294/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4283 - val_accuracy: 0.8252\n",
            "Epoch 295/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8252\n",
            "Epoch 296/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4286 - val_accuracy: 0.8252\n",
            "Epoch 297/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4284 - val_accuracy: 0.8252\n",
            "Epoch 298/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4283 - val_accuracy: 0.8252\n",
            "Epoch 299/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4281 - val_accuracy: 0.8252\n",
            "Epoch 300/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4281 - val_accuracy: 0.8252\n",
            "Epoch 301/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4283 - val_accuracy: 0.8252\n",
            "Epoch 302/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4282 - val_accuracy: 0.8252\n",
            "Epoch 303/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4281 - val_accuracy: 0.8252\n",
            "Epoch 304/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4281 - val_accuracy: 0.8252\n",
            "Epoch 305/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4282 - val_accuracy: 0.8252\n",
            "Epoch 306/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4280 - val_accuracy: 0.8252\n",
            "Epoch 307/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4280 - val_accuracy: 0.8252\n",
            "Epoch 308/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4281 - val_accuracy: 0.8252\n",
            "Epoch 309/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4283 - val_accuracy: 0.8252\n",
            "Epoch 310/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4280 - val_accuracy: 0.8252\n",
            "Epoch 311/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4282 - val_accuracy: 0.8252\n",
            "Epoch 312/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4282 - val_accuracy: 0.8252\n",
            "Epoch 313/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4288 - accuracy: 0.8228 - val_loss: 0.4280 - val_accuracy: 0.8252\n",
            "Epoch 314/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4291 - accuracy: 0.8228 - val_loss: 0.4282 - val_accuracy: 0.8182\n",
            "Epoch 315/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4279 - val_accuracy: 0.8252\n",
            "Epoch 316/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8228 - val_loss: 0.4277 - val_accuracy: 0.8252\n",
            "Epoch 317/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4279 - val_accuracy: 0.8252\n",
            "Epoch 318/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4279 - val_accuracy: 0.8252\n",
            "Epoch 319/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4278 - val_accuracy: 0.8252\n",
            "Epoch 320/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4278 - val_accuracy: 0.8252\n",
            "Epoch 321/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4277 - val_accuracy: 0.8252\n",
            "Epoch 322/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4277 - val_accuracy: 0.8252\n",
            "Epoch 323/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4276 - val_accuracy: 0.8252\n",
            "Epoch 324/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4280 - val_accuracy: 0.8182\n",
            "Epoch 325/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4277 - val_accuracy: 0.8252\n",
            "Epoch 326/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4277 - val_accuracy: 0.8252\n",
            "Epoch 327/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4279 - val_accuracy: 0.8252\n",
            "Epoch 328/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4278 - val_accuracy: 0.8252\n",
            "Epoch 329/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4279 - val_accuracy: 0.8252\n",
            "Epoch 330/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4279 - val_accuracy: 0.8182\n",
            "Epoch 331/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4278 - val_accuracy: 0.8182\n",
            "Epoch 332/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4276 - val_accuracy: 0.8252\n",
            "Epoch 333/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4279 - val_accuracy: 0.8182\n",
            "Epoch 334/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4277 - val_accuracy: 0.8252\n",
            "Epoch 335/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4278 - val_accuracy: 0.8252\n",
            "Epoch 336/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4278 - val_accuracy: 0.8252\n",
            "Epoch 337/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4276 - val_accuracy: 0.8252\n",
            "Epoch 338/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4275 - val_accuracy: 0.8252\n",
            "Epoch 339/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4276 - val_accuracy: 0.8182\n",
            "Epoch 340/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4275 - val_accuracy: 0.8182\n",
            "Epoch 341/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4275 - val_accuracy: 0.8182\n",
            "Epoch 342/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4276 - val_accuracy: 0.8182\n",
            "Epoch 343/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4276 - val_accuracy: 0.8182\n",
            "Epoch 344/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4274 - val_accuracy: 0.8252\n",
            "Epoch 345/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4275 - val_accuracy: 0.8182\n",
            "Epoch 346/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4273 - val_accuracy: 0.8182\n",
            "Epoch 347/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4274 - val_accuracy: 0.8182\n",
            "Epoch 348/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4273 - val_accuracy: 0.8182\n",
            "Epoch 349/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 350/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4273 - val_accuracy: 0.8182\n",
            "Epoch 351/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 352/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8252\n",
            "Epoch 353/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 354/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 355/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 356/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4273 - val_accuracy: 0.8182\n",
            "Epoch 357/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4285 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 358/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 359/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 360/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8228 - val_loss: 0.4276 - val_accuracy: 0.8182\n",
            "Epoch 361/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 362/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 363/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 364/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 365/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 366/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 367/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 368/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 369/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4284 - accuracy: 0.8228 - val_loss: 0.4269 - val_accuracy: 0.8182\n",
            "Epoch 370/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 371/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4273 - val_accuracy: 0.8182\n",
            "Epoch 372/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 373/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 374/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4273 - val_accuracy: 0.8182\n",
            "Epoch 375/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4273 - val_accuracy: 0.8182\n",
            "Epoch 376/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 377/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 378/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 379/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4269 - val_accuracy: 0.8182\n",
            "Epoch 380/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 381/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 382/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 383/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 384/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 385/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 386/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 387/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 388/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 389/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 390/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 391/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4269 - val_accuracy: 0.8182\n",
            "Epoch 392/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4269 - val_accuracy: 0.8182\n",
            "Epoch 393/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4271 - val_accuracy: 0.8182\n",
            "Epoch 394/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8228 - val_loss: 0.4272 - val_accuracy: 0.8182\n",
            "Epoch 395/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4269 - val_accuracy: 0.8182\n",
            "Epoch 396/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8228 - val_loss: 0.4269 - val_accuracy: 0.8182\n",
            "Epoch 397/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4267 - val_accuracy: 0.8182\n",
            "Epoch 398/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 399/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 400/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 401/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4267 - val_accuracy: 0.8182\n",
            "Epoch 402/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 403/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 404/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4266 - val_accuracy: 0.8182\n",
            "Epoch 405/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4266 - val_accuracy: 0.8182\n",
            "Epoch 406/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 407/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4267 - val_accuracy: 0.8182\n",
            "Epoch 408/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 409/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 410/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 411/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 412/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4267 - val_accuracy: 0.8182\n",
            "Epoch 413/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 414/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4267 - val_accuracy: 0.8182\n",
            "Epoch 415/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 416/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 417/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4267 - val_accuracy: 0.8182\n",
            "Epoch 418/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4267 - val_accuracy: 0.8182\n",
            "Epoch 419/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4266 - val_accuracy: 0.8182\n",
            "Epoch 420/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 421/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4268 - val_accuracy: 0.8182\n",
            "Epoch 422/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4282 - accuracy: 0.8228 - val_loss: 0.4266 - val_accuracy: 0.8182\n",
            "Epoch 423/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4269 - val_accuracy: 0.8182\n",
            "Epoch 424/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4266 - val_accuracy: 0.8182\n",
            "Epoch 425/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 426/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 427/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4266 - val_accuracy: 0.8182\n",
            "Epoch 428/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 429/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4266 - val_accuracy: 0.8182\n",
            "Epoch 430/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
            "Epoch 431/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 432/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 433/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4263 - val_accuracy: 0.8182\n",
            "Epoch 434/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
            "Epoch 435/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 436/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8228 - val_loss: 0.4263 - val_accuracy: 0.8182\n",
            "Epoch 437/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8246 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
            "Epoch 438/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8228 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 439/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8246 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 440/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8246 - val_loss: 0.4263 - val_accuracy: 0.8182\n",
            "Epoch 441/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8246 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
            "Epoch 442/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8246 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 443/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 444/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8246 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 445/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
            "Epoch 446/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 447/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8263 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 448/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8263 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
            "Epoch 449/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 450/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4263 - val_accuracy: 0.8182\n",
            "Epoch 451/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 452/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 453/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 454/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
            "Epoch 455/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 456/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 457/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4263 - val_accuracy: 0.8182\n",
            "Epoch 458/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 459/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4263 - val_accuracy: 0.8182\n",
            "Epoch 460/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4264 - val_accuracy: 0.8182\n",
            "Epoch 461/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4263 - val_accuracy: 0.8182\n",
            "Epoch 462/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 463/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 464/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 465/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 466/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 467/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 468/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 469/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4281 - accuracy: 0.8263 - val_loss: 0.4263 - val_accuracy: 0.8182\n",
            "Epoch 470/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 471/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 472/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 473/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 474/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 475/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 476/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 477/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 478/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 479/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 480/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 481/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4262 - val_accuracy: 0.8182\n",
            "Epoch 482/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 483/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 484/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 485/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 486/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 487/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 488/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 489/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 490/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 491/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 492/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 493/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 494/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4261 - val_accuracy: 0.8182\n",
            "Epoch 495/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 496/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 497/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 498/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 499/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 500/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 501/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 502/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 503/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 504/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4260 - val_accuracy: 0.8182\n",
            "Epoch 505/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 506/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 507/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 508/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 509/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 510/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4255 - val_accuracy: 0.8182\n",
            "Epoch 511/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 512/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 513/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 514/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 515/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 516/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 517/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 518/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4255 - val_accuracy: 0.8182\n",
            "Epoch 519/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 520/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 521/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 522/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 523/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 524/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 525/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 526/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 527/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 528/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4255 - val_accuracy: 0.8182\n",
            "Epoch 529/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 530/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 531/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 532/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 533/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 534/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 535/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 536/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 537/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4259 - val_accuracy: 0.8182\n",
            "Epoch 538/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 539/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 540/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 541/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 542/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 543/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 544/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 545/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 546/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 547/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 548/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4255 - val_accuracy: 0.8182\n",
            "Epoch 549/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 550/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 551/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 552/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 553/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 554/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 555/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 556/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4255 - val_accuracy: 0.8182\n",
            "Epoch 557/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 558/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 559/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 560/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 561/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 562/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 563/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4255 - val_accuracy: 0.8182\n",
            "Epoch 564/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4276 - accuracy: 0.8263 - val_loss: 0.4257 - val_accuracy: 0.8182\n",
            "Epoch 565/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 566/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4258 - val_accuracy: 0.8182\n",
            "Epoch 567/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 568/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4277 - accuracy: 0.8263 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4518 - accuracy: 0.8090\n",
            "Epoch 1/1000\n",
            "36/36 [==============================] - 1s 10ms/step - loss: 0.6762 - accuracy: 0.6070 - val_loss: 0.6397 - val_accuracy: 0.6573\n",
            "Epoch 2/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6627 - accuracy: 0.6105 - val_loss: 0.6265 - val_accuracy: 0.6643\n",
            "Epoch 3/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6503 - accuracy: 0.6158 - val_loss: 0.6145 - val_accuracy: 0.6713\n",
            "Epoch 4/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6385 - accuracy: 0.6246 - val_loss: 0.6035 - val_accuracy: 0.6783\n",
            "Epoch 5/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.6277 - accuracy: 0.6404 - val_loss: 0.5922 - val_accuracy: 0.6923\n",
            "Epoch 6/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6169 - accuracy: 0.6509 - val_loss: 0.5827 - val_accuracy: 0.6923\n",
            "Epoch 7/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6071 - accuracy: 0.6632 - val_loss: 0.5730 - val_accuracy: 0.7063\n",
            "Epoch 8/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5981 - accuracy: 0.6719 - val_loss: 0.5642 - val_accuracy: 0.7063\n",
            "Epoch 9/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5891 - accuracy: 0.6860 - val_loss: 0.5559 - val_accuracy: 0.7203\n",
            "Epoch 10/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5810 - accuracy: 0.6877 - val_loss: 0.5483 - val_accuracy: 0.7483\n",
            "Epoch 11/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5732 - accuracy: 0.7053 - val_loss: 0.5410 - val_accuracy: 0.7692\n",
            "Epoch 12/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5659 - accuracy: 0.7123 - val_loss: 0.5346 - val_accuracy: 0.7692\n",
            "Epoch 13/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5591 - accuracy: 0.7193 - val_loss: 0.5279 - val_accuracy: 0.7832\n",
            "Epoch 14/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.5526 - accuracy: 0.7333 - val_loss: 0.5217 - val_accuracy: 0.7692\n",
            "Epoch 15/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5466 - accuracy: 0.7421 - val_loss: 0.5160 - val_accuracy: 0.7832\n",
            "Epoch 16/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5408 - accuracy: 0.7421 - val_loss: 0.5106 - val_accuracy: 0.7972\n",
            "Epoch 17/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.5355 - accuracy: 0.7509 - val_loss: 0.5056 - val_accuracy: 0.8182\n",
            "Epoch 18/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5305 - accuracy: 0.7579 - val_loss: 0.5009 - val_accuracy: 0.8322\n",
            "Epoch 19/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5256 - accuracy: 0.7684 - val_loss: 0.4969 - val_accuracy: 0.8252\n",
            "Epoch 20/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5212 - accuracy: 0.7719 - val_loss: 0.4928 - val_accuracy: 0.8322\n",
            "Epoch 21/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5169 - accuracy: 0.7737 - val_loss: 0.4887 - val_accuracy: 0.8322\n",
            "Epoch 22/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5127 - accuracy: 0.7772 - val_loss: 0.4851 - val_accuracy: 0.8322\n",
            "Epoch 23/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5091 - accuracy: 0.7789 - val_loss: 0.4817 - val_accuracy: 0.8252\n",
            "Epoch 24/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5054 - accuracy: 0.7930 - val_loss: 0.4783 - val_accuracy: 0.8252\n",
            "Epoch 25/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5018 - accuracy: 0.7947 - val_loss: 0.4754 - val_accuracy: 0.8322\n",
            "Epoch 26/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4986 - accuracy: 0.7930 - val_loss: 0.4727 - val_accuracy: 0.8322\n",
            "Epoch 27/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.7930 - val_loss: 0.4697 - val_accuracy: 0.8252\n",
            "Epoch 28/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4926 - accuracy: 0.7930 - val_loss: 0.4671 - val_accuracy: 0.8322\n",
            "Epoch 29/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4900 - accuracy: 0.7965 - val_loss: 0.4653 - val_accuracy: 0.8392\n",
            "Epoch 30/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4872 - accuracy: 0.7965 - val_loss: 0.4625 - val_accuracy: 0.8392\n",
            "Epoch 31/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4846 - accuracy: 0.8000 - val_loss: 0.4601 - val_accuracy: 0.8462\n",
            "Epoch 32/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4822 - accuracy: 0.7982 - val_loss: 0.4580 - val_accuracy: 0.8462\n",
            "Epoch 33/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4799 - accuracy: 0.8000 - val_loss: 0.4561 - val_accuracy: 0.8392\n",
            "Epoch 34/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4778 - accuracy: 0.8053 - val_loss: 0.4546 - val_accuracy: 0.8322\n",
            "Epoch 35/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4757 - accuracy: 0.8053 - val_loss: 0.4526 - val_accuracy: 0.8322\n",
            "Epoch 36/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4738 - accuracy: 0.8105 - val_loss: 0.4508 - val_accuracy: 0.8182\n",
            "Epoch 37/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4720 - accuracy: 0.8158 - val_loss: 0.4492 - val_accuracy: 0.8182\n",
            "Epoch 38/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4703 - accuracy: 0.8298 - val_loss: 0.4475 - val_accuracy: 0.8182\n",
            "Epoch 39/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4684 - accuracy: 0.8298 - val_loss: 0.4464 - val_accuracy: 0.8322\n",
            "Epoch 40/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4670 - accuracy: 0.8351 - val_loss: 0.4451 - val_accuracy: 0.8252\n",
            "Epoch 41/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4653 - accuracy: 0.8351 - val_loss: 0.4436 - val_accuracy: 0.8252\n",
            "Epoch 42/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4639 - accuracy: 0.8351 - val_loss: 0.4425 - val_accuracy: 0.8252\n",
            "Epoch 43/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.8351 - val_loss: 0.4413 - val_accuracy: 0.8252\n",
            "Epoch 44/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.8351 - val_loss: 0.4400 - val_accuracy: 0.8252\n",
            "Epoch 45/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.8351 - val_loss: 0.4391 - val_accuracy: 0.8252\n",
            "Epoch 46/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4586 - accuracy: 0.8351 - val_loss: 0.4379 - val_accuracy: 0.8252\n",
            "Epoch 47/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.8351 - val_loss: 0.4366 - val_accuracy: 0.8252\n",
            "Epoch 48/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4563 - accuracy: 0.8351 - val_loss: 0.4358 - val_accuracy: 0.8252\n",
            "Epoch 49/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8368 - val_loss: 0.4353 - val_accuracy: 0.8252\n",
            "Epoch 50/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4542 - accuracy: 0.8368 - val_loss: 0.4344 - val_accuracy: 0.8252\n",
            "Epoch 51/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4531 - accuracy: 0.8368 - val_loss: 0.4335 - val_accuracy: 0.8252\n",
            "Epoch 52/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.8368 - val_loss: 0.4325 - val_accuracy: 0.8252\n",
            "Epoch 53/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8368 - val_loss: 0.4320 - val_accuracy: 0.8252\n",
            "Epoch 54/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4505 - accuracy: 0.8351 - val_loss: 0.4310 - val_accuracy: 0.8252\n",
            "Epoch 55/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8333 - val_loss: 0.4305 - val_accuracy: 0.8252\n",
            "Epoch 56/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8333 - val_loss: 0.4296 - val_accuracy: 0.8252\n",
            "Epoch 57/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4481 - accuracy: 0.8333 - val_loss: 0.4292 - val_accuracy: 0.8252\n",
            "Epoch 58/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4473 - accuracy: 0.8333 - val_loss: 0.4285 - val_accuracy: 0.8252\n",
            "Epoch 59/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.8333 - val_loss: 0.4279 - val_accuracy: 0.8252\n",
            "Epoch 60/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4459 - accuracy: 0.8333 - val_loss: 0.4271 - val_accuracy: 0.8252\n",
            "Epoch 61/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8333 - val_loss: 0.4267 - val_accuracy: 0.8252\n",
            "Epoch 62/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8333 - val_loss: 0.4261 - val_accuracy: 0.8252\n",
            "Epoch 63/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8333 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 64/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4435 - accuracy: 0.8316 - val_loss: 0.4250 - val_accuracy: 0.8182\n",
            "Epoch 65/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8316 - val_loss: 0.4247 - val_accuracy: 0.8182\n",
            "Epoch 66/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8316 - val_loss: 0.4244 - val_accuracy: 0.8182\n",
            "Epoch 67/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.8298 - val_loss: 0.4235 - val_accuracy: 0.8182\n",
            "Epoch 68/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8316 - val_loss: 0.4236 - val_accuracy: 0.8182\n",
            "Epoch 69/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8316 - val_loss: 0.4230 - val_accuracy: 0.8182\n",
            "Epoch 70/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8298 - val_loss: 0.4225 - val_accuracy: 0.8182\n",
            "Epoch 71/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4400 - accuracy: 0.8316 - val_loss: 0.4224 - val_accuracy: 0.8182\n",
            "Epoch 72/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4396 - accuracy: 0.8298 - val_loss: 0.4218 - val_accuracy: 0.8182\n",
            "Epoch 73/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4391 - accuracy: 0.8316 - val_loss: 0.4213 - val_accuracy: 0.8182\n",
            "Epoch 74/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4386 - accuracy: 0.8298 - val_loss: 0.4211 - val_accuracy: 0.8182\n",
            "Epoch 75/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4382 - accuracy: 0.8316 - val_loss: 0.4207 - val_accuracy: 0.8112\n",
            "Epoch 76/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4379 - accuracy: 0.8298 - val_loss: 0.4206 - val_accuracy: 0.8112\n",
            "Epoch 77/1000\n",
            "36/36 [==============================] - 0s 3ms/step - loss: 0.4375 - accuracy: 0.8298 - val_loss: 0.4202 - val_accuracy: 0.8112\n",
            "Epoch 78/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4371 - accuracy: 0.8298 - val_loss: 0.4197 - val_accuracy: 0.8112\n",
            "Epoch 79/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4368 - accuracy: 0.8298 - val_loss: 0.4196 - val_accuracy: 0.8112\n",
            "Epoch 80/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4364 - accuracy: 0.8298 - val_loss: 0.4193 - val_accuracy: 0.8112\n",
            "Epoch 81/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4361 - accuracy: 0.8298 - val_loss: 0.4188 - val_accuracy: 0.8112\n",
            "Epoch 82/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4358 - accuracy: 0.8298 - val_loss: 0.4186 - val_accuracy: 0.8112\n",
            "Epoch 83/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4356 - accuracy: 0.8298 - val_loss: 0.4184 - val_accuracy: 0.8112\n",
            "Epoch 84/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4352 - accuracy: 0.8298 - val_loss: 0.4182 - val_accuracy: 0.8112\n",
            "Epoch 85/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4349 - accuracy: 0.8298 - val_loss: 0.4178 - val_accuracy: 0.8112\n",
            "Epoch 86/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4347 - accuracy: 0.8298 - val_loss: 0.4176 - val_accuracy: 0.8112\n",
            "Epoch 87/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4344 - accuracy: 0.8298 - val_loss: 0.4175 - val_accuracy: 0.8112\n",
            "Epoch 88/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4341 - accuracy: 0.8298 - val_loss: 0.4172 - val_accuracy: 0.8112\n",
            "Epoch 89/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4339 - accuracy: 0.8298 - val_loss: 0.4170 - val_accuracy: 0.8112\n",
            "Epoch 90/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4337 - accuracy: 0.8298 - val_loss: 0.4169 - val_accuracy: 0.8112\n",
            "Epoch 91/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4334 - accuracy: 0.8298 - val_loss: 0.4168 - val_accuracy: 0.8252\n",
            "Epoch 92/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4332 - accuracy: 0.8316 - val_loss: 0.4165 - val_accuracy: 0.8252\n",
            "Epoch 93/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4329 - accuracy: 0.8316 - val_loss: 0.4162 - val_accuracy: 0.8252\n",
            "Epoch 94/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4328 - accuracy: 0.8316 - val_loss: 0.4160 - val_accuracy: 0.8322\n",
            "Epoch 95/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4325 - accuracy: 0.8316 - val_loss: 0.4155 - val_accuracy: 0.8252\n",
            "Epoch 96/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4325 - accuracy: 0.8316 - val_loss: 0.4154 - val_accuracy: 0.8252\n",
            "Epoch 97/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4321 - accuracy: 0.8316 - val_loss: 0.4153 - val_accuracy: 0.8252\n",
            "Epoch 98/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4320 - accuracy: 0.8316 - val_loss: 0.4154 - val_accuracy: 0.8252\n",
            "Epoch 99/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4319 - accuracy: 0.8316 - val_loss: 0.4148 - val_accuracy: 0.8252\n",
            "Epoch 100/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4316 - accuracy: 0.8316 - val_loss: 0.4147 - val_accuracy: 0.8252\n",
            "Epoch 101/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.8333 - val_loss: 0.4148 - val_accuracy: 0.8322\n",
            "Epoch 102/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4313 - accuracy: 0.8333 - val_loss: 0.4146 - val_accuracy: 0.8252\n",
            "Epoch 103/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4311 - accuracy: 0.8333 - val_loss: 0.4142 - val_accuracy: 0.8322\n",
            "Epoch 104/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4309 - accuracy: 0.8333 - val_loss: 0.4143 - val_accuracy: 0.8322\n",
            "Epoch 105/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8333 - val_loss: 0.4143 - val_accuracy: 0.8322\n",
            "Epoch 106/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4307 - accuracy: 0.8333 - val_loss: 0.4138 - val_accuracy: 0.8322\n",
            "Epoch 107/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4304 - accuracy: 0.8333 - val_loss: 0.4139 - val_accuracy: 0.8252\n",
            "Epoch 108/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4305 - accuracy: 0.8333 - val_loss: 0.4134 - val_accuracy: 0.8252\n",
            "Epoch 109/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4302 - accuracy: 0.8333 - val_loss: 0.4137 - val_accuracy: 0.8252\n",
            "Epoch 110/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.8333 - val_loss: 0.4134 - val_accuracy: 0.8252\n",
            "Epoch 111/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4298 - accuracy: 0.8333 - val_loss: 0.4132 - val_accuracy: 0.8252\n",
            "Epoch 112/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4299 - accuracy: 0.8333 - val_loss: 0.4127 - val_accuracy: 0.8252\n",
            "Epoch 113/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8333 - val_loss: 0.4131 - val_accuracy: 0.8252\n",
            "Epoch 114/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4296 - accuracy: 0.8333 - val_loss: 0.4126 - val_accuracy: 0.8252\n",
            "Epoch 115/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4293 - accuracy: 0.8333 - val_loss: 0.4128 - val_accuracy: 0.8252\n",
            "Epoch 116/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4292 - accuracy: 0.8333 - val_loss: 0.4126 - val_accuracy: 0.8252\n",
            "Epoch 117/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4290 - accuracy: 0.8333 - val_loss: 0.4125 - val_accuracy: 0.8252\n",
            "Epoch 118/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4289 - accuracy: 0.8333 - val_loss: 0.4123 - val_accuracy: 0.8252\n",
            "Epoch 119/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4289 - accuracy: 0.8333 - val_loss: 0.4121 - val_accuracy: 0.8252\n",
            "Epoch 120/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4287 - accuracy: 0.8333 - val_loss: 0.4124 - val_accuracy: 0.8252\n",
            "Epoch 121/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4286 - accuracy: 0.8333 - val_loss: 0.4121 - val_accuracy: 0.8252\n",
            "Epoch 122/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4285 - accuracy: 0.8333 - val_loss: 0.4121 - val_accuracy: 0.8252\n",
            "Epoch 123/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4284 - accuracy: 0.8333 - val_loss: 0.4120 - val_accuracy: 0.8252\n",
            "Epoch 124/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4283 - accuracy: 0.8333 - val_loss: 0.4119 - val_accuracy: 0.8252\n",
            "Epoch 125/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8333 - val_loss: 0.4118 - val_accuracy: 0.8252\n",
            "Epoch 126/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4281 - accuracy: 0.8333 - val_loss: 0.4115 - val_accuracy: 0.8252\n",
            "Epoch 127/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4280 - accuracy: 0.8333 - val_loss: 0.4112 - val_accuracy: 0.8252\n",
            "Epoch 128/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4279 - accuracy: 0.8333 - val_loss: 0.4115 - val_accuracy: 0.8252\n",
            "Epoch 129/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4280 - accuracy: 0.8316 - val_loss: 0.4116 - val_accuracy: 0.8252\n",
            "Epoch 130/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8333 - val_loss: 0.4113 - val_accuracy: 0.8252\n",
            "Epoch 131/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4278 - accuracy: 0.8351 - val_loss: 0.4107 - val_accuracy: 0.8252\n",
            "Epoch 132/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4275 - accuracy: 0.8333 - val_loss: 0.4109 - val_accuracy: 0.8252\n",
            "Epoch 133/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4275 - accuracy: 0.8316 - val_loss: 0.4111 - val_accuracy: 0.8252\n",
            "Epoch 134/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4274 - accuracy: 0.8333 - val_loss: 0.4109 - val_accuracy: 0.8252\n",
            "Epoch 135/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4273 - accuracy: 0.8333 - val_loss: 0.4106 - val_accuracy: 0.8252\n",
            "Epoch 136/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4272 - accuracy: 0.8333 - val_loss: 0.4106 - val_accuracy: 0.8252\n",
            "Epoch 137/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8333 - val_loss: 0.4106 - val_accuracy: 0.8252\n",
            "Epoch 138/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4271 - accuracy: 0.8333 - val_loss: 0.4104 - val_accuracy: 0.8252\n",
            "Epoch 139/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.8333 - val_loss: 0.4106 - val_accuracy: 0.8252\n",
            "Epoch 140/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4269 - accuracy: 0.8333 - val_loss: 0.4104 - val_accuracy: 0.8252\n",
            "Epoch 141/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8333 - val_loss: 0.4106 - val_accuracy: 0.8252\n",
            "Epoch 142/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4267 - accuracy: 0.8333 - val_loss: 0.4102 - val_accuracy: 0.8252\n",
            "Epoch 143/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4267 - accuracy: 0.8333 - val_loss: 0.4100 - val_accuracy: 0.8252\n",
            "Epoch 144/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4268 - accuracy: 0.8316 - val_loss: 0.4101 - val_accuracy: 0.8252\n",
            "Epoch 145/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4266 - accuracy: 0.8351 - val_loss: 0.4098 - val_accuracy: 0.8252\n",
            "Epoch 146/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4265 - accuracy: 0.8351 - val_loss: 0.4100 - val_accuracy: 0.8252\n",
            "Epoch 147/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4264 - accuracy: 0.8351 - val_loss: 0.4099 - val_accuracy: 0.8252\n",
            "Epoch 148/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4264 - accuracy: 0.8333 - val_loss: 0.4098 - val_accuracy: 0.8252\n",
            "Epoch 149/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4263 - accuracy: 0.8351 - val_loss: 0.4096 - val_accuracy: 0.8252\n",
            "Epoch 150/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4262 - accuracy: 0.8351 - val_loss: 0.4097 - val_accuracy: 0.8252\n",
            "Epoch 151/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8351 - val_loss: 0.4097 - val_accuracy: 0.8252\n",
            "Epoch 152/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4263 - accuracy: 0.8333 - val_loss: 0.4097 - val_accuracy: 0.8252\n",
            "Epoch 153/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4260 - accuracy: 0.8351 - val_loss: 0.4094 - val_accuracy: 0.8252\n",
            "Epoch 154/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4261 - accuracy: 0.8333 - val_loss: 0.4094 - val_accuracy: 0.8252\n",
            "Epoch 155/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4261 - accuracy: 0.8351 - val_loss: 0.4092 - val_accuracy: 0.8252\n",
            "Epoch 156/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4258 - accuracy: 0.8351 - val_loss: 0.4090 - val_accuracy: 0.8252\n",
            "Epoch 157/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4258 - accuracy: 0.8351 - val_loss: 0.4092 - val_accuracy: 0.8252\n",
            "Epoch 158/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4257 - accuracy: 0.8351 - val_loss: 0.4089 - val_accuracy: 0.8252\n",
            "Epoch 159/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8351 - val_loss: 0.4089 - val_accuracy: 0.8252\n",
            "Epoch 160/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4257 - accuracy: 0.8351 - val_loss: 0.4090 - val_accuracy: 0.8252\n",
            "Epoch 161/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8333 - val_loss: 0.4091 - val_accuracy: 0.8252\n",
            "Epoch 162/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4256 - accuracy: 0.8351 - val_loss: 0.4088 - val_accuracy: 0.8252\n",
            "Epoch 163/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8351 - val_loss: 0.4088 - val_accuracy: 0.8252\n",
            "Epoch 164/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4254 - accuracy: 0.8351 - val_loss: 0.4087 - val_accuracy: 0.8252\n",
            "Epoch 165/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.8333 - val_loss: 0.4088 - val_accuracy: 0.8252\n",
            "Epoch 166/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4254 - accuracy: 0.8351 - val_loss: 0.4086 - val_accuracy: 0.8252\n",
            "Epoch 167/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4255 - accuracy: 0.8333 - val_loss: 0.4087 - val_accuracy: 0.8252\n",
            "Epoch 168/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4252 - accuracy: 0.8333 - val_loss: 0.4084 - val_accuracy: 0.8252\n",
            "Epoch 169/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4252 - accuracy: 0.8351 - val_loss: 0.4085 - val_accuracy: 0.8252\n",
            "Epoch 170/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4252 - accuracy: 0.8333 - val_loss: 0.4085 - val_accuracy: 0.8252\n",
            "Epoch 171/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4251 - accuracy: 0.8333 - val_loss: 0.4081 - val_accuracy: 0.8252\n",
            "Epoch 172/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8351 - val_loss: 0.4083 - val_accuracy: 0.8252\n",
            "Epoch 173/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8333 - val_loss: 0.4083 - val_accuracy: 0.8252\n",
            "Epoch 174/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8333 - val_loss: 0.4083 - val_accuracy: 0.8252\n",
            "Epoch 175/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4250 - accuracy: 0.8333 - val_loss: 0.4083 - val_accuracy: 0.8252\n",
            "Epoch 176/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4251 - accuracy: 0.8333 - val_loss: 0.4083 - val_accuracy: 0.8252\n",
            "Epoch 177/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4249 - accuracy: 0.8333 - val_loss: 0.4082 - val_accuracy: 0.8252\n",
            "Epoch 178/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4249 - accuracy: 0.8333 - val_loss: 0.4081 - val_accuracy: 0.8252\n",
            "Epoch 179/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8333 - val_loss: 0.4081 - val_accuracy: 0.8252\n",
            "Epoch 180/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8333 - val_loss: 0.4079 - val_accuracy: 0.8252\n",
            "Epoch 181/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4248 - accuracy: 0.8333 - val_loss: 0.4082 - val_accuracy: 0.8252\n",
            "Epoch 182/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4247 - accuracy: 0.8333 - val_loss: 0.4079 - val_accuracy: 0.8252\n",
            "Epoch 183/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4246 - accuracy: 0.8333 - val_loss: 0.4080 - val_accuracy: 0.8252\n",
            "Epoch 184/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4247 - accuracy: 0.8333 - val_loss: 0.4079 - val_accuracy: 0.8252\n",
            "Epoch 185/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8333 - val_loss: 0.4079 - val_accuracy: 0.8252\n",
            "Epoch 186/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8333 - val_loss: 0.4078 - val_accuracy: 0.8252\n",
            "Epoch 187/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4245 - accuracy: 0.8333 - val_loss: 0.4076 - val_accuracy: 0.8252\n",
            "Epoch 188/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8333 - val_loss: 0.4077 - val_accuracy: 0.8252\n",
            "Epoch 189/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4245 - accuracy: 0.8333 - val_loss: 0.4077 - val_accuracy: 0.8252\n",
            "Epoch 190/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8333 - val_loss: 0.4075 - val_accuracy: 0.8252\n",
            "Epoch 191/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4244 - accuracy: 0.8333 - val_loss: 0.4077 - val_accuracy: 0.8252\n",
            "Epoch 192/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4242 - accuracy: 0.8333 - val_loss: 0.4075 - val_accuracy: 0.8252\n",
            "Epoch 193/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8333 - val_loss: 0.4074 - val_accuracy: 0.8252\n",
            "Epoch 194/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4243 - accuracy: 0.8333 - val_loss: 0.4075 - val_accuracy: 0.8252\n",
            "Epoch 195/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4242 - accuracy: 0.8333 - val_loss: 0.4072 - val_accuracy: 0.8252\n",
            "Epoch 196/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8316 - val_loss: 0.4075 - val_accuracy: 0.8182\n",
            "Epoch 197/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8333 - val_loss: 0.4074 - val_accuracy: 0.8182\n",
            "Epoch 198/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8316 - val_loss: 0.4073 - val_accuracy: 0.8182\n",
            "Epoch 199/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8316 - val_loss: 0.4073 - val_accuracy: 0.8182\n",
            "Epoch 200/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4241 - accuracy: 0.8316 - val_loss: 0.4072 - val_accuracy: 0.8182\n",
            "Epoch 201/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4240 - accuracy: 0.8316 - val_loss: 0.4072 - val_accuracy: 0.8182\n",
            "Epoch 202/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4241 - accuracy: 0.8333 - val_loss: 0.4069 - val_accuracy: 0.8182\n",
            "Epoch 203/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8316 - val_loss: 0.4070 - val_accuracy: 0.8182\n",
            "Epoch 204/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4239 - accuracy: 0.8316 - val_loss: 0.4070 - val_accuracy: 0.8182\n",
            "Epoch 205/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4240 - accuracy: 0.8316 - val_loss: 0.4068 - val_accuracy: 0.8182\n",
            "Epoch 206/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4238 - accuracy: 0.8316 - val_loss: 0.4071 - val_accuracy: 0.8252\n",
            "Epoch 207/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8316 - val_loss: 0.4069 - val_accuracy: 0.8182\n",
            "Epoch 208/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4237 - accuracy: 0.8316 - val_loss: 0.4069 - val_accuracy: 0.8182\n",
            "Epoch 209/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8316 - val_loss: 0.4068 - val_accuracy: 0.8252\n",
            "Epoch 210/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8316 - val_loss: 0.4069 - val_accuracy: 0.8252\n",
            "Epoch 211/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8316 - val_loss: 0.4068 - val_accuracy: 0.8252\n",
            "Epoch 212/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4237 - accuracy: 0.8316 - val_loss: 0.4069 - val_accuracy: 0.8182\n",
            "Epoch 213/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4238 - accuracy: 0.8316 - val_loss: 0.4071 - val_accuracy: 0.8252\n",
            "Epoch 214/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8316 - val_loss: 0.4067 - val_accuracy: 0.8252\n",
            "Epoch 215/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8316 - val_loss: 0.4066 - val_accuracy: 0.8252\n",
            "Epoch 216/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8316 - val_loss: 0.4069 - val_accuracy: 0.8252\n",
            "Epoch 217/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8316 - val_loss: 0.4068 - val_accuracy: 0.8252\n",
            "Epoch 218/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8316 - val_loss: 0.4066 - val_accuracy: 0.8252\n",
            "Epoch 219/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4235 - accuracy: 0.8316 - val_loss: 0.4067 - val_accuracy: 0.8252\n",
            "Epoch 220/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8316 - val_loss: 0.4067 - val_accuracy: 0.8252\n",
            "Epoch 221/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4237 - accuracy: 0.8316 - val_loss: 0.4068 - val_accuracy: 0.8252\n",
            "Epoch 222/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4235 - accuracy: 0.8316 - val_loss: 0.4066 - val_accuracy: 0.8252\n",
            "Epoch 223/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4234 - accuracy: 0.8316 - val_loss: 0.4066 - val_accuracy: 0.8252\n",
            "Epoch 224/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4236 - accuracy: 0.8316 - val_loss: 0.4062 - val_accuracy: 0.8252\n",
            "Epoch 225/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8316 - val_loss: 0.4066 - val_accuracy: 0.8252\n",
            "Epoch 226/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8316 - val_loss: 0.4065 - val_accuracy: 0.8252\n",
            "Epoch 227/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4233 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 228/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8316 - val_loss: 0.4064 - val_accuracy: 0.8252\n",
            "Epoch 229/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4234 - accuracy: 0.8316 - val_loss: 0.4062 - val_accuracy: 0.8252\n",
            "Epoch 230/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 231/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8316 - val_loss: 0.4064 - val_accuracy: 0.8252\n",
            "Epoch 232/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4233 - accuracy: 0.8316 - val_loss: 0.4066 - val_accuracy: 0.8252\n",
            "Epoch 233/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 234/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4233 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 235/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 236/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4232 - accuracy: 0.8316 - val_loss: 0.4061 - val_accuracy: 0.8252\n",
            "Epoch 237/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 238/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4231 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 239/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8316 - val_loss: 0.4064 - val_accuracy: 0.8252\n",
            "Epoch 240/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 241/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 242/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8316 - val_loss: 0.4062 - val_accuracy: 0.8252\n",
            "Epoch 243/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8316 - val_loss: 0.4062 - val_accuracy: 0.8252\n",
            "Epoch 244/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4230 - accuracy: 0.8316 - val_loss: 0.4063 - val_accuracy: 0.8252\n",
            "Epoch 245/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4231 - accuracy: 0.8316 - val_loss: 0.4060 - val_accuracy: 0.8252\n",
            "Epoch 246/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8316 - val_loss: 0.4061 - val_accuracy: 0.8252\n",
            "Epoch 247/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4230 - accuracy: 0.8316 - val_loss: 0.4064 - val_accuracy: 0.8252\n",
            "Epoch 248/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4231 - accuracy: 0.8316 - val_loss: 0.4059 - val_accuracy: 0.8252\n",
            "Epoch 249/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8316 - val_loss: 0.4064 - val_accuracy: 0.8252\n",
            "Epoch 250/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4229 - accuracy: 0.8316 - val_loss: 0.4060 - val_accuracy: 0.8252\n",
            "Epoch 251/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4228 - accuracy: 0.8316 - val_loss: 0.4061 - val_accuracy: 0.8252\n",
            "Epoch 252/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8316 - val_loss: 0.4061 - val_accuracy: 0.8252\n",
            "Epoch 253/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8316 - val_loss: 0.4062 - val_accuracy: 0.8252\n",
            "Epoch 254/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8316 - val_loss: 0.4058 - val_accuracy: 0.8252\n",
            "Epoch 255/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 256/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4229 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 257/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4059 - val_accuracy: 0.8252\n",
            "Epoch 258/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4059 - val_accuracy: 0.8252\n",
            "Epoch 259/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4228 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 260/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4060 - val_accuracy: 0.8252\n",
            "Epoch 261/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4059 - val_accuracy: 0.8252\n",
            "Epoch 262/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4060 - val_accuracy: 0.8252\n",
            "Epoch 263/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4226 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 264/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8316 - val_loss: 0.4058 - val_accuracy: 0.8252\n",
            "Epoch 265/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8316 - val_loss: 0.4060 - val_accuracy: 0.8252\n",
            "Epoch 266/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 267/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 268/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4227 - accuracy: 0.8316 - val_loss: 0.4058 - val_accuracy: 0.8252\n",
            "Epoch 269/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4226 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 270/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 271/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 272/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 273/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8316 - val_loss: 0.4056 - val_accuracy: 0.8252\n",
            "Epoch 274/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 275/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4225 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 276/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4225 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 277/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 278/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 279/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 280/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4224 - accuracy: 0.8316 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 281/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4225 - accuracy: 0.8316 - val_loss: 0.4057 - val_accuracy: 0.8252\n",
            "Epoch 282/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 283/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8316 - val_loss: 0.4056 - val_accuracy: 0.8252\n",
            "Epoch 284/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 285/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 286/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 287/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 288/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 289/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 290/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 291/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 292/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 293/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 294/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 295/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4224 - accuracy: 0.8316 - val_loss: 0.4053 - val_accuracy: 0.8252\n",
            "Epoch 296/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8316 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 297/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8316 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 298/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8351 - val_loss: 0.4053 - val_accuracy: 0.8252\n",
            "Epoch 299/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8351 - val_loss: 0.4053 - val_accuracy: 0.8252\n",
            "Epoch 300/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8333 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 301/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8316 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 302/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8316 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 303/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 304/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4222 - accuracy: 0.8333 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 305/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 306/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 307/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4222 - accuracy: 0.8351 - val_loss: 0.4055 - val_accuracy: 0.8252\n",
            "Epoch 308/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4226 - accuracy: 0.8316 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 309/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4223 - accuracy: 0.8333 - val_loss: 0.4053 - val_accuracy: 0.8252\n",
            "Epoch 310/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 311/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 312/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4053 - val_accuracy: 0.8252\n",
            "Epoch 313/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 314/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 315/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4054 - val_accuracy: 0.8252\n",
            "Epoch 316/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4221 - accuracy: 0.8351 - val_loss: 0.4050 - val_accuracy: 0.8252\n",
            "Epoch 317/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 318/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 319/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 320/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 321/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 322/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 323/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4050 - val_accuracy: 0.8252\n",
            "Epoch 324/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 325/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 326/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4051 - val_accuracy: 0.8252\n",
            "Epoch 327/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 328/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4052 - val_accuracy: 0.8252\n",
            "Epoch 329/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 330/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 331/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4050 - val_accuracy: 0.8252\n",
            "Epoch 332/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 333/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 334/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 335/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 336/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4220 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 337/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 338/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 339/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 340/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 341/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 342/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 343/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4219 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 344/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 345/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 346/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 347/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 348/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 349/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 350/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 351/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 352/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4050 - val_accuracy: 0.8252\n",
            "Epoch 353/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 354/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 355/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 356/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 357/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 358/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4050 - val_accuracy: 0.8252\n",
            "Epoch 359/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 360/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 361/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 362/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4050 - val_accuracy: 0.8252\n",
            "Epoch 363/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 364/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4050 - val_accuracy: 0.8252\n",
            "Epoch 365/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 366/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 367/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 368/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4218 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 369/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 370/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 371/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 372/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 373/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 374/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 375/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 376/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 377/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 378/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4048 - val_accuracy: 0.8252\n",
            "Epoch 379/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 380/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 381/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 382/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 383/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4041 - val_accuracy: 0.8252\n",
            "Epoch 384/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 385/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 386/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 387/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 388/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 389/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 390/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 391/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 392/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 393/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 394/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 395/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 396/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 397/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 398/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 399/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 400/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 401/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 402/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 403/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 404/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 405/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 406/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 407/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4215 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 408/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 409/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4216 - accuracy: 0.8351 - val_loss: 0.4049 - val_accuracy: 0.8252\n",
            "Epoch 410/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4217 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 411/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4042 - val_accuracy: 0.8252\n",
            "Epoch 412/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 413/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 414/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 415/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 416/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 417/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 418/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 419/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 420/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 421/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 422/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8351 - val_loss: 0.4046 - val_accuracy: 0.8252\n",
            "Epoch 423/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 424/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 425/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4045 - val_accuracy: 0.8252\n",
            "Epoch 426/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "Epoch 427/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4042 - val_accuracy: 0.8252\n",
            "Epoch 428/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 429/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 430/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4212 - accuracy: 0.8351 - val_loss: 0.4047 - val_accuracy: 0.8252\n",
            "Epoch 431/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4212 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 432/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4213 - accuracy: 0.8351 - val_loss: 0.4044 - val_accuracy: 0.8252\n",
            "Epoch 433/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4214 - accuracy: 0.8351 - val_loss: 0.4043 - val_accuracy: 0.8252\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7865\n",
            "Epoch 1/1000\n",
            "36/36 [==============================] - 1s 9ms/step - loss: 0.7250 - accuracy: 0.5895 - val_loss: 0.6988 - val_accuracy: 0.6084\n",
            "Epoch 2/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.7086 - accuracy: 0.5947 - val_loss: 0.6812 - val_accuracy: 0.6294\n",
            "Epoch 3/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6933 - accuracy: 0.6105 - val_loss: 0.6649 - val_accuracy: 0.6294\n",
            "Epoch 4/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6790 - accuracy: 0.6158 - val_loss: 0.6500 - val_accuracy: 0.6503\n",
            "Epoch 5/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6658 - accuracy: 0.6316 - val_loss: 0.6355 - val_accuracy: 0.6503\n",
            "Epoch 6/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6531 - accuracy: 0.6333 - val_loss: 0.6217 - val_accuracy: 0.6503\n",
            "Epoch 7/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6414 - accuracy: 0.6333 - val_loss: 0.6099 - val_accuracy: 0.6503\n",
            "Epoch 8/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6302 - accuracy: 0.6333 - val_loss: 0.5985 - val_accuracy: 0.6573\n",
            "Epoch 9/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6200 - accuracy: 0.6456 - val_loss: 0.5873 - val_accuracy: 0.6783\n",
            "Epoch 10/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6101 - accuracy: 0.6579 - val_loss: 0.5774 - val_accuracy: 0.6853\n",
            "Epoch 11/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6009 - accuracy: 0.6754 - val_loss: 0.5680 - val_accuracy: 0.6993\n",
            "Epoch 12/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5923 - accuracy: 0.6842 - val_loss: 0.5587 - val_accuracy: 0.7133\n",
            "Epoch 13/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5841 - accuracy: 0.6930 - val_loss: 0.5503 - val_accuracy: 0.7133\n",
            "Epoch 14/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5767 - accuracy: 0.6965 - val_loss: 0.5421 - val_accuracy: 0.7203\n",
            "Epoch 15/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5696 - accuracy: 0.7035 - val_loss: 0.5345 - val_accuracy: 0.7133\n",
            "Epoch 16/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5628 - accuracy: 0.7193 - val_loss: 0.5281 - val_accuracy: 0.7203\n",
            "Epoch 17/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5567 - accuracy: 0.7386 - val_loss: 0.5219 - val_accuracy: 0.7483\n",
            "Epoch 18/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5509 - accuracy: 0.7491 - val_loss: 0.5155 - val_accuracy: 0.7413\n",
            "Epoch 19/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5454 - accuracy: 0.7561 - val_loss: 0.5097 - val_accuracy: 0.7483\n",
            "Epoch 20/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5403 - accuracy: 0.7614 - val_loss: 0.5050 - val_accuracy: 0.7483\n",
            "Epoch 21/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5354 - accuracy: 0.7632 - val_loss: 0.4999 - val_accuracy: 0.7483\n",
            "Epoch 22/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5310 - accuracy: 0.7667 - val_loss: 0.4948 - val_accuracy: 0.7483\n",
            "Epoch 23/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5266 - accuracy: 0.7702 - val_loss: 0.4906 - val_accuracy: 0.7552\n",
            "Epoch 24/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5228 - accuracy: 0.7772 - val_loss: 0.4861 - val_accuracy: 0.7552\n",
            "Epoch 25/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5189 - accuracy: 0.7789 - val_loss: 0.4828 - val_accuracy: 0.7692\n",
            "Epoch 26/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5152 - accuracy: 0.7877 - val_loss: 0.4788 - val_accuracy: 0.7832\n",
            "Epoch 27/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5119 - accuracy: 0.7930 - val_loss: 0.4753 - val_accuracy: 0.7832\n",
            "Epoch 28/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5087 - accuracy: 0.7930 - val_loss: 0.4721 - val_accuracy: 0.7972\n",
            "Epoch 29/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5058 - accuracy: 0.7895 - val_loss: 0.4690 - val_accuracy: 0.8042\n",
            "Epoch 30/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5032 - accuracy: 0.8000 - val_loss: 0.4661 - val_accuracy: 0.8042\n",
            "Epoch 31/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5004 - accuracy: 0.8018 - val_loss: 0.4638 - val_accuracy: 0.8042\n",
            "Epoch 32/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4979 - accuracy: 0.8018 - val_loss: 0.4612 - val_accuracy: 0.8042\n",
            "Epoch 33/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4956 - accuracy: 0.8018 - val_loss: 0.4580 - val_accuracy: 0.8042\n",
            "Epoch 34/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4934 - accuracy: 0.8018 - val_loss: 0.4560 - val_accuracy: 0.8112\n",
            "Epoch 35/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.8035 - val_loss: 0.4539 - val_accuracy: 0.8042\n",
            "Epoch 36/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4893 - accuracy: 0.7982 - val_loss: 0.4520 - val_accuracy: 0.7972\n",
            "Epoch 37/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4874 - accuracy: 0.8000 - val_loss: 0.4502 - val_accuracy: 0.7972\n",
            "Epoch 38/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4857 - accuracy: 0.8000 - val_loss: 0.4481 - val_accuracy: 0.7972\n",
            "Epoch 39/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4840 - accuracy: 0.7982 - val_loss: 0.4464 - val_accuracy: 0.7972\n",
            "Epoch 40/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4824 - accuracy: 0.7965 - val_loss: 0.4444 - val_accuracy: 0.7972\n",
            "Epoch 41/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4810 - accuracy: 0.7947 - val_loss: 0.4432 - val_accuracy: 0.8182\n",
            "Epoch 42/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4794 - accuracy: 0.7947 - val_loss: 0.4413 - val_accuracy: 0.8182\n",
            "Epoch 43/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4781 - accuracy: 0.8000 - val_loss: 0.4403 - val_accuracy: 0.8042\n",
            "Epoch 44/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4768 - accuracy: 0.8070 - val_loss: 0.4385 - val_accuracy: 0.8112\n",
            "Epoch 45/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4756 - accuracy: 0.8053 - val_loss: 0.4375 - val_accuracy: 0.8042\n",
            "Epoch 46/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4743 - accuracy: 0.8088 - val_loss: 0.4361 - val_accuracy: 0.8042\n",
            "Epoch 47/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4733 - accuracy: 0.8088 - val_loss: 0.4349 - val_accuracy: 0.8042\n",
            "Epoch 48/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4724 - accuracy: 0.8088 - val_loss: 0.4338 - val_accuracy: 0.8042\n",
            "Epoch 49/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4712 - accuracy: 0.8070 - val_loss: 0.4327 - val_accuracy: 0.8042\n",
            "Epoch 50/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4703 - accuracy: 0.8053 - val_loss: 0.4318 - val_accuracy: 0.8112\n",
            "Epoch 51/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4693 - accuracy: 0.8053 - val_loss: 0.4308 - val_accuracy: 0.8182\n",
            "Epoch 52/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4686 - accuracy: 0.8070 - val_loss: 0.4301 - val_accuracy: 0.8182\n",
            "Epoch 53/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4677 - accuracy: 0.8070 - val_loss: 0.4286 - val_accuracy: 0.8182\n",
            "Epoch 54/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.8088 - val_loss: 0.4281 - val_accuracy: 0.8182\n",
            "Epoch 55/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4662 - accuracy: 0.8088 - val_loss: 0.4270 - val_accuracy: 0.8182\n",
            "Epoch 56/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4655 - accuracy: 0.8105 - val_loss: 0.4265 - val_accuracy: 0.8182\n",
            "Epoch 57/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4648 - accuracy: 0.8105 - val_loss: 0.4256 - val_accuracy: 0.8182\n",
            "Epoch 58/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4643 - accuracy: 0.8105 - val_loss: 0.4249 - val_accuracy: 0.8182\n",
            "Epoch 59/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4635 - accuracy: 0.8105 - val_loss: 0.4244 - val_accuracy: 0.8182\n",
            "Epoch 60/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.8105 - val_loss: 0.4242 - val_accuracy: 0.8252\n",
            "Epoch 61/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.8105 - val_loss: 0.4232 - val_accuracy: 0.8252\n",
            "Epoch 62/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.8105 - val_loss: 0.4224 - val_accuracy: 0.8252\n",
            "Epoch 63/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.8105 - val_loss: 0.4223 - val_accuracy: 0.8252\n",
            "Epoch 64/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4607 - accuracy: 0.8105 - val_loss: 0.4216 - val_accuracy: 0.8182\n",
            "Epoch 65/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4602 - accuracy: 0.8105 - val_loss: 0.4208 - val_accuracy: 0.8182\n",
            "Epoch 66/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4598 - accuracy: 0.8105 - val_loss: 0.4202 - val_accuracy: 0.8182\n",
            "Epoch 67/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4593 - accuracy: 0.8105 - val_loss: 0.4199 - val_accuracy: 0.8182\n",
            "Epoch 68/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4588 - accuracy: 0.8105 - val_loss: 0.4193 - val_accuracy: 0.8182\n",
            "Epoch 69/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8105 - val_loss: 0.4191 - val_accuracy: 0.8182\n",
            "Epoch 70/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4581 - accuracy: 0.8105 - val_loss: 0.4185 - val_accuracy: 0.8182\n",
            "Epoch 71/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4576 - accuracy: 0.8105 - val_loss: 0.4181 - val_accuracy: 0.8182\n",
            "Epoch 72/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4572 - accuracy: 0.8105 - val_loss: 0.4175 - val_accuracy: 0.8182\n",
            "Epoch 73/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4570 - accuracy: 0.8105 - val_loss: 0.4171 - val_accuracy: 0.8182\n",
            "Epoch 74/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4565 - accuracy: 0.8105 - val_loss: 0.4168 - val_accuracy: 0.8182\n",
            "Epoch 75/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.8105 - val_loss: 0.4165 - val_accuracy: 0.8182\n",
            "Epoch 76/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.8105 - val_loss: 0.4158 - val_accuracy: 0.8182\n",
            "Epoch 77/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4556 - accuracy: 0.8105 - val_loss: 0.4156 - val_accuracy: 0.8182\n",
            "Epoch 78/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4552 - accuracy: 0.8105 - val_loss: 0.4153 - val_accuracy: 0.8182\n",
            "Epoch 79/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4549 - accuracy: 0.8105 - val_loss: 0.4153 - val_accuracy: 0.8182\n",
            "Epoch 80/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.8105 - val_loss: 0.4149 - val_accuracy: 0.8182\n",
            "Epoch 81/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4543 - accuracy: 0.8105 - val_loss: 0.4144 - val_accuracy: 0.8182\n",
            "Epoch 82/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4541 - accuracy: 0.8123 - val_loss: 0.4141 - val_accuracy: 0.8182\n",
            "Epoch 83/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.8123 - val_loss: 0.4134 - val_accuracy: 0.8182\n",
            "Epoch 84/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4537 - accuracy: 0.8123 - val_loss: 0.4138 - val_accuracy: 0.8182\n",
            "Epoch 85/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4533 - accuracy: 0.8123 - val_loss: 0.4130 - val_accuracy: 0.8182\n",
            "Epoch 86/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4531 - accuracy: 0.8123 - val_loss: 0.4131 - val_accuracy: 0.8182\n",
            "Epoch 87/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4529 - accuracy: 0.8123 - val_loss: 0.4126 - val_accuracy: 0.8182\n",
            "Epoch 88/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4527 - accuracy: 0.8123 - val_loss: 0.4124 - val_accuracy: 0.8182\n",
            "Epoch 89/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4524 - accuracy: 0.8123 - val_loss: 0.4122 - val_accuracy: 0.8182\n",
            "Epoch 90/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.8123 - val_loss: 0.4119 - val_accuracy: 0.8182\n",
            "Epoch 91/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4520 - accuracy: 0.8123 - val_loss: 0.4119 - val_accuracy: 0.8182\n",
            "Epoch 92/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4519 - accuracy: 0.8123 - val_loss: 0.4113 - val_accuracy: 0.8182\n",
            "Epoch 93/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4517 - accuracy: 0.8123 - val_loss: 0.4111 - val_accuracy: 0.8182\n",
            "Epoch 94/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8123 - val_loss: 0.4105 - val_accuracy: 0.8182\n",
            "Epoch 95/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4512 - accuracy: 0.8123 - val_loss: 0.4108 - val_accuracy: 0.8182\n",
            "Epoch 96/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.8123 - val_loss: 0.4105 - val_accuracy: 0.8182\n",
            "Epoch 97/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8123 - val_loss: 0.4104 - val_accuracy: 0.8182\n",
            "Epoch 98/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8123 - val_loss: 0.4103 - val_accuracy: 0.8182\n",
            "Epoch 99/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4505 - accuracy: 0.8123 - val_loss: 0.4099 - val_accuracy: 0.8182\n",
            "Epoch 100/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8123 - val_loss: 0.4099 - val_accuracy: 0.8182\n",
            "Epoch 101/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4502 - accuracy: 0.8123 - val_loss: 0.4094 - val_accuracy: 0.8182\n",
            "Epoch 102/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4501 - accuracy: 0.8123 - val_loss: 0.4095 - val_accuracy: 0.8182\n",
            "Epoch 103/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8140 - val_loss: 0.4089 - val_accuracy: 0.8182\n",
            "Epoch 104/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4498 - accuracy: 0.8140 - val_loss: 0.4088 - val_accuracy: 0.8182\n",
            "Epoch 105/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.8140 - val_loss: 0.4088 - val_accuracy: 0.8182\n",
            "Epoch 106/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8140 - val_loss: 0.4085 - val_accuracy: 0.8182\n",
            "Epoch 107/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8140 - val_loss: 0.4084 - val_accuracy: 0.8182\n",
            "Epoch 108/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.8140 - val_loss: 0.4083 - val_accuracy: 0.8182\n",
            "Epoch 109/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8140 - val_loss: 0.4080 - val_accuracy: 0.8182\n",
            "Epoch 110/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8140 - val_loss: 0.4078 - val_accuracy: 0.8182\n",
            "Epoch 111/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.8140 - val_loss: 0.4077 - val_accuracy: 0.8182\n",
            "Epoch 112/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8140 - val_loss: 0.4076 - val_accuracy: 0.8182\n",
            "Epoch 113/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8123 - val_loss: 0.4077 - val_accuracy: 0.8182\n",
            "Epoch 114/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.4072 - val_accuracy: 0.8182\n",
            "Epoch 115/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.8123 - val_loss: 0.4076 - val_accuracy: 0.8182\n",
            "Epoch 116/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4481 - accuracy: 0.8123 - val_loss: 0.4072 - val_accuracy: 0.8182\n",
            "Epoch 117/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4481 - accuracy: 0.8140 - val_loss: 0.4073 - val_accuracy: 0.8182\n",
            "Epoch 118/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4480 - accuracy: 0.8123 - val_loss: 0.4071 - val_accuracy: 0.8182\n",
            "Epoch 119/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4479 - accuracy: 0.8123 - val_loss: 0.4069 - val_accuracy: 0.8182\n",
            "Epoch 120/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4477 - accuracy: 0.8123 - val_loss: 0.4066 - val_accuracy: 0.8182\n",
            "Epoch 121/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4477 - accuracy: 0.8123 - val_loss: 0.4067 - val_accuracy: 0.8182\n",
            "Epoch 122/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4478 - accuracy: 0.8105 - val_loss: 0.4064 - val_accuracy: 0.8182\n",
            "Epoch 123/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4475 - accuracy: 0.8123 - val_loss: 0.4061 - val_accuracy: 0.8182\n",
            "Epoch 124/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4474 - accuracy: 0.8123 - val_loss: 0.4062 - val_accuracy: 0.8182\n",
            "Epoch 125/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4474 - accuracy: 0.8123 - val_loss: 0.4062 - val_accuracy: 0.8182\n",
            "Epoch 126/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.8123 - val_loss: 0.4060 - val_accuracy: 0.8182\n",
            "Epoch 127/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4471 - accuracy: 0.8123 - val_loss: 0.4057 - val_accuracy: 0.8182\n",
            "Epoch 128/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4471 - accuracy: 0.8123 - val_loss: 0.4058 - val_accuracy: 0.8182\n",
            "Epoch 129/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4470 - accuracy: 0.8123 - val_loss: 0.4054 - val_accuracy: 0.8182\n",
            "Epoch 130/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4470 - accuracy: 0.8105 - val_loss: 0.4058 - val_accuracy: 0.8182\n",
            "Epoch 131/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4468 - accuracy: 0.8123 - val_loss: 0.4057 - val_accuracy: 0.8182\n",
            "Epoch 132/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.8123 - val_loss: 0.4055 - val_accuracy: 0.8182\n",
            "Epoch 133/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4466 - accuracy: 0.8123 - val_loss: 0.4049 - val_accuracy: 0.8182\n",
            "Epoch 134/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4465 - accuracy: 0.8123 - val_loss: 0.4048 - val_accuracy: 0.8182\n",
            "Epoch 135/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4464 - accuracy: 0.8123 - val_loss: 0.4054 - val_accuracy: 0.8182\n",
            "Epoch 136/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4464 - accuracy: 0.8140 - val_loss: 0.4052 - val_accuracy: 0.8182\n",
            "Epoch 137/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4463 - accuracy: 0.8123 - val_loss: 0.4049 - val_accuracy: 0.8182\n",
            "Epoch 138/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4462 - accuracy: 0.8140 - val_loss: 0.4047 - val_accuracy: 0.8182\n",
            "Epoch 139/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4460 - accuracy: 0.8158 - val_loss: 0.4046 - val_accuracy: 0.8182\n",
            "Epoch 140/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4461 - accuracy: 0.8158 - val_loss: 0.4045 - val_accuracy: 0.8182\n",
            "Epoch 141/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4460 - accuracy: 0.8158 - val_loss: 0.4046 - val_accuracy: 0.8182\n",
            "Epoch 142/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4459 - accuracy: 0.8158 - val_loss: 0.4044 - val_accuracy: 0.8182\n",
            "Epoch 143/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.8158 - val_loss: 0.4045 - val_accuracy: 0.8182\n",
            "Epoch 144/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4458 - accuracy: 0.8158 - val_loss: 0.4042 - val_accuracy: 0.8182\n",
            "Epoch 145/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4457 - accuracy: 0.8158 - val_loss: 0.4041 - val_accuracy: 0.8182\n",
            "Epoch 146/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4457 - accuracy: 0.8158 - val_loss: 0.4043 - val_accuracy: 0.8182\n",
            "Epoch 147/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4455 - accuracy: 0.8158 - val_loss: 0.4039 - val_accuracy: 0.8182\n",
            "Epoch 148/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4455 - accuracy: 0.8158 - val_loss: 0.4038 - val_accuracy: 0.8182\n",
            "Epoch 149/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4454 - accuracy: 0.8158 - val_loss: 0.4041 - val_accuracy: 0.8182\n",
            "Epoch 150/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4454 - accuracy: 0.8158 - val_loss: 0.4037 - val_accuracy: 0.8182\n",
            "Epoch 151/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4454 - accuracy: 0.8158 - val_loss: 0.4035 - val_accuracy: 0.8182\n",
            "Epoch 152/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4453 - accuracy: 0.8158 - val_loss: 0.4033 - val_accuracy: 0.8182\n",
            "Epoch 153/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4453 - accuracy: 0.8158 - val_loss: 0.4035 - val_accuracy: 0.8182\n",
            "Epoch 154/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4452 - accuracy: 0.8158 - val_loss: 0.4033 - val_accuracy: 0.8182\n",
            "Epoch 155/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4451 - accuracy: 0.8158 - val_loss: 0.4036 - val_accuracy: 0.8182\n",
            "Epoch 156/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4452 - accuracy: 0.8158 - val_loss: 0.4030 - val_accuracy: 0.8182\n",
            "Epoch 157/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.8158 - val_loss: 0.4033 - val_accuracy: 0.8182\n",
            "Epoch 158/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4450 - accuracy: 0.8158 - val_loss: 0.4031 - val_accuracy: 0.8182\n",
            "Epoch 159/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4449 - accuracy: 0.8158 - val_loss: 0.4030 - val_accuracy: 0.8182\n",
            "Epoch 160/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4450 - accuracy: 0.8158 - val_loss: 0.4035 - val_accuracy: 0.8182\n",
            "Epoch 161/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8175 - val_loss: 0.4029 - val_accuracy: 0.8182\n",
            "Epoch 162/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4448 - accuracy: 0.8175 - val_loss: 0.4026 - val_accuracy: 0.8182\n",
            "Epoch 163/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8175 - val_loss: 0.4025 - val_accuracy: 0.8182\n",
            "Epoch 164/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4447 - accuracy: 0.8175 - val_loss: 0.4032 - val_accuracy: 0.8182\n",
            "Epoch 165/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4445 - accuracy: 0.8175 - val_loss: 0.4027 - val_accuracy: 0.8182\n",
            "Epoch 166/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4445 - accuracy: 0.8175 - val_loss: 0.4024 - val_accuracy: 0.8182\n",
            "Epoch 167/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4446 - accuracy: 0.8193 - val_loss: 0.4029 - val_accuracy: 0.8182\n",
            "Epoch 168/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.8175 - val_loss: 0.4023 - val_accuracy: 0.8182\n",
            "Epoch 169/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4444 - accuracy: 0.8228 - val_loss: 0.4024 - val_accuracy: 0.8182\n",
            "Epoch 170/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4443 - accuracy: 0.8228 - val_loss: 0.4023 - val_accuracy: 0.8182\n",
            "Epoch 171/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8228 - val_loss: 0.4021 - val_accuracy: 0.8182\n",
            "Epoch 172/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4443 - accuracy: 0.8228 - val_loss: 0.4024 - val_accuracy: 0.8252\n",
            "Epoch 173/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8228 - val_loss: 0.4021 - val_accuracy: 0.8252\n",
            "Epoch 174/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4442 - accuracy: 0.8228 - val_loss: 0.4023 - val_accuracy: 0.8252\n",
            "Epoch 175/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4442 - accuracy: 0.8228 - val_loss: 0.4019 - val_accuracy: 0.8252\n",
            "Epoch 176/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4441 - accuracy: 0.8228 - val_loss: 0.4020 - val_accuracy: 0.8252\n",
            "Epoch 177/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8228 - val_loss: 0.4017 - val_accuracy: 0.8252\n",
            "Epoch 178/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8228 - val_loss: 0.4018 - val_accuracy: 0.8252\n",
            "Epoch 179/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8228 - val_loss: 0.4017 - val_accuracy: 0.8252\n",
            "Epoch 180/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4440 - accuracy: 0.8228 - val_loss: 0.4021 - val_accuracy: 0.8252\n",
            "Epoch 181/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4439 - accuracy: 0.8228 - val_loss: 0.4015 - val_accuracy: 0.8252\n",
            "Epoch 182/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4440 - accuracy: 0.8228 - val_loss: 0.4014 - val_accuracy: 0.8252\n",
            "Epoch 183/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4439 - accuracy: 0.8228 - val_loss: 0.4012 - val_accuracy: 0.8252\n",
            "Epoch 184/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4438 - accuracy: 0.8228 - val_loss: 0.4011 - val_accuracy: 0.8252\n",
            "Epoch 185/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4437 - accuracy: 0.8228 - val_loss: 0.4012 - val_accuracy: 0.8252\n",
            "Epoch 186/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4437 - accuracy: 0.8228 - val_loss: 0.4015 - val_accuracy: 0.8252\n",
            "Epoch 187/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4437 - accuracy: 0.8228 - val_loss: 0.4012 - val_accuracy: 0.8252\n",
            "Epoch 188/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.8228 - val_loss: 0.4012 - val_accuracy: 0.8252\n",
            "Epoch 189/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.8228 - val_loss: 0.4012 - val_accuracy: 0.8252\n",
            "Epoch 190/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4436 - accuracy: 0.8228 - val_loss: 0.4010 - val_accuracy: 0.8252\n",
            "Epoch 191/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4436 - accuracy: 0.8228 - val_loss: 0.4013 - val_accuracy: 0.8252\n",
            "Epoch 192/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8228 - val_loss: 0.4007 - val_accuracy: 0.8252\n",
            "Epoch 193/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4436 - accuracy: 0.8228 - val_loss: 0.4008 - val_accuracy: 0.8252\n",
            "Epoch 194/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4435 - accuracy: 0.8228 - val_loss: 0.4009 - val_accuracy: 0.8252\n",
            "Epoch 195/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4435 - accuracy: 0.8228 - val_loss: 0.4005 - val_accuracy: 0.8252\n",
            "Epoch 196/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4433 - accuracy: 0.8228 - val_loss: 0.4007 - val_accuracy: 0.8252\n",
            "Epoch 197/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.8228 - val_loss: 0.4009 - val_accuracy: 0.8252\n",
            "Epoch 198/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4434 - accuracy: 0.8228 - val_loss: 0.4007 - val_accuracy: 0.8252\n",
            "Epoch 199/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4433 - accuracy: 0.8228 - val_loss: 0.4005 - val_accuracy: 0.8252\n",
            "Epoch 200/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8228 - val_loss: 0.4005 - val_accuracy: 0.8252\n",
            "Epoch 201/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4432 - accuracy: 0.8228 - val_loss: 0.4006 - val_accuracy: 0.8252\n",
            "Epoch 202/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4432 - accuracy: 0.8228 - val_loss: 0.4007 - val_accuracy: 0.8252\n",
            "Epoch 203/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4431 - accuracy: 0.8228 - val_loss: 0.4006 - val_accuracy: 0.8252\n",
            "Epoch 204/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.8228 - val_loss: 0.4007 - val_accuracy: 0.8252\n",
            "Epoch 205/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4432 - accuracy: 0.8228 - val_loss: 0.4004 - val_accuracy: 0.8252\n",
            "Epoch 206/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4430 - accuracy: 0.8228 - val_loss: 0.4001 - val_accuracy: 0.8252\n",
            "Epoch 207/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4431 - accuracy: 0.8228 - val_loss: 0.4005 - val_accuracy: 0.8252\n",
            "Epoch 208/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.8228 - val_loss: 0.4002 - val_accuracy: 0.8252\n",
            "Epoch 209/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4430 - accuracy: 0.8228 - val_loss: 0.4003 - val_accuracy: 0.8252\n",
            "Epoch 210/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4430 - accuracy: 0.8228 - val_loss: 0.4006 - val_accuracy: 0.8252\n",
            "Epoch 211/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4429 - accuracy: 0.8228 - val_loss: 0.4002 - val_accuracy: 0.8252\n",
            "Epoch 212/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4429 - accuracy: 0.8228 - val_loss: 0.4001 - val_accuracy: 0.8252\n",
            "Epoch 213/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4429 - accuracy: 0.8228 - val_loss: 0.4001 - val_accuracy: 0.8252\n",
            "Epoch 214/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4429 - accuracy: 0.8211 - val_loss: 0.4004 - val_accuracy: 0.8252\n",
            "Epoch 215/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8211 - val_loss: 0.4004 - val_accuracy: 0.8252\n",
            "Epoch 216/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4428 - accuracy: 0.8211 - val_loss: 0.3999 - val_accuracy: 0.8252\n",
            "Epoch 217/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8228 - val_loss: 0.4000 - val_accuracy: 0.8252\n",
            "Epoch 218/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8228 - val_loss: 0.4002 - val_accuracy: 0.8252\n",
            "Epoch 219/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4428 - accuracy: 0.8228 - val_loss: 0.4001 - val_accuracy: 0.8252\n",
            "Epoch 220/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8228 - val_loss: 0.4000 - val_accuracy: 0.8252\n",
            "Epoch 221/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4427 - accuracy: 0.8211 - val_loss: 0.3998 - val_accuracy: 0.8252\n",
            "Epoch 222/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8211 - val_loss: 0.3997 - val_accuracy: 0.8252\n",
            "Epoch 223/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8228 - val_loss: 0.3996 - val_accuracy: 0.8252\n",
            "Epoch 224/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8211 - val_loss: 0.3999 - val_accuracy: 0.8252\n",
            "Epoch 225/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8211 - val_loss: 0.3996 - val_accuracy: 0.8252\n",
            "Epoch 226/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8211 - val_loss: 0.3996 - val_accuracy: 0.8252\n",
            "Epoch 227/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4426 - accuracy: 0.8211 - val_loss: 0.3996 - val_accuracy: 0.8252\n",
            "Epoch 228/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4426 - accuracy: 0.8211 - val_loss: 0.3997 - val_accuracy: 0.8252\n",
            "Epoch 229/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4425 - accuracy: 0.8211 - val_loss: 0.3998 - val_accuracy: 0.8252\n",
            "Epoch 230/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4427 - accuracy: 0.8211 - val_loss: 0.3999 - val_accuracy: 0.8252\n",
            "Epoch 231/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4425 - accuracy: 0.8211 - val_loss: 0.3997 - val_accuracy: 0.8252\n",
            "Epoch 232/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8211 - val_loss: 0.3993 - val_accuracy: 0.8252\n",
            "Epoch 233/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4426 - accuracy: 0.8211 - val_loss: 0.3999 - val_accuracy: 0.8252\n",
            "Epoch 234/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8211 - val_loss: 0.3994 - val_accuracy: 0.8252\n",
            "Epoch 235/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8211 - val_loss: 0.3994 - val_accuracy: 0.8252\n",
            "Epoch 236/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4424 - accuracy: 0.8211 - val_loss: 0.3992 - val_accuracy: 0.8252\n",
            "Epoch 237/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4424 - accuracy: 0.8211 - val_loss: 0.3993 - val_accuracy: 0.8252\n",
            "Epoch 238/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.3993 - val_accuracy: 0.8252\n",
            "Epoch 239/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.3997 - val_accuracy: 0.8252\n",
            "Epoch 240/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.3996 - val_accuracy: 0.8252\n",
            "Epoch 241/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.3991 - val_accuracy: 0.8252\n",
            "Epoch 242/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8211 - val_loss: 0.3992 - val_accuracy: 0.8252\n",
            "Epoch 243/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8211 - val_loss: 0.3995 - val_accuracy: 0.8252\n",
            "Epoch 244/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.3993 - val_accuracy: 0.8252\n",
            "Epoch 245/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.3994 - val_accuracy: 0.8252\n",
            "Epoch 246/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8211 - val_loss: 0.3994 - val_accuracy: 0.8252\n",
            "Epoch 247/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.3993 - val_accuracy: 0.8252\n",
            "Epoch 248/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8211 - val_loss: 0.3995 - val_accuracy: 0.8252\n",
            "Epoch 249/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8211 - val_loss: 0.3994 - val_accuracy: 0.8252\n",
            "Epoch 250/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4423 - accuracy: 0.8211 - val_loss: 0.3991 - val_accuracy: 0.8252\n",
            "Epoch 251/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8211 - val_loss: 0.3990 - val_accuracy: 0.8252\n",
            "Epoch 252/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.8211 - val_loss: 0.3990 - val_accuracy: 0.8252\n",
            "Epoch 253/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4421 - accuracy: 0.8211 - val_loss: 0.3991 - val_accuracy: 0.8252\n",
            "Epoch 254/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4422 - accuracy: 0.8211 - val_loss: 0.3993 - val_accuracy: 0.8252\n",
            "Epoch 255/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8211 - val_loss: 0.3988 - val_accuracy: 0.8252\n",
            "Epoch 256/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4420 - accuracy: 0.8211 - val_loss: 0.3986 - val_accuracy: 0.8252\n",
            "Epoch 257/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8211 - val_loss: 0.3987 - val_accuracy: 0.8252\n",
            "Epoch 258/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4422 - accuracy: 0.8211 - val_loss: 0.3992 - val_accuracy: 0.8252\n",
            "Epoch 259/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8211 - val_loss: 0.3987 - val_accuracy: 0.8252\n",
            "Epoch 260/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4419 - accuracy: 0.8211 - val_loss: 0.3986 - val_accuracy: 0.8252\n",
            "Epoch 261/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8211 - val_loss: 0.3986 - val_accuracy: 0.8252\n",
            "Epoch 262/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.8211 - val_loss: 0.3987 - val_accuracy: 0.8252\n",
            "Epoch 263/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4421 - accuracy: 0.8211 - val_loss: 0.3988 - val_accuracy: 0.8252\n",
            "Epoch 264/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8211 - val_loss: 0.3986 - val_accuracy: 0.8252\n",
            "Epoch 265/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.8211 - val_loss: 0.3988 - val_accuracy: 0.8252\n",
            "Epoch 266/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8211 - val_loss: 0.3983 - val_accuracy: 0.8252\n",
            "Epoch 267/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4420 - accuracy: 0.8211 - val_loss: 0.3986 - val_accuracy: 0.8252\n",
            "Epoch 268/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4419 - accuracy: 0.8211 - val_loss: 0.3981 - val_accuracy: 0.8252\n",
            "Epoch 269/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4418 - accuracy: 0.8211 - val_loss: 0.3982 - val_accuracy: 0.8252\n",
            "Epoch 270/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.8211 - val_loss: 0.3987 - val_accuracy: 0.8252\n",
            "Epoch 271/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.8211 - val_loss: 0.3984 - val_accuracy: 0.8252\n",
            "Epoch 272/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4419 - accuracy: 0.8211 - val_loss: 0.3990 - val_accuracy: 0.8252\n",
            "Epoch 273/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4418 - accuracy: 0.8211 - val_loss: 0.3980 - val_accuracy: 0.8252\n",
            "Epoch 274/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4418 - accuracy: 0.8211 - val_loss: 0.3984 - val_accuracy: 0.8252\n",
            "Epoch 275/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3983 - val_accuracy: 0.8252\n",
            "Epoch 276/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4420 - accuracy: 0.8211 - val_loss: 0.3987 - val_accuracy: 0.8252\n",
            "Epoch 277/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3984 - val_accuracy: 0.8252\n",
            "Epoch 278/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3982 - val_accuracy: 0.8252\n",
            "Epoch 279/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3982 - val_accuracy: 0.8252\n",
            "Epoch 280/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4418 - accuracy: 0.8211 - val_loss: 0.3982 - val_accuracy: 0.8252\n",
            "Epoch 281/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3984 - val_accuracy: 0.8252\n",
            "Epoch 282/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3983 - val_accuracy: 0.8252\n",
            "Epoch 283/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8211 - val_loss: 0.3984 - val_accuracy: 0.8252\n",
            "Epoch 284/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3985 - val_accuracy: 0.8252\n",
            "Epoch 285/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4416 - accuracy: 0.8211 - val_loss: 0.3986 - val_accuracy: 0.8252\n",
            "Epoch 286/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3982 - val_accuracy: 0.8252\n",
            "Epoch 287/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8211 - val_loss: 0.3981 - val_accuracy: 0.8252\n",
            "Epoch 288/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3978 - val_accuracy: 0.8252\n",
            "Epoch 289/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8211 - val_loss: 0.3983 - val_accuracy: 0.8252\n",
            "Epoch 290/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3985 - val_accuracy: 0.8252\n",
            "Epoch 291/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3982 - val_accuracy: 0.8252\n",
            "Epoch 292/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4416 - accuracy: 0.8211 - val_loss: 0.3983 - val_accuracy: 0.8252\n",
            "Epoch 293/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3980 - val_accuracy: 0.8252\n",
            "Epoch 294/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3979 - val_accuracy: 0.8252\n",
            "Epoch 295/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3980 - val_accuracy: 0.8252\n",
            "Epoch 296/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4417 - accuracy: 0.8211 - val_loss: 0.3979 - val_accuracy: 0.8252\n",
            "Epoch 297/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3978 - val_accuracy: 0.8252\n",
            "Epoch 298/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3980 - val_accuracy: 0.8252\n",
            "Epoch 299/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3982 - val_accuracy: 0.8252\n",
            "Epoch 300/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 301/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3983 - val_accuracy: 0.8252\n",
            "Epoch 302/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8211 - val_loss: 0.3980 - val_accuracy: 0.8252\n",
            "Epoch 303/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8211 - val_loss: 0.3980 - val_accuracy: 0.8252\n",
            "Epoch 304/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 305/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8211 - val_loss: 0.3980 - val_accuracy: 0.8252\n",
            "Epoch 306/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8211 - val_loss: 0.3981 - val_accuracy: 0.8252\n",
            "Epoch 307/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8211 - val_loss: 0.3979 - val_accuracy: 0.8252\n",
            "Epoch 308/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 309/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3978 - val_accuracy: 0.8252\n",
            "Epoch 310/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4416 - accuracy: 0.8211 - val_loss: 0.3975 - val_accuracy: 0.8252\n",
            "Epoch 311/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3981 - val_accuracy: 0.8252\n",
            "Epoch 312/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 313/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4415 - accuracy: 0.8211 - val_loss: 0.3976 - val_accuracy: 0.8252\n",
            "Epoch 314/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 315/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3975 - val_accuracy: 0.8252\n",
            "Epoch 316/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3978 - val_accuracy: 0.8252\n",
            "Epoch 317/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3978 - val_accuracy: 0.8252\n",
            "Epoch 318/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4414 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 319/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3976 - val_accuracy: 0.8252\n",
            "Epoch 320/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3975 - val_accuracy: 0.8252\n",
            "Epoch 321/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 322/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4414 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 323/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 324/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3976 - val_accuracy: 0.8252\n",
            "Epoch 325/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 326/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3978 - val_accuracy: 0.8252\n",
            "Epoch 327/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3978 - val_accuracy: 0.8252\n",
            "Epoch 328/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3976 - val_accuracy: 0.8252\n",
            "Epoch 329/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3980 - val_accuracy: 0.8252\n",
            "Epoch 330/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 331/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3973 - val_accuracy: 0.8252\n",
            "Epoch 332/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3975 - val_accuracy: 0.8252\n",
            "Epoch 333/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3978 - val_accuracy: 0.8252\n",
            "Epoch 334/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3975 - val_accuracy: 0.8252\n",
            "Epoch 335/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3971 - val_accuracy: 0.8252\n",
            "Epoch 336/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3973 - val_accuracy: 0.8252\n",
            "Epoch 337/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 338/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 339/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 340/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3977 - val_accuracy: 0.8252\n",
            "Epoch 341/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4413 - accuracy: 0.8211 - val_loss: 0.3972 - val_accuracy: 0.8252\n",
            "Epoch 342/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3972 - val_accuracy: 0.8252\n",
            "Epoch 343/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3971 - val_accuracy: 0.8252\n",
            "Epoch 344/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3976 - val_accuracy: 0.8252\n",
            "Epoch 345/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 346/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3971 - val_accuracy: 0.8252\n",
            "Epoch 347/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 348/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 349/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3971 - val_accuracy: 0.8252\n",
            "Epoch 350/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4412 - accuracy: 0.8211 - val_loss: 0.3972 - val_accuracy: 0.8252\n",
            "Epoch 351/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 352/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3973 - val_accuracy: 0.8252\n",
            "Epoch 353/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 354/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 355/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3971 - val_accuracy: 0.8252\n",
            "Epoch 356/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 357/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 358/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3973 - val_accuracy: 0.8252\n",
            "Epoch 359/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3969 - val_accuracy: 0.8252\n",
            "Epoch 360/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3971 - val_accuracy: 0.8252\n",
            "Epoch 361/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 362/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 363/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3972 - val_accuracy: 0.8252\n",
            "Epoch 364/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3973 - val_accuracy: 0.8252\n",
            "Epoch 365/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 366/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 367/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3969 - val_accuracy: 0.8252\n",
            "Epoch 368/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 369/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 370/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3969 - val_accuracy: 0.8252\n",
            "Epoch 371/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 372/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3972 - val_accuracy: 0.8252\n",
            "Epoch 373/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 374/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3971 - val_accuracy: 0.8252\n",
            "Epoch 375/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 376/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3972 - val_accuracy: 0.8252\n",
            "Epoch 377/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3969 - val_accuracy: 0.8252\n",
            "Epoch 378/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3976 - val_accuracy: 0.8252\n",
            "Epoch 379/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3974 - val_accuracy: 0.8252\n",
            "Epoch 380/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 381/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 382/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 383/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3969 - val_accuracy: 0.8252\n",
            "Epoch 384/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3972 - val_accuracy: 0.8252\n",
            "Epoch 385/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 386/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4411 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 387/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3967 - val_accuracy: 0.8252\n",
            "Epoch 388/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4410 - accuracy: 0.8211 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 389/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 390/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3969 - val_accuracy: 0.8252\n",
            "Epoch 391/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3967 - val_accuracy: 0.8252\n",
            "Epoch 392/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3967 - val_accuracy: 0.8252\n",
            "Epoch 393/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3969 - val_accuracy: 0.8252\n",
            "Epoch 394/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 395/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3967 - val_accuracy: 0.8252\n",
            "Epoch 396/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 397/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3967 - val_accuracy: 0.8252\n",
            "Epoch 398/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3970 - val_accuracy: 0.8252\n",
            "Epoch 399/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 400/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 401/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 402/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 403/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3967 - val_accuracy: 0.8252\n",
            "Epoch 404/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4409 - accuracy: 0.8211 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 405/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 406/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8211 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 407/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8228 - val_loss: 0.3967 - val_accuracy: 0.8252\n",
            "Epoch 408/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 409/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 410/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8211 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 411/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8228 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 412/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8211 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 413/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8228 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 414/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8228 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 415/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4409 - accuracy: 0.8228 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 416/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8246 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 417/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8228 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 418/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8228 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 419/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 420/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 421/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8228 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 422/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 423/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8228 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 424/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 425/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 426/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3969 - val_accuracy: 0.8252\n",
            "Epoch 427/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4408 - accuracy: 0.8228 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 428/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4410 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 429/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4410 - accuracy: 0.8246 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 430/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 431/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 432/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 433/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 434/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 435/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 436/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 437/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 438/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 439/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 440/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 441/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 442/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 443/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 444/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8246 - val_loss: 0.3966 - val_accuracy: 0.8252\n",
            "Epoch 445/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4408 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 446/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 447/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4408 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 448/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 449/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 450/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 451/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3968 - val_accuracy: 0.8252\n",
            "Epoch 452/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 453/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 454/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 455/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 456/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 457/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 458/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 459/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 460/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4408 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 461/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 462/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 463/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 464/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 465/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 466/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 467/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 468/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 469/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 470/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 471/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 472/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 473/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 474/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 475/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 476/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 477/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 478/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 479/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 480/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 481/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 482/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 483/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 484/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3965 - val_accuracy: 0.8252\n",
            "Epoch 485/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 486/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 487/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 488/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 489/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 490/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 491/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 492/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 493/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 494/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 495/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 496/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 497/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 498/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3963 - val_accuracy: 0.8252\n",
            "Epoch 499/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 500/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 501/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 502/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 503/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 504/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 505/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 506/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 507/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 508/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 509/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4407 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 510/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 511/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 512/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 513/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 514/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 515/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 516/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 517/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 518/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 519/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 520/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 521/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 522/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3954 - val_accuracy: 0.8252\n",
            "Epoch 523/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 524/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 525/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 526/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 527/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 528/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 529/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4406 - accuracy: 0.8246 - val_loss: 0.3964 - val_accuracy: 0.8252\n",
            "Epoch 530/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 531/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 532/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 533/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 534/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 535/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 536/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 537/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 538/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 539/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 540/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 541/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 542/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 543/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 544/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 545/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 546/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 547/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 548/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 549/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 550/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 551/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 552/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 553/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 554/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 555/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 556/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 557/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 558/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 559/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 560/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 561/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 562/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 563/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 564/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3961 - val_accuracy: 0.8252\n",
            "Epoch 565/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 566/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 567/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 568/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 569/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 570/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 571/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 572/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 573/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 574/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 575/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 576/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 577/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3962 - val_accuracy: 0.8252\n",
            "Epoch 578/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 579/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 580/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3954 - val_accuracy: 0.8252\n",
            "Epoch 581/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 582/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 583/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 584/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 585/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 586/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 587/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 588/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 589/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 590/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 591/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 592/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 593/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4406 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 594/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 595/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 596/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 597/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 598/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 599/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 600/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 601/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 602/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3954 - val_accuracy: 0.8252\n",
            "Epoch 603/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 604/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 605/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 606/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 607/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 608/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 609/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 610/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 611/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4405 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 612/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 613/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 614/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 615/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3950 - val_accuracy: 0.8252\n",
            "Epoch 616/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 617/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 618/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8228 - val_loss: 0.3950 - val_accuracy: 0.8252\n",
            "Epoch 619/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 620/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 621/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 622/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 623/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 624/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 625/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 626/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4402 - accuracy: 0.8228 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 627/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 628/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 629/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4405 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 630/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 631/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 632/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 633/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 634/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 635/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 636/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 637/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 638/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 639/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3954 - val_accuracy: 0.8252\n",
            "Epoch 640/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3951 - val_accuracy: 0.8252\n",
            "Epoch 641/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 642/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 643/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 644/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 645/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 646/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3954 - val_accuracy: 0.8252\n",
            "Epoch 647/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 648/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 649/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 650/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 651/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3958 - val_accuracy: 0.8252\n",
            "Epoch 652/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 653/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 654/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 655/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3954 - val_accuracy: 0.8252\n",
            "Epoch 656/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 657/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4402 - accuracy: 0.8246 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 658/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3954 - val_accuracy: 0.8252\n",
            "Epoch 659/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 660/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3960 - val_accuracy: 0.8252\n",
            "Epoch 661/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3955 - val_accuracy: 0.8252\n",
            "Epoch 662/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4404 - accuracy: 0.8246 - val_loss: 0.3952 - val_accuracy: 0.8252\n",
            "Epoch 663/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3959 - val_accuracy: 0.8252\n",
            "Epoch 664/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3957 - val_accuracy: 0.8252\n",
            "Epoch 665/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 666/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8246 - val_loss: 0.3956 - val_accuracy: 0.8252\n",
            "Epoch 667/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4404 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "Epoch 668/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4403 - accuracy: 0.8228 - val_loss: 0.3953 - val_accuracy: 0.8252\n",
            "6/6 [==============================] - 0s 4ms/step - loss: 0.4246 - accuracy: 0.8427\n",
            "Epoch 1/1000\n",
            "36/36 [==============================] - 1s 12ms/step - loss: 0.6575 - accuracy: 0.6491 - val_loss: 0.6013 - val_accuracy: 0.7203\n",
            "Epoch 2/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6454 - accuracy: 0.6596 - val_loss: 0.5865 - val_accuracy: 0.7203\n",
            "Epoch 3/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.6338 - accuracy: 0.6649 - val_loss: 0.5755 - val_accuracy: 0.7273\n",
            "Epoch 4/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6232 - accuracy: 0.6754 - val_loss: 0.5646 - val_accuracy: 0.7413\n",
            "Epoch 5/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.6136 - accuracy: 0.6860 - val_loss: 0.5545 - val_accuracy: 0.7622\n",
            "Epoch 6/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.6047 - accuracy: 0.6877 - val_loss: 0.5447 - val_accuracy: 0.7692\n",
            "Epoch 7/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5963 - accuracy: 0.6895 - val_loss: 0.5376 - val_accuracy: 0.7902\n",
            "Epoch 8/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5885 - accuracy: 0.7000 - val_loss: 0.5296 - val_accuracy: 0.7902\n",
            "Epoch 9/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5813 - accuracy: 0.7018 - val_loss: 0.5224 - val_accuracy: 0.7902\n",
            "Epoch 10/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5745 - accuracy: 0.7053 - val_loss: 0.5162 - val_accuracy: 0.7902\n",
            "Epoch 11/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5684 - accuracy: 0.7123 - val_loss: 0.5095 - val_accuracy: 0.8042\n",
            "Epoch 12/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5624 - accuracy: 0.7228 - val_loss: 0.5043 - val_accuracy: 0.7972\n",
            "Epoch 13/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5569 - accuracy: 0.7298 - val_loss: 0.4987 - val_accuracy: 0.8182\n",
            "Epoch 14/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5520 - accuracy: 0.7439 - val_loss: 0.4947 - val_accuracy: 0.8182\n",
            "Epoch 15/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5469 - accuracy: 0.7456 - val_loss: 0.4895 - val_accuracy: 0.8182\n",
            "Epoch 16/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5423 - accuracy: 0.7526 - val_loss: 0.4856 - val_accuracy: 0.8042\n",
            "Epoch 17/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5381 - accuracy: 0.7579 - val_loss: 0.4813 - val_accuracy: 0.8112\n",
            "Epoch 18/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5341 - accuracy: 0.7579 - val_loss: 0.4783 - val_accuracy: 0.8042\n",
            "Epoch 19/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5305 - accuracy: 0.7632 - val_loss: 0.4745 - val_accuracy: 0.8112\n",
            "Epoch 20/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5269 - accuracy: 0.7649 - val_loss: 0.4721 - val_accuracy: 0.8182\n",
            "Epoch 21/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5235 - accuracy: 0.7667 - val_loss: 0.4687 - val_accuracy: 0.8182\n",
            "Epoch 22/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5203 - accuracy: 0.7684 - val_loss: 0.4659 - val_accuracy: 0.8182\n",
            "Epoch 23/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5173 - accuracy: 0.7789 - val_loss: 0.4632 - val_accuracy: 0.8182\n",
            "Epoch 24/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5146 - accuracy: 0.7789 - val_loss: 0.4606 - val_accuracy: 0.8112\n",
            "Epoch 25/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.5118 - accuracy: 0.7789 - val_loss: 0.4577 - val_accuracy: 0.8112\n",
            "Epoch 26/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5094 - accuracy: 0.7772 - val_loss: 0.4558 - val_accuracy: 0.8112\n",
            "Epoch 27/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5070 - accuracy: 0.7807 - val_loss: 0.4530 - val_accuracy: 0.8112\n",
            "Epoch 28/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5048 - accuracy: 0.7825 - val_loss: 0.4511 - val_accuracy: 0.8112\n",
            "Epoch 29/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.5025 - accuracy: 0.7860 - val_loss: 0.4493 - val_accuracy: 0.8112\n",
            "Epoch 30/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.5004 - accuracy: 0.7860 - val_loss: 0.4474 - val_accuracy: 0.8112\n",
            "Epoch 31/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4986 - accuracy: 0.7860 - val_loss: 0.4455 - val_accuracy: 0.8112\n",
            "Epoch 32/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4968 - accuracy: 0.7895 - val_loss: 0.4441 - val_accuracy: 0.8112\n",
            "Epoch 33/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4949 - accuracy: 0.7895 - val_loss: 0.4419 - val_accuracy: 0.8112\n",
            "Epoch 34/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.7912 - val_loss: 0.4405 - val_accuracy: 0.8112\n",
            "Epoch 35/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4916 - accuracy: 0.7912 - val_loss: 0.4391 - val_accuracy: 0.8112\n",
            "Epoch 36/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4901 - accuracy: 0.7877 - val_loss: 0.4378 - val_accuracy: 0.8112\n",
            "Epoch 37/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4888 - accuracy: 0.7877 - val_loss: 0.4364 - val_accuracy: 0.8112\n",
            "Epoch 38/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4873 - accuracy: 0.7877 - val_loss: 0.4354 - val_accuracy: 0.8112\n",
            "Epoch 39/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4861 - accuracy: 0.7877 - val_loss: 0.4343 - val_accuracy: 0.8112\n",
            "Epoch 40/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4847 - accuracy: 0.7860 - val_loss: 0.4330 - val_accuracy: 0.8112\n",
            "Epoch 41/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4836 - accuracy: 0.7860 - val_loss: 0.4320 - val_accuracy: 0.8112\n",
            "Epoch 42/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4824 - accuracy: 0.7860 - val_loss: 0.4311 - val_accuracy: 0.8112\n",
            "Epoch 43/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4813 - accuracy: 0.7860 - val_loss: 0.4295 - val_accuracy: 0.8112\n",
            "Epoch 44/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4802 - accuracy: 0.7860 - val_loss: 0.4283 - val_accuracy: 0.8112\n",
            "Epoch 45/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4792 - accuracy: 0.7877 - val_loss: 0.4274 - val_accuracy: 0.8112\n",
            "Epoch 46/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4783 - accuracy: 0.7947 - val_loss: 0.4265 - val_accuracy: 0.8112\n",
            "Epoch 47/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4775 - accuracy: 0.8018 - val_loss: 0.4256 - val_accuracy: 0.8112\n",
            "Epoch 48/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4766 - accuracy: 0.8018 - val_loss: 0.4250 - val_accuracy: 0.8182\n",
            "Epoch 49/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4758 - accuracy: 0.8018 - val_loss: 0.4244 - val_accuracy: 0.8182\n",
            "Epoch 50/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4748 - accuracy: 0.8018 - val_loss: 0.4235 - val_accuracy: 0.8182\n",
            "Epoch 51/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4741 - accuracy: 0.8000 - val_loss: 0.4225 - val_accuracy: 0.8182\n",
            "Epoch 52/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4734 - accuracy: 0.8000 - val_loss: 0.4217 - val_accuracy: 0.8182\n",
            "Epoch 53/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4728 - accuracy: 0.8035 - val_loss: 0.4220 - val_accuracy: 0.8182\n",
            "Epoch 54/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4720 - accuracy: 0.8035 - val_loss: 0.4204 - val_accuracy: 0.8182\n",
            "Epoch 55/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4712 - accuracy: 0.8053 - val_loss: 0.4201 - val_accuracy: 0.8182\n",
            "Epoch 56/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4706 - accuracy: 0.8018 - val_loss: 0.4199 - val_accuracy: 0.8252\n",
            "Epoch 57/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4700 - accuracy: 0.8053 - val_loss: 0.4187 - val_accuracy: 0.8112\n",
            "Epoch 58/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4694 - accuracy: 0.8035 - val_loss: 0.4186 - val_accuracy: 0.8182\n",
            "Epoch 59/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4688 - accuracy: 0.8053 - val_loss: 0.4179 - val_accuracy: 0.8182\n",
            "Epoch 60/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4683 - accuracy: 0.8035 - val_loss: 0.4174 - val_accuracy: 0.8182\n",
            "Epoch 61/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4677 - accuracy: 0.8035 - val_loss: 0.4167 - val_accuracy: 0.8182\n",
            "Epoch 62/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4672 - accuracy: 0.8035 - val_loss: 0.4165 - val_accuracy: 0.8182\n",
            "Epoch 63/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4668 - accuracy: 0.8035 - val_loss: 0.4158 - val_accuracy: 0.8182\n",
            "Epoch 64/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4663 - accuracy: 0.8035 - val_loss: 0.4152 - val_accuracy: 0.8182\n",
            "Epoch 65/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4658 - accuracy: 0.8000 - val_loss: 0.4149 - val_accuracy: 0.8182\n",
            "Epoch 66/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4654 - accuracy: 0.8000 - val_loss: 0.4146 - val_accuracy: 0.8182\n",
            "Epoch 67/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4651 - accuracy: 0.8018 - val_loss: 0.4138 - val_accuracy: 0.8182\n",
            "Epoch 68/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4646 - accuracy: 0.7982 - val_loss: 0.4138 - val_accuracy: 0.8182\n",
            "Epoch 69/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4642 - accuracy: 0.8035 - val_loss: 0.4133 - val_accuracy: 0.8182\n",
            "Epoch 70/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4638 - accuracy: 0.8035 - val_loss: 0.4129 - val_accuracy: 0.8182\n",
            "Epoch 71/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4634 - accuracy: 0.8035 - val_loss: 0.4126 - val_accuracy: 0.8182\n",
            "Epoch 72/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4630 - accuracy: 0.8018 - val_loss: 0.4119 - val_accuracy: 0.8182\n",
            "Epoch 73/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4626 - accuracy: 0.8018 - val_loss: 0.4119 - val_accuracy: 0.8182\n",
            "Epoch 74/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4624 - accuracy: 0.8035 - val_loss: 0.4114 - val_accuracy: 0.8252\n",
            "Epoch 75/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4620 - accuracy: 0.8035 - val_loss: 0.4106 - val_accuracy: 0.8182\n",
            "Epoch 76/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4617 - accuracy: 0.8053 - val_loss: 0.4103 - val_accuracy: 0.8252\n",
            "Epoch 77/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4615 - accuracy: 0.8088 - val_loss: 0.4104 - val_accuracy: 0.8252\n",
            "Epoch 78/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4612 - accuracy: 0.8088 - val_loss: 0.4101 - val_accuracy: 0.8252\n",
            "Epoch 79/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4609 - accuracy: 0.8088 - val_loss: 0.4093 - val_accuracy: 0.8252\n",
            "Epoch 80/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4605 - accuracy: 0.8088 - val_loss: 0.4091 - val_accuracy: 0.8252\n",
            "Epoch 81/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4605 - accuracy: 0.8088 - val_loss: 0.4085 - val_accuracy: 0.8252\n",
            "Epoch 82/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4601 - accuracy: 0.8088 - val_loss: 0.4092 - val_accuracy: 0.8252\n",
            "Epoch 83/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4598 - accuracy: 0.8088 - val_loss: 0.4087 - val_accuracy: 0.8252\n",
            "Epoch 84/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4595 - accuracy: 0.8088 - val_loss: 0.4083 - val_accuracy: 0.8252\n",
            "Epoch 85/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4594 - accuracy: 0.8088 - val_loss: 0.4076 - val_accuracy: 0.8252\n",
            "Epoch 86/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4591 - accuracy: 0.8088 - val_loss: 0.4080 - val_accuracy: 0.8252\n",
            "Epoch 87/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4589 - accuracy: 0.8088 - val_loss: 0.4077 - val_accuracy: 0.8252\n",
            "Epoch 88/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4587 - accuracy: 0.8088 - val_loss: 0.4073 - val_accuracy: 0.8322\n",
            "Epoch 89/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4584 - accuracy: 0.8088 - val_loss: 0.4074 - val_accuracy: 0.8322\n",
            "Epoch 90/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4582 - accuracy: 0.8088 - val_loss: 0.4071 - val_accuracy: 0.8322\n",
            "Epoch 91/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4581 - accuracy: 0.8105 - val_loss: 0.4066 - val_accuracy: 0.8322\n",
            "Epoch 92/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4578 - accuracy: 0.8088 - val_loss: 0.4063 - val_accuracy: 0.8322\n",
            "Epoch 93/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.8088 - val_loss: 0.4067 - val_accuracy: 0.8322\n",
            "Epoch 94/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4575 - accuracy: 0.8105 - val_loss: 0.4059 - val_accuracy: 0.8322\n",
            "Epoch 95/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4573 - accuracy: 0.8105 - val_loss: 0.4060 - val_accuracy: 0.8322\n",
            "Epoch 96/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4572 - accuracy: 0.8105 - val_loss: 0.4061 - val_accuracy: 0.8322\n",
            "Epoch 97/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4571 - accuracy: 0.8105 - val_loss: 0.4056 - val_accuracy: 0.8322\n",
            "Epoch 98/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4570 - accuracy: 0.8105 - val_loss: 0.4050 - val_accuracy: 0.8322\n",
            "Epoch 99/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4566 - accuracy: 0.8105 - val_loss: 0.4050 - val_accuracy: 0.8322\n",
            "Epoch 100/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4564 - accuracy: 0.8105 - val_loss: 0.4051 - val_accuracy: 0.8322\n",
            "Epoch 101/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4563 - accuracy: 0.8105 - val_loss: 0.4052 - val_accuracy: 0.8322\n",
            "Epoch 102/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4562 - accuracy: 0.8105 - val_loss: 0.4049 - val_accuracy: 0.8322\n",
            "Epoch 103/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4561 - accuracy: 0.8105 - val_loss: 0.4045 - val_accuracy: 0.8322\n",
            "Epoch 104/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4559 - accuracy: 0.8123 - val_loss: 0.4042 - val_accuracy: 0.8322\n",
            "Epoch 105/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4557 - accuracy: 0.8123 - val_loss: 0.4042 - val_accuracy: 0.8322\n",
            "Epoch 106/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4558 - accuracy: 0.8105 - val_loss: 0.4039 - val_accuracy: 0.8322\n",
            "Epoch 107/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4556 - accuracy: 0.8105 - val_loss: 0.4042 - val_accuracy: 0.8322\n",
            "Epoch 108/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4554 - accuracy: 0.8105 - val_loss: 0.4039 - val_accuracy: 0.8322\n",
            "Epoch 109/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4553 - accuracy: 0.8105 - val_loss: 0.4035 - val_accuracy: 0.8322\n",
            "Epoch 110/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.8123 - val_loss: 0.4035 - val_accuracy: 0.8322\n",
            "Epoch 111/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4551 - accuracy: 0.8123 - val_loss: 0.4036 - val_accuracy: 0.8322\n",
            "Epoch 112/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4548 - accuracy: 0.8123 - val_loss: 0.4031 - val_accuracy: 0.8322\n",
            "Epoch 113/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4548 - accuracy: 0.8123 - val_loss: 0.4029 - val_accuracy: 0.8322\n",
            "Epoch 114/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4547 - accuracy: 0.8105 - val_loss: 0.4032 - val_accuracy: 0.8322\n",
            "Epoch 115/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4547 - accuracy: 0.8123 - val_loss: 0.4028 - val_accuracy: 0.8322\n",
            "Epoch 116/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.8105 - val_loss: 0.4025 - val_accuracy: 0.8252\n",
            "Epoch 117/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4544 - accuracy: 0.8088 - val_loss: 0.4026 - val_accuracy: 0.8252\n",
            "Epoch 118/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4543 - accuracy: 0.8088 - val_loss: 0.4025 - val_accuracy: 0.8252\n",
            "Epoch 119/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4543 - accuracy: 0.8088 - val_loss: 0.4020 - val_accuracy: 0.8252\n",
            "Epoch 120/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4541 - accuracy: 0.8105 - val_loss: 0.4019 - val_accuracy: 0.8252\n",
            "Epoch 121/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4541 - accuracy: 0.8088 - val_loss: 0.4025 - val_accuracy: 0.8252\n",
            "Epoch 122/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4539 - accuracy: 0.8105 - val_loss: 0.4021 - val_accuracy: 0.8252\n",
            "Epoch 123/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.8105 - val_loss: 0.4020 - val_accuracy: 0.8252\n",
            "Epoch 124/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4538 - accuracy: 0.8105 - val_loss: 0.4018 - val_accuracy: 0.8252\n",
            "Epoch 125/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.8105 - val_loss: 0.4017 - val_accuracy: 0.8252\n",
            "Epoch 126/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.8105 - val_loss: 0.4015 - val_accuracy: 0.8252\n",
            "Epoch 127/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4536 - accuracy: 0.8105 - val_loss: 0.4013 - val_accuracy: 0.8252\n",
            "Epoch 128/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4534 - accuracy: 0.8105 - val_loss: 0.4011 - val_accuracy: 0.8252\n",
            "Epoch 129/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4535 - accuracy: 0.8105 - val_loss: 0.4014 - val_accuracy: 0.8252\n",
            "Epoch 130/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4533 - accuracy: 0.8105 - val_loss: 0.4011 - val_accuracy: 0.8252\n",
            "Epoch 131/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4532 - accuracy: 0.8105 - val_loss: 0.4009 - val_accuracy: 0.8252\n",
            "Epoch 132/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4532 - accuracy: 0.8105 - val_loss: 0.4009 - val_accuracy: 0.8252\n",
            "Epoch 133/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4530 - accuracy: 0.8105 - val_loss: 0.4005 - val_accuracy: 0.8252\n",
            "Epoch 134/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4531 - accuracy: 0.8105 - val_loss: 0.4001 - val_accuracy: 0.8252\n",
            "Epoch 135/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4528 - accuracy: 0.8105 - val_loss: 0.4006 - val_accuracy: 0.8252\n",
            "Epoch 136/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4529 - accuracy: 0.8105 - val_loss: 0.4010 - val_accuracy: 0.8252\n",
            "Epoch 137/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.8105 - val_loss: 0.4003 - val_accuracy: 0.8252\n",
            "Epoch 138/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4527 - accuracy: 0.8105 - val_loss: 0.4003 - val_accuracy: 0.8252\n",
            "Epoch 139/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4526 - accuracy: 0.8105 - val_loss: 0.4001 - val_accuracy: 0.8252\n",
            "Epoch 140/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.8105 - val_loss: 0.4001 - val_accuracy: 0.8252\n",
            "Epoch 141/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.8105 - val_loss: 0.4004 - val_accuracy: 0.8252\n",
            "Epoch 142/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4526 - accuracy: 0.8105 - val_loss: 0.4003 - val_accuracy: 0.8252\n",
            "Epoch 143/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.8105 - val_loss: 0.3998 - val_accuracy: 0.8252\n",
            "Epoch 144/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4525 - accuracy: 0.8105 - val_loss: 0.4000 - val_accuracy: 0.8252\n",
            "Epoch 145/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4523 - accuracy: 0.8105 - val_loss: 0.4001 - val_accuracy: 0.8252\n",
            "Epoch 146/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4524 - accuracy: 0.8105 - val_loss: 0.3993 - val_accuracy: 0.8252\n",
            "Epoch 147/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.8105 - val_loss: 0.3999 - val_accuracy: 0.8252\n",
            "Epoch 148/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4522 - accuracy: 0.8105 - val_loss: 0.3999 - val_accuracy: 0.8252\n",
            "Epoch 149/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.8105 - val_loss: 0.3996 - val_accuracy: 0.8252\n",
            "Epoch 150/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4521 - accuracy: 0.8105 - val_loss: 0.3993 - val_accuracy: 0.8392\n",
            "Epoch 151/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4520 - accuracy: 0.8105 - val_loss: 0.3992 - val_accuracy: 0.8392\n",
            "Epoch 152/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4519 - accuracy: 0.8105 - val_loss: 0.3992 - val_accuracy: 0.8392\n",
            "Epoch 153/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4521 - accuracy: 0.8105 - val_loss: 0.3997 - val_accuracy: 0.8252\n",
            "Epoch 154/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4519 - accuracy: 0.8105 - val_loss: 0.3991 - val_accuracy: 0.8252\n",
            "Epoch 155/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4518 - accuracy: 0.8105 - val_loss: 0.3990 - val_accuracy: 0.8392\n",
            "Epoch 156/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.8105 - val_loss: 0.3988 - val_accuracy: 0.8392\n",
            "Epoch 157/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.8105 - val_loss: 0.3989 - val_accuracy: 0.8392\n",
            "Epoch 158/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4516 - accuracy: 0.8105 - val_loss: 0.3990 - val_accuracy: 0.8392\n",
            "Epoch 159/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.8105 - val_loss: 0.3992 - val_accuracy: 0.8392\n",
            "Epoch 160/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4516 - accuracy: 0.8105 - val_loss: 0.3988 - val_accuracy: 0.8392\n",
            "Epoch 161/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4515 - accuracy: 0.8105 - val_loss: 0.3987 - val_accuracy: 0.8392\n",
            "Epoch 162/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4515 - accuracy: 0.8105 - val_loss: 0.3989 - val_accuracy: 0.8392\n",
            "Epoch 163/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4514 - accuracy: 0.8123 - val_loss: 0.3988 - val_accuracy: 0.8392\n",
            "Epoch 164/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4517 - accuracy: 0.8105 - val_loss: 0.3985 - val_accuracy: 0.8392\n",
            "Epoch 165/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8123 - val_loss: 0.3986 - val_accuracy: 0.8392\n",
            "Epoch 166/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4514 - accuracy: 0.8123 - val_loss: 0.3987 - val_accuracy: 0.8392\n",
            "Epoch 167/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.8105 - val_loss: 0.3987 - val_accuracy: 0.8392\n",
            "Epoch 168/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.8105 - val_loss: 0.3982 - val_accuracy: 0.8392\n",
            "Epoch 169/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4513 - accuracy: 0.8105 - val_loss: 0.3988 - val_accuracy: 0.8392\n",
            "Epoch 170/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8123 - val_loss: 0.3987 - val_accuracy: 0.8392\n",
            "Epoch 171/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8105 - val_loss: 0.3983 - val_accuracy: 0.8392\n",
            "Epoch 172/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8105 - val_loss: 0.3984 - val_accuracy: 0.8392\n",
            "Epoch 173/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8105 - val_loss: 0.3982 - val_accuracy: 0.8392\n",
            "Epoch 174/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.8105 - val_loss: 0.3983 - val_accuracy: 0.8392\n",
            "Epoch 175/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4511 - accuracy: 0.8088 - val_loss: 0.3984 - val_accuracy: 0.8392\n",
            "Epoch 176/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4510 - accuracy: 0.8088 - val_loss: 0.3982 - val_accuracy: 0.8392\n",
            "Epoch 177/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.8105 - val_loss: 0.3981 - val_accuracy: 0.8392\n",
            "Epoch 178/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4513 - accuracy: 0.8105 - val_loss: 0.3976 - val_accuracy: 0.8392\n",
            "Epoch 179/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4509 - accuracy: 0.8105 - val_loss: 0.3979 - val_accuracy: 0.8392\n",
            "Epoch 180/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4508 - accuracy: 0.8105 - val_loss: 0.3979 - val_accuracy: 0.8392\n",
            "Epoch 181/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4509 - accuracy: 0.8105 - val_loss: 0.3984 - val_accuracy: 0.8392\n",
            "Epoch 182/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.8088 - val_loss: 0.3979 - val_accuracy: 0.8392\n",
            "Epoch 183/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4508 - accuracy: 0.8105 - val_loss: 0.3978 - val_accuracy: 0.8392\n",
            "Epoch 184/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4507 - accuracy: 0.8105 - val_loss: 0.3982 - val_accuracy: 0.8392\n",
            "Epoch 185/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8105 - val_loss: 0.3977 - val_accuracy: 0.8392\n",
            "Epoch 186/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.8105 - val_loss: 0.3975 - val_accuracy: 0.8392\n",
            "Epoch 187/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4507 - accuracy: 0.8105 - val_loss: 0.3977 - val_accuracy: 0.8392\n",
            "Epoch 188/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4506 - accuracy: 0.8105 - val_loss: 0.3977 - val_accuracy: 0.8392\n",
            "Epoch 189/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.8105 - val_loss: 0.3977 - val_accuracy: 0.8392\n",
            "Epoch 190/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8105 - val_loss: 0.3976 - val_accuracy: 0.8392\n",
            "Epoch 191/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8105 - val_loss: 0.3973 - val_accuracy: 0.8392\n",
            "Epoch 192/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4505 - accuracy: 0.8105 - val_loss: 0.3977 - val_accuracy: 0.8392\n",
            "Epoch 193/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4506 - accuracy: 0.8105 - val_loss: 0.3972 - val_accuracy: 0.8392\n",
            "Epoch 194/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4504 - accuracy: 0.8105 - val_loss: 0.3972 - val_accuracy: 0.8392\n",
            "Epoch 195/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4504 - accuracy: 0.8105 - val_loss: 0.3975 - val_accuracy: 0.8392\n",
            "Epoch 196/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4503 - accuracy: 0.8105 - val_loss: 0.3972 - val_accuracy: 0.8392\n",
            "Epoch 197/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.8105 - val_loss: 0.3973 - val_accuracy: 0.8392\n",
            "Epoch 198/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4504 - accuracy: 0.8105 - val_loss: 0.3974 - val_accuracy: 0.8392\n",
            "Epoch 199/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4503 - accuracy: 0.8105 - val_loss: 0.3970 - val_accuracy: 0.8392\n",
            "Epoch 200/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.8105 - val_loss: 0.3971 - val_accuracy: 0.8392\n",
            "Epoch 201/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.8105 - val_loss: 0.3974 - val_accuracy: 0.8392\n",
            "Epoch 202/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8105 - val_loss: 0.3973 - val_accuracy: 0.8392\n",
            "Epoch 203/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8105 - val_loss: 0.3970 - val_accuracy: 0.8392\n",
            "Epoch 204/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4503 - accuracy: 0.8105 - val_loss: 0.3968 - val_accuracy: 0.8392\n",
            "Epoch 205/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8123 - val_loss: 0.3971 - val_accuracy: 0.8392\n",
            "Epoch 206/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8105 - val_loss: 0.3967 - val_accuracy: 0.8392\n",
            "Epoch 207/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8123 - val_loss: 0.3967 - val_accuracy: 0.8392\n",
            "Epoch 208/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4501 - accuracy: 0.8105 - val_loss: 0.3968 - val_accuracy: 0.8392\n",
            "Epoch 209/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4503 - accuracy: 0.8105 - val_loss: 0.3974 - val_accuracy: 0.8392\n",
            "Epoch 210/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4502 - accuracy: 0.8123 - val_loss: 0.3970 - val_accuracy: 0.8392\n",
            "Epoch 211/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.8105 - val_loss: 0.3970 - val_accuracy: 0.8392\n",
            "Epoch 212/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4501 - accuracy: 0.8105 - val_loss: 0.3966 - val_accuracy: 0.8392\n",
            "Epoch 213/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.8123 - val_loss: 0.3970 - val_accuracy: 0.8392\n",
            "Epoch 214/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.8105 - val_loss: 0.3969 - val_accuracy: 0.8392\n",
            "Epoch 215/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4501 - accuracy: 0.8105 - val_loss: 0.3970 - val_accuracy: 0.8392\n",
            "Epoch 216/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4499 - accuracy: 0.8123 - val_loss: 0.3964 - val_accuracy: 0.8392\n",
            "Epoch 217/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.8105 - val_loss: 0.3968 - val_accuracy: 0.8392\n",
            "Epoch 218/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.8105 - val_loss: 0.3966 - val_accuracy: 0.8392\n",
            "Epoch 219/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4500 - accuracy: 0.8123 - val_loss: 0.3963 - val_accuracy: 0.8392\n",
            "Epoch 220/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4499 - accuracy: 0.8123 - val_loss: 0.3967 - val_accuracy: 0.8392\n",
            "Epoch 221/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8123 - val_loss: 0.3965 - val_accuracy: 0.8392\n",
            "Epoch 222/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4499 - accuracy: 0.8123 - val_loss: 0.3967 - val_accuracy: 0.8392\n",
            "Epoch 223/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4500 - accuracy: 0.8123 - val_loss: 0.3961 - val_accuracy: 0.8392\n",
            "Epoch 224/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8123 - val_loss: 0.3963 - val_accuracy: 0.8392\n",
            "Epoch 225/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8123 - val_loss: 0.3963 - val_accuracy: 0.8392\n",
            "Epoch 226/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8123 - val_loss: 0.3963 - val_accuracy: 0.8392\n",
            "Epoch 227/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8123 - val_loss: 0.3963 - val_accuracy: 0.8392\n",
            "Epoch 228/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4499 - accuracy: 0.8123 - val_loss: 0.3959 - val_accuracy: 0.8392\n",
            "Epoch 229/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8123 - val_loss: 0.3964 - val_accuracy: 0.8392\n",
            "Epoch 230/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4498 - accuracy: 0.8123 - val_loss: 0.3963 - val_accuracy: 0.8392\n",
            "Epoch 231/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8105 - val_loss: 0.3966 - val_accuracy: 0.8392\n",
            "Epoch 232/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4497 - accuracy: 0.8123 - val_loss: 0.3961 - val_accuracy: 0.8392\n",
            "Epoch 233/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4496 - accuracy: 0.8123 - val_loss: 0.3962 - val_accuracy: 0.8392\n",
            "Epoch 234/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.8123 - val_loss: 0.3965 - val_accuracy: 0.8392\n",
            "Epoch 235/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8123 - val_loss: 0.3962 - val_accuracy: 0.8392\n",
            "Epoch 236/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4497 - accuracy: 0.8123 - val_loss: 0.3959 - val_accuracy: 0.8392\n",
            "Epoch 237/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8123 - val_loss: 0.3963 - val_accuracy: 0.8392\n",
            "Epoch 238/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.8123 - val_loss: 0.3957 - val_accuracy: 0.8392\n",
            "Epoch 239/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4496 - accuracy: 0.8123 - val_loss: 0.3960 - val_accuracy: 0.8392\n",
            "Epoch 240/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8123 - val_loss: 0.3959 - val_accuracy: 0.8392\n",
            "Epoch 241/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3959 - val_accuracy: 0.8392\n",
            "Epoch 242/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4496 - accuracy: 0.8123 - val_loss: 0.3962 - val_accuracy: 0.8392\n",
            "Epoch 243/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3957 - val_accuracy: 0.8392\n",
            "Epoch 244/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3958 - val_accuracy: 0.8392\n",
            "Epoch 245/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3960 - val_accuracy: 0.8392\n",
            "Epoch 246/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3960 - val_accuracy: 0.8392\n",
            "Epoch 247/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3958 - val_accuracy: 0.8392\n",
            "Epoch 248/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8123 - val_loss: 0.3960 - val_accuracy: 0.8392\n",
            "Epoch 249/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8123 - val_loss: 0.3955 - val_accuracy: 0.8392\n",
            "Epoch 250/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8123 - val_loss: 0.3955 - val_accuracy: 0.8392\n",
            "Epoch 251/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3957 - val_accuracy: 0.8392\n",
            "Epoch 252/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8123 - val_loss: 0.3953 - val_accuracy: 0.8392\n",
            "Epoch 253/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8123 - val_loss: 0.3954 - val_accuracy: 0.8392\n",
            "Epoch 254/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8123 - val_loss: 0.3955 - val_accuracy: 0.8392\n",
            "Epoch 255/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3954 - val_accuracy: 0.8392\n",
            "Epoch 256/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4495 - accuracy: 0.8123 - val_loss: 0.3960 - val_accuracy: 0.8392\n",
            "Epoch 257/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8123 - val_loss: 0.3955 - val_accuracy: 0.8392\n",
            "Epoch 258/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3954 - val_accuracy: 0.8392\n",
            "Epoch 259/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3956 - val_accuracy: 0.8392\n",
            "Epoch 260/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3957 - val_accuracy: 0.8392\n",
            "Epoch 261/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3954 - val_accuracy: 0.8392\n",
            "Epoch 262/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3952 - val_accuracy: 0.8392\n",
            "Epoch 263/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4494 - accuracy: 0.8123 - val_loss: 0.3949 - val_accuracy: 0.8392\n",
            "Epoch 264/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3952 - val_accuracy: 0.8392\n",
            "Epoch 265/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3952 - val_accuracy: 0.8392\n",
            "Epoch 266/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3954 - val_accuracy: 0.8392\n",
            "Epoch 267/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3949 - val_accuracy: 0.8392\n",
            "Epoch 268/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3952 - val_accuracy: 0.8392\n",
            "Epoch 269/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3953 - val_accuracy: 0.8392\n",
            "Epoch 270/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3949 - val_accuracy: 0.8392\n",
            "Epoch 271/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3956 - val_accuracy: 0.8392\n",
            "Epoch 272/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3949 - val_accuracy: 0.8392\n",
            "Epoch 273/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3950 - val_accuracy: 0.8392\n",
            "Epoch 274/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3952 - val_accuracy: 0.8392\n",
            "Epoch 275/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3954 - val_accuracy: 0.8392\n",
            "Epoch 276/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3949 - val_accuracy: 0.8392\n",
            "Epoch 277/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 278/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4493 - accuracy: 0.8123 - val_loss: 0.3952 - val_accuracy: 0.8392\n",
            "Epoch 279/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3954 - val_accuracy: 0.8392\n",
            "Epoch 280/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3952 - val_accuracy: 0.8392\n",
            "Epoch 281/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3951 - val_accuracy: 0.8392\n",
            "Epoch 282/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3949 - val_accuracy: 0.8392\n",
            "Epoch 283/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 284/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 285/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3949 - val_accuracy: 0.8392\n",
            "Epoch 286/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 287/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3951 - val_accuracy: 0.8392\n",
            "Epoch 288/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 289/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 290/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 291/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 292/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 293/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4492 - accuracy: 0.8123 - val_loss: 0.3953 - val_accuracy: 0.8392\n",
            "Epoch 294/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 295/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3950 - val_accuracy: 0.8392\n",
            "Epoch 296/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 297/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 298/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4491 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 299/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3945 - val_accuracy: 0.8392\n",
            "Epoch 300/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 301/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 302/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 303/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 304/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 305/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 306/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 307/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 308/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3941 - val_accuracy: 0.8392\n",
            "Epoch 309/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 310/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 311/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 312/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 313/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 314/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 315/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4490 - accuracy: 0.8123 - val_loss: 0.3951 - val_accuracy: 0.8392\n",
            "Epoch 316/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 317/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 318/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 319/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3948 - val_accuracy: 0.8392\n",
            "Epoch 320/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3952 - val_accuracy: 0.8392\n",
            "Epoch 321/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 322/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3950 - val_accuracy: 0.8392\n",
            "Epoch 323/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3945 - val_accuracy: 0.8392\n",
            "Epoch 324/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3949 - val_accuracy: 0.8392\n",
            "Epoch 325/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 326/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 327/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3945 - val_accuracy: 0.8392\n",
            "Epoch 328/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 329/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3941 - val_accuracy: 0.8392\n",
            "Epoch 330/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 331/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 332/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 333/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3945 - val_accuracy: 0.8392\n",
            "Epoch 334/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 335/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4489 - accuracy: 0.8123 - val_loss: 0.3940 - val_accuracy: 0.8392\n",
            "Epoch 336/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 337/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4488 - accuracy: 0.8123 - val_loss: 0.3947 - val_accuracy: 0.8392\n",
            "Epoch 338/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8140 - val_loss: 0.3941 - val_accuracy: 0.8392\n",
            "Epoch 339/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3940 - val_accuracy: 0.8392\n",
            "Epoch 340/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 341/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8123 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 342/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.8123 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 343/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3945 - val_accuracy: 0.8392\n",
            "Epoch 344/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.8123 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 345/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4487 - accuracy: 0.8123 - val_loss: 0.3940 - val_accuracy: 0.8392\n",
            "Epoch 346/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8140 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 347/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 348/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 349/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8123 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 350/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 351/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.8140 - val_loss: 0.3946 - val_accuracy: 0.8392\n",
            "Epoch 352/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8140 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 353/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 354/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 355/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8140 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 356/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 357/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4488 - accuracy: 0.8158 - val_loss: 0.3939 - val_accuracy: 0.8462\n",
            "Epoch 358/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.3937 - val_accuracy: 0.8462\n",
            "Epoch 359/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.3939 - val_accuracy: 0.8462\n",
            "Epoch 360/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4487 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 361/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 362/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 363/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3938 - val_accuracy: 0.8462\n",
            "Epoch 364/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3938 - val_accuracy: 0.8462\n",
            "Epoch 365/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 366/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3936 - val_accuracy: 0.8462\n",
            "Epoch 367/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3932 - val_accuracy: 0.8462\n",
            "Epoch 368/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4487 - accuracy: 0.8140 - val_loss: 0.3935 - val_accuracy: 0.8462\n",
            "Epoch 369/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 370/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3941 - val_accuracy: 0.8462\n",
            "Epoch 371/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3939 - val_accuracy: 0.8462\n",
            "Epoch 372/1000\n",
            "36/36 [==============================] - 0s 8ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8462\n",
            "Epoch 373/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8462\n",
            "Epoch 374/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 375/1000\n",
            "36/36 [==============================] - 0s 7ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3941 - val_accuracy: 0.8392\n",
            "Epoch 376/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3935 - val_accuracy: 0.8462\n",
            "Epoch 377/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8462\n",
            "Epoch 378/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 379/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 380/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 381/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 382/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4486 - accuracy: 0.8158 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 383/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 384/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 385/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3938 - val_accuracy: 0.8462\n",
            "Epoch 386/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3937 - val_accuracy: 0.8462\n",
            "Epoch 387/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3938 - val_accuracy: 0.8462\n",
            "Epoch 388/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3939 - val_accuracy: 0.8462\n",
            "Epoch 389/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3936 - val_accuracy: 0.8462\n",
            "Epoch 390/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3935 - val_accuracy: 0.8462\n",
            "Epoch 391/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3943 - val_accuracy: 0.8392\n",
            "Epoch 392/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 393/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 394/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3939 - val_accuracy: 0.8462\n",
            "Epoch 395/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8140 - val_loss: 0.3939 - val_accuracy: 0.8462\n",
            "Epoch 396/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3945 - val_accuracy: 0.8392\n",
            "Epoch 397/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8462\n",
            "Epoch 398/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8392\n",
            "Epoch 399/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3944 - val_accuracy: 0.8392\n",
            "Epoch 400/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 401/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3939 - val_accuracy: 0.8462\n",
            "Epoch 402/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3939 - val_accuracy: 0.8462\n",
            "Epoch 403/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.8158 - val_loss: 0.3936 - val_accuracy: 0.8462\n",
            "Epoch 404/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3938 - val_accuracy: 0.8462\n",
            "Epoch 405/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4485 - accuracy: 0.8140 - val_loss: 0.3936 - val_accuracy: 0.8462\n",
            "Epoch 406/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 407/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3941 - val_accuracy: 0.8462\n",
            "Epoch 408/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3941 - val_accuracy: 0.8392\n",
            "Epoch 409/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3941 - val_accuracy: 0.8462\n",
            "Epoch 410/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 411/1000\n",
            "36/36 [==============================] - 0s 6ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8392\n",
            "Epoch 412/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3938 - val_accuracy: 0.8462\n",
            "Epoch 413/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 414/1000\n",
            "36/36 [==============================] - 0s 5ms/step - loss: 0.4484 - accuracy: 0.8175 - val_loss: 0.3943 - val_accuracy: 0.8462\n",
            "Epoch 415/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3940 - val_accuracy: 0.8462\n",
            "Epoch 416/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4484 - accuracy: 0.8158 - val_loss: 0.3942 - val_accuracy: 0.8462\n",
            "Epoch 417/1000\n",
            "36/36 [==============================] - 0s 4ms/step - loss: 0.4483 - accuracy: 0.8158 - val_loss: 0.3938 - val_accuracy: 0.8462\n",
            "6/6 [==============================] - 0s 3ms/step - loss: 0.4042 - accuracy: 0.8652\n",
            "\n",
            " 5 fold mean accuracy: 0.8193399999999998\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy"
      ],
      "metadata": {
        "id": "ol6cpWWTQ418",
        "outputId": "5c44449a-5c73-463d-9c8e-30109c2d508e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 382,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.7933, 0.809, 0.7865, 0.8427, 0.8652]"
            ]
          },
          "metadata": {},
          "execution_count": 382
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras import regularizers\n",
        "model = Sequential()\n",
        "model.add(Dense(1, input_dim=23, kernel_regularizer=regularizers.l2(0.001), activation='sigmoid'))\n",
        "#model.add(Dropout(0.25))\n",
        "#model.add(Dense(16, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "#model.add(Dense(4, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "#model.add(Dense(4, kernel_regularizer=regularizers.l2(0.001), activation='relu'))\n",
        "#model.add(Dropout(0.25))\n",
        "#model.add(Dense(1, activation='sigmoid'))\n",
        "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
        "model.fit(X, Y, epochs=400, batch_size=16, verbose=1)"
      ],
      "metadata": {
        "id": "Ta5oADPjFFY5",
        "outputId": "9f838ead-a54b-45cd-dff1-c023b90fdff8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 383,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/400\n",
            "56/56 [==============================] - 1s 2ms/step - loss: 0.6449 - accuracy: 0.6465\n",
            "Epoch 2/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6244 - accuracy: 0.6599\n",
            "Epoch 3/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.6061 - accuracy: 0.6678\n",
            "Epoch 4/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5897 - accuracy: 0.6857\n",
            "Epoch 5/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5752 - accuracy: 0.7071\n",
            "Epoch 6/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5625 - accuracy: 0.7295\n",
            "Epoch 7/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5510 - accuracy: 0.7374\n",
            "Epoch 8/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5409 - accuracy: 0.7553\n",
            "Epoch 9/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5317 - accuracy: 0.7632\n",
            "Epoch 10/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5235 - accuracy: 0.7755\n",
            "Epoch 11/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5162 - accuracy: 0.7856\n",
            "Epoch 12/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5096 - accuracy: 0.7879\n",
            "Epoch 13/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.5037 - accuracy: 0.7856\n",
            "Epoch 14/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4982 - accuracy: 0.7868\n",
            "Epoch 15/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4935 - accuracy: 0.7957\n",
            "Epoch 16/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4894 - accuracy: 0.7957\n",
            "Epoch 17/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4852 - accuracy: 0.7969\n",
            "Epoch 18/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4815 - accuracy: 0.7957\n",
            "Epoch 19/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4783 - accuracy: 0.7980\n",
            "Epoch 20/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4752 - accuracy: 0.8036\n",
            "Epoch 21/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4725 - accuracy: 0.8070\n",
            "Epoch 22/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4700 - accuracy: 0.8103\n",
            "Epoch 23/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4676 - accuracy: 0.8103\n",
            "Epoch 24/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4655 - accuracy: 0.8092\n",
            "Epoch 25/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4635 - accuracy: 0.8092\n",
            "Epoch 26/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4618 - accuracy: 0.8092\n",
            "Epoch 27/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4600 - accuracy: 0.8092\n",
            "Epoch 28/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4584 - accuracy: 0.8103\n",
            "Epoch 29/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4570 - accuracy: 0.8092\n",
            "Epoch 30/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4556 - accuracy: 0.8081\n",
            "Epoch 31/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4542 - accuracy: 0.8058\n",
            "Epoch 32/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4532 - accuracy: 0.8103\n",
            "Epoch 33/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4521 - accuracy: 0.8193\n",
            "Epoch 34/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8204\n",
            "Epoch 35/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4501 - accuracy: 0.8215\n",
            "Epoch 36/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4493 - accuracy: 0.8215\n",
            "Epoch 37/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4483 - accuracy: 0.8215\n",
            "Epoch 38/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4475 - accuracy: 0.8238\n",
            "Epoch 39/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4468 - accuracy: 0.8249\n",
            "Epoch 40/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4459 - accuracy: 0.8238\n",
            "Epoch 41/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4453 - accuracy: 0.8238\n",
            "Epoch 42/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4446 - accuracy: 0.8238\n",
            "Epoch 43/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4440 - accuracy: 0.8249\n",
            "Epoch 44/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4434 - accuracy: 0.8238\n",
            "Epoch 45/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4428 - accuracy: 0.8260\n",
            "Epoch 46/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4424 - accuracy: 0.8294\n",
            "Epoch 47/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4419 - accuracy: 0.8294\n",
            "Epoch 48/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4413 - accuracy: 0.8294\n",
            "Epoch 49/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4409 - accuracy: 0.8294\n",
            "Epoch 50/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4404 - accuracy: 0.8294\n",
            "Epoch 51/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4399 - accuracy: 0.8294\n",
            "Epoch 52/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4396 - accuracy: 0.8294\n",
            "Epoch 53/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4392 - accuracy: 0.8283\n",
            "Epoch 54/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4388 - accuracy: 0.8294\n",
            "Epoch 55/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4386 - accuracy: 0.8272\n",
            "Epoch 56/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4381 - accuracy: 0.8283\n",
            "Epoch 57/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4379 - accuracy: 0.8283\n",
            "Epoch 58/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4375 - accuracy: 0.8283\n",
            "Epoch 59/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4372 - accuracy: 0.8294\n",
            "Epoch 60/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4369 - accuracy: 0.8283\n",
            "Epoch 61/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4365 - accuracy: 0.8283\n",
            "Epoch 62/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4363 - accuracy: 0.8283\n",
            "Epoch 63/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4361 - accuracy: 0.8283\n",
            "Epoch 64/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4358 - accuracy: 0.8283\n",
            "Epoch 65/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4354 - accuracy: 0.8283\n",
            "Epoch 66/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4353 - accuracy: 0.8294\n",
            "Epoch 67/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4350 - accuracy: 0.8283\n",
            "Epoch 68/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4349 - accuracy: 0.8294\n",
            "Epoch 69/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4347 - accuracy: 0.8283\n",
            "Epoch 70/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4344 - accuracy: 0.8294\n",
            "Epoch 71/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4342 - accuracy: 0.8305\n",
            "Epoch 72/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4341 - accuracy: 0.8305\n",
            "Epoch 73/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4338 - accuracy: 0.8305\n",
            "Epoch 74/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4336 - accuracy: 0.8316\n",
            "Epoch 75/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4334 - accuracy: 0.8305\n",
            "Epoch 76/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4332 - accuracy: 0.8305\n",
            "Epoch 77/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8316\n",
            "Epoch 78/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4330 - accuracy: 0.8316\n",
            "Epoch 79/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4327 - accuracy: 0.8316\n",
            "Epoch 80/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4325 - accuracy: 0.8316\n",
            "Epoch 81/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4325 - accuracy: 0.8328\n",
            "Epoch 82/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4323 - accuracy: 0.8305\n",
            "Epoch 83/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4322 - accuracy: 0.8328\n",
            "Epoch 84/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4321 - accuracy: 0.8328\n",
            "Epoch 85/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4319 - accuracy: 0.8328\n",
            "Epoch 86/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4318 - accuracy: 0.8328\n",
            "Epoch 87/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4317 - accuracy: 0.8328\n",
            "Epoch 88/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4316 - accuracy: 0.8328\n",
            "Epoch 89/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8328\n",
            "Epoch 90/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4313 - accuracy: 0.8328\n",
            "Epoch 91/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4312 - accuracy: 0.8328\n",
            "Epoch 92/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8328\n",
            "Epoch 93/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4311 - accuracy: 0.8316\n",
            "Epoch 94/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8328\n",
            "Epoch 95/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4308 - accuracy: 0.8305\n",
            "Epoch 96/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4307 - accuracy: 0.8316\n",
            "Epoch 97/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4306 - accuracy: 0.8316\n",
            "Epoch 98/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4305 - accuracy: 0.8283\n",
            "Epoch 99/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4304 - accuracy: 0.8294\n",
            "Epoch 100/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4303 - accuracy: 0.8283\n",
            "Epoch 101/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4302 - accuracy: 0.8283\n",
            "Epoch 102/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8283\n",
            "Epoch 103/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8283\n",
            "Epoch 104/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4300 - accuracy: 0.8283\n",
            "Epoch 105/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4301 - accuracy: 0.8294\n",
            "Epoch 106/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8283\n",
            "Epoch 107/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4298 - accuracy: 0.8283\n",
            "Epoch 108/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8283\n",
            "Epoch 109/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4297 - accuracy: 0.8283\n",
            "Epoch 110/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4296 - accuracy: 0.8294\n",
            "Epoch 111/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4295 - accuracy: 0.8283\n",
            "Epoch 112/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8283\n",
            "Epoch 113/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8283\n",
            "Epoch 114/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8294\n",
            "Epoch 115/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8283\n",
            "Epoch 116/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4293 - accuracy: 0.8294\n",
            "Epoch 117/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8294\n",
            "Epoch 118/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8283\n",
            "Epoch 119/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8283\n",
            "Epoch 120/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4291 - accuracy: 0.8294\n",
            "Epoch 121/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4290 - accuracy: 0.8283\n",
            "Epoch 122/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8283\n",
            "Epoch 123/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8283\n",
            "Epoch 124/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8283\n",
            "Epoch 125/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4289 - accuracy: 0.8294\n",
            "Epoch 126/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4288 - accuracy: 0.8294\n",
            "Epoch 127/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4287 - accuracy: 0.8294\n",
            "Epoch 128/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8294\n",
            "Epoch 129/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4286 - accuracy: 0.8294\n",
            "Epoch 130/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8294\n",
            "Epoch 131/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4285 - accuracy: 0.8294\n",
            "Epoch 132/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8294\n",
            "Epoch 133/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8294\n",
            "Epoch 134/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4284 - accuracy: 0.8294\n",
            "Epoch 135/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8294\n",
            "Epoch 136/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8294\n",
            "Epoch 137/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8294\n",
            "Epoch 138/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8294\n",
            "Epoch 139/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8294\n",
            "Epoch 140/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8294\n",
            "Epoch 141/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4283 - accuracy: 0.8294\n",
            "Epoch 142/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8294\n",
            "Epoch 143/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8294\n",
            "Epoch 144/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8294\n",
            "Epoch 145/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8294\n",
            "Epoch 146/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4281 - accuracy: 0.8294\n",
            "Epoch 147/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8294\n",
            "Epoch 148/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8294\n",
            "Epoch 149/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4280 - accuracy: 0.8294\n",
            "Epoch 150/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8294\n",
            "Epoch 151/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4279 - accuracy: 0.8294\n",
            "Epoch 152/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4278 - accuracy: 0.8294\n",
            "Epoch 153/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8294\n",
            "Epoch 154/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8294\n",
            "Epoch 155/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8294\n",
            "Epoch 156/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8294\n",
            "Epoch 157/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8294\n",
            "Epoch 158/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4277 - accuracy: 0.8294\n",
            "Epoch 159/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8294\n",
            "Epoch 160/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8294\n",
            "Epoch 161/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8294\n",
            "Epoch 162/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8294\n",
            "Epoch 163/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8294\n",
            "Epoch 164/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4276 - accuracy: 0.8294\n",
            "Epoch 165/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8294\n",
            "Epoch 166/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8294\n",
            "Epoch 167/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8294\n",
            "Epoch 168/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8294\n",
            "Epoch 169/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8294\n",
            "Epoch 170/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8294\n",
            "Epoch 171/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8294\n",
            "Epoch 172/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8294\n",
            "Epoch 173/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8294\n",
            "Epoch 174/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8294\n",
            "Epoch 175/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8294\n",
            "Epoch 176/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8294\n",
            "Epoch 177/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4274 - accuracy: 0.8294\n",
            "Epoch 178/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8294\n",
            "Epoch 179/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8294\n",
            "Epoch 180/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8294\n",
            "Epoch 181/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8294\n",
            "Epoch 182/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8294\n",
            "Epoch 183/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4273 - accuracy: 0.8283\n",
            "Epoch 184/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8294\n",
            "Epoch 185/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8294\n",
            "Epoch 186/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4274 - accuracy: 0.8283\n",
            "Epoch 187/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8283\n",
            "Epoch 188/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4273 - accuracy: 0.8294\n",
            "Epoch 189/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8283\n",
            "Epoch 190/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 191/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 192/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 193/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8294\n",
            "Epoch 194/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 195/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8283\n",
            "Epoch 196/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4272 - accuracy: 0.8283\n",
            "Epoch 197/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 198/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 199/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 200/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 201/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4272 - accuracy: 0.8283\n",
            "Epoch 202/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 203/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 204/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 205/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 206/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 207/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8283\n",
            "Epoch 208/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8294\n",
            "Epoch 209/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 210/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 211/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 212/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 213/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 214/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 215/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 216/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 217/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 218/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 219/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 220/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 221/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 222/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 223/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 224/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 225/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 226/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 227/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 228/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 229/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 230/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 231/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 232/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 233/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 234/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 235/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 236/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4270 - accuracy: 0.8283\n",
            "Epoch 237/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 238/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 239/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 240/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 241/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 242/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 243/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 244/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 245/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4269 - accuracy: 0.8283\n",
            "Epoch 246/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 247/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 248/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 249/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 250/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 251/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 252/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 253/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 254/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 255/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 256/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 257/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 258/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 259/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 260/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 261/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 262/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 263/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 264/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 265/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 266/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 267/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 268/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 269/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 270/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 271/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 272/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 273/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 274/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 275/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 276/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 277/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 278/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 279/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 280/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 281/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 282/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 283/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 284/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 285/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 286/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 287/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 288/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 289/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 290/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 291/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 292/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 293/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 294/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 295/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 296/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 297/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4268 - accuracy: 0.8283\n",
            "Epoch 298/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 299/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 300/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 301/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 302/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 303/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 304/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 305/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 306/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 307/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 308/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 309/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 310/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 311/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 312/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 313/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 314/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 315/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 316/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 317/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 318/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 319/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 320/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 321/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 322/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 323/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 324/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4268 - accuracy: 0.8272\n",
            "Epoch 325/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 326/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 327/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 328/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 329/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 330/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 331/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 332/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 333/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 334/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 335/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 336/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 337/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 338/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 339/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 340/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 341/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 342/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 343/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 344/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 345/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 346/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 347/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 348/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 349/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 350/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 351/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 352/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8283\n",
            "Epoch 353/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 354/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8272\n",
            "Epoch 355/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 356/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 357/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 358/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 359/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 360/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 361/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 362/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 363/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 364/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 365/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8272\n",
            "Epoch 366/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 367/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8272\n",
            "Epoch 368/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 369/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 370/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 371/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 372/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 373/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 374/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8283\n",
            "Epoch 375/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 376/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 377/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 378/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8283\n",
            "Epoch 379/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 380/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 381/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8272\n",
            "Epoch 382/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 383/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4266 - accuracy: 0.8283\n",
            "Epoch 384/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4264 - accuracy: 0.8283\n",
            "Epoch 385/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8272\n",
            "Epoch 386/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8272\n",
            "Epoch 387/400\n",
            "56/56 [==============================] - 0s 2ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 388/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8272\n",
            "Epoch 389/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 390/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8283\n",
            "Epoch 391/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8283\n",
            "Epoch 392/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 393/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 394/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4266 - accuracy: 0.8272\n",
            "Epoch 395/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 396/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 397/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4264 - accuracy: 0.8272\n",
            "Epoch 398/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 399/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n",
            "Epoch 400/400\n",
            "56/56 [==============================] - 0s 3ms/step - loss: 0.4265 - accuracy: 0.8283\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f8654806ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 383
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_vloss = history.history['val_loss'][10:]\n",
        "model_loss = history.history['loss'][10:]\n",
        "x_len = np.arange(len(model_loss))\n",
        "\n",
        "plt.plot(x_len, model_vloss, \"o\", c=\"red\", markersize=3)\n",
        "plt.plot(x_len, model_loss, \"o\", c=\"blue\", markersize=3)\n",
        "plt.show()\n",
        "\n",
        "print(\"\\n Accurarcy: %.4f\" % (model.evaluate(X_test, Y_test)[1]))"
      ],
      "metadata": {
        "id": "mlAc76SinTNY",
        "outputId": "bdf7b885-4764-41cf-a48f-4675a15bd46a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 482
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9/9 [==============================] - 0s 2ms/step - loss: 0.4571 - accuracy: 0.7873\n",
            "\n",
            " Accurarcy: 0.7873\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('please.h5')"
      ],
      "metadata": {
        "id": "1UKmU6Rxa8y4"
      },
      "execution_count": 405,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = load_model('please.h5')\n",
        "Y_prediction = model.predict(dataset).flatten()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "CYLRla1ncEQ8",
        "outputId": "70af0340-593c-4eda-b3c7-271cb7f5e579",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 406,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(Y_prediction[891:])"
      ],
      "metadata": {
        "id": "X5DyyB0wm4Wt",
        "outputId": "9d0ff4d9-2ff9-4f23-ebde-6a0ef4a74809",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "418"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submission = pd.read_csv('gender_submission.csv')\n",
        "submission['Survived'] = Y_prediction[891:]\n",
        "submission.loc[submission['Survived'] < 0.5 ,'Survived'] = 0\n",
        "submission.loc[submission['Survived'] >= 0.5 ,'Survived'] = 1\n",
        "submission['Survived'] = submission['Survived'].astype(int)\n",
        "submission.to_csv('sub.csv',index=False)"
      ],
      "metadata": {
        "id": "Gy3q57IEfg0j"
      },
      "execution_count": 407,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Y_prediction = model.predict(X_test).flatten()\n",
        "osub = pd.read_csv(\"submit.csv\")\n",
        "\n",
        "Y_pred_old = osub['Survived']\n",
        "\n",
        "#plt.plot(range(len(Y_test)), Y_test, \"o\", c=\"red\", markersize=3)\n",
        "plt.plot(range(len(Y_prediction)), submission['Survived'], \"o\", c=\"blue\", markersize=3)\n",
        "plt.plot(range(len(Y_prediction)), Y_pred_old, \"o\", c='red', markersize=3)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o271V5Fkobdf",
        "outputId": "78940036-a05f-45a6-a3ea-f226438c5cba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "t = df['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)\n",
        "pd.DataFrame(t).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 504
        },
        "id": "vtYiMOPq_lCo",
        "outputId": "002535a4-a22c-46a4-d75b-12372c5f0dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3801\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3802\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/_libs/index.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Name'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-14fb102119fa>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Name'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' ([A-Za-z]+)\\.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3805\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnlevels\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3807\u001b[0;31m             \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3808\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3809\u001b[0m                 \u001b[0mindexer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   3802\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3803\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3804\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3805\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3806\u001b[0m                 \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'Name'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df['FBand'] = pd.cut(df['Fare'], 7)\n",
        "df[['FBand','Survived']].groupby(['FBand'], as_index=False).mean()"
      ],
      "metadata": {
        "id": "hfTIJaeFv7PT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Ncabin'] = df['Cabin'].str.extract('([A-G])', expand=False)\n",
        "pd.crosstab(df['Ncabin'],df['Survived'])"
      ],
      "metadata": {
        "id": "Fy8RE1S8Gswe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[['Embarked','Fare']].groupby(['Embarked'], as_index=False).mean()\n",
        "df[['Pclass','Fare']].groupby(['Pclass'], as_index=False).mean()"
      ],
      "metadata": {
        "id": "u5IQkdndMNSf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()\n",
        "df[df['Embarked'].isnull()]"
      ],
      "metadata": {
        "id": "rg5-yYe3VHAq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "df[['Ncabin','Survived']].groupby('Ncabin').mean()"
      ],
      "metadata": {
        "id": "CVGL4yGtbs5x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit1 = pd.read_csv('sub.csv')\n",
        "submit2 = pd.read_csv('sub(5).csv')"
      ],
      "metadata": {
        "id": "EUyWlIDtxAoP"
      },
      "execution_count": 408,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit1[submit1['Survived'] == submit2['Survived']]"
      ],
      "metadata": {
        "id": "NkbyPQmBxHzI",
        "outputId": "33f27863-bd8a-4764-ef3b-8f5e32f406b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": 410,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     PassengerId  Survived\n",
              "0            892         0\n",
              "1            893         1\n",
              "2            894         0\n",
              "3            895         0\n",
              "5            897         0\n",
              "..           ...       ...\n",
              "413         1305         0\n",
              "414         1306         1\n",
              "415         1307         0\n",
              "416         1308         0\n",
              "417         1309         1\n",
              "\n",
              "[403 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4e9b201c-d8ae-4f9e-938d-6b71a2a4e25f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>PassengerId</th>\n",
              "      <th>Survived</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>892</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>893</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>894</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>895</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>897</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>1305</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>1306</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>1307</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>1308</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>1309</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>403 rows  2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4e9b201c-d8ae-4f9e-938d-6b71a2a4e25f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4e9b201c-d8ae-4f9e-938d-6b71a2a4e25f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4e9b201c-d8ae-4f9e-938d-6b71a2a4e25f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 410
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "W1eHjYYkF5Cx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}